{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562aa9cd-ee99-4676-9806-a6df224f0b18",
   "metadata": {},
   "source": [
    "![](images/ml_flow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d852287-c347-4c93-a151-3e872f1d929f",
   "metadata": {},
   "source": [
    "## Pipelines Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e9928-1aa9-4adf-ad77-7050517e8367",
   "metadata": {},
   "source": [
    "### Data Extraction and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a2de2e31-28d3-47f2-abed-4a6bf175022b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.dsl import (component, pipeline, Artifact, Input, Output, ClassificationMetrics)\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "\n",
    "#Data Processing\n",
    "@component(packages_to_install=['google-cloud-bigquery[bqstorage,pandas]', 'scikit-learn'])\n",
    "def preprocess(\n",
    "    bq_dataset: str,\n",
    "    x_train_out: Output[Artifact],\n",
    "    y_train_out: Output[Artifact],\n",
    "    x_test_out: Output[Artifact],\n",
    "    y_test_out: Output[Artifact]\n",
    "):\n",
    "    import random\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from google.cloud import bigquery\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    ########################################################################\n",
    "    # Loading DS from BigQuery\n",
    "    \n",
    "    client = bigquery.Client(project='jchavezar-demo')\n",
    "    sql = f\"\"\"\n",
    "        SELECT * \n",
    "        FROM `{bq_dataset}`\n",
    "    \"\"\"\n",
    "    df = client.query(sql).to_dataframe()\n",
    "    X_raw = df.iloc[:,:-1]  # features (pandas DataFrame)\n",
    "    y_raw = df.target  # labels (pandas Series)\n",
    "\n",
    "    ########################################################################\n",
    "    \n",
    "    ########################################################################\n",
    "    # Feature Engineering\n",
    "    \n",
    "    SEED = 123456\n",
    "    np.random.seed(SEED)\n",
    "    random.seed(SEED)\n",
    "    \n",
    "    cat_features = X_raw.select_dtypes([\"object\", \"bool\"]).columns\n",
    "    num_features = X_raw.select_dtypes(\"float64\").columns\n",
    "    \n",
    "    X_encoded = pd.get_dummies(X_raw, columns=cat_features, drop_first=True)\n",
    "    print(X_encoded)\n",
    "    y = y_raw.map({\"bad\": 0, \"good\": 1})  # encode labels as integers\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_encoded,\n",
    "        y,\n",
    "        test_size=0.25,\n",
    "        random_state=SEED,\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train[num_features] = scaler.fit_transform(X_train[num_features])\n",
    "    X_test[num_features] = scaler.transform(X_test[num_features])\n",
    "    ########################################################################\n",
    "    \n",
    "    ########################################################################\n",
    "    # Storing DS' GCS\n",
    "    \n",
    "    # Target encoding (from text to int)\n",
    "    X_train.to_csv(x_train_out.path, index=False)\n",
    "    y_train.to_csv(y_train_out.path, index=False)\n",
    "    X_test.to_csv(x_test_out.path, index=False)\n",
    "    y_test.to_csv(y_test_out.path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558d822b-d64f-4c16-98a8-59f7dd202b10",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70112724-3d29-49cf-8891-da0ae34ba907",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-0:latest\",\n",
    "    packages_to_install=['pandas', 'gcsfs', 'scikit-learn'])\n",
    "def train(\n",
    "    x_train_in: Input[Artifact],\n",
    "    y_train_in: Input[Artifact],\n",
    "    x_test_in: Input[Artifact],\n",
    "    y_test_in: Input[Artifact],\n",
    "    metrics: Output[ClassificationMetrics],\n",
    "    model: Output[Artifact]\n",
    ") -> str:\n",
    "    import pickle\n",
    "    import pathlib\n",
    "    import pandas as pd\n",
    "    from joblib import dump\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    \n",
    "    x_train = pd.read_csv(x_train_in.path)\n",
    "    y_train = pd.read_csv(y_train_in.path)\n",
    "    X_test = pd.read_csv(x_test_in.path)\n",
    "    y_test = pd.read_csv(y_test_in.path)\n",
    "\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(x_train, y_train)\n",
    "    acc_og = clf.score(X_test, y_test)\n",
    "    print(f\"Test accuracy of original logistic regression: {acc_og}\")\n",
    "    \n",
    "    # Saving Model\n",
    "    file_name = model.path + \"/model.pkl\"\n",
    "    \n",
    "    pathlib.Path(model.path).mkdir()\n",
    "    with open(file_name, \"wb\") as file:\n",
    "        pickle.dump(clf, file)\n",
    "    \n",
    "    # Metrics export (Confusion Matrix)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    metrics.log_confusion_matrix(\n",
    "        ['good', 'bad'],\n",
    "        confusion_matrix(y_test, y_test_pred).tolist()\n",
    "    )\n",
    "    \n",
    "    return str(acc_og)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d47fed3-c6ad-4b78-a76d-080d635ec429",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "468eeb0f-1375-4c57-9de3-bd16bcc069bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(name='simple-testing')\n",
    "def pipeline(bq_dataset: str):\n",
    "    _preprocess = preprocess(bq_dataset=bq_dataset)\n",
    "    _train = train(\n",
    "        x_train_in = _preprocess.outputs['x_train_out'],\n",
    "        y_train_in = _preprocess.outputs['y_train_out'],\n",
    "        x_test_in = _preprocess.outputs['x_test_out'],\n",
    "        y_test_in = _preprocess.outputs['y_test_out'],\n",
    "    )\n",
    "    model_upload_op = ModelUploadOp(\n",
    "        display_name='sklearn-pipe',\n",
    "        project='jchavezar-demo',\n",
    "        location='us-central1',\n",
    "        unmanaged_container_model=_train.outputs['model']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b59b347-b4c8-4ea9-8194-f6be6d3bbd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile File\n",
    "from kfp import compiler\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path='simple_testing.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e6eacc18-5ca8-4374-9f8a-b733bdd740c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Template:\n",
    "from kfp.registry import RegistryClient\n",
    "\n",
    "client = RegistryClient(host=f\"https://us-central1-kfp.pkg.dev/jchavezar-demo/simple-samples-repo\")\n",
    "\n",
    "## Upload Template\n",
    "\n",
    "templateName, versionName = client.upload_pipeline(\n",
    "  file_name=\"simple_testing.yaml\",\n",
    "  tags=[\"v1\", \"latest\"],\n",
    "  extra_headers={\"description\":\"This is an example pipeline template.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457b9e3-7b5a-47d5-94bd-f16412d7fcc3",
   "metadata": {},
   "source": [
    "## Creating Pipelines from Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e793a74a-a89b-4ba0-80ec-22cbb1c311ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating 2 pipelines from template\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Initialize the aiplatform package\n",
    "aiplatform.init(\n",
    "    project=\"jchavezar-demo\",\n",
    "    location='us-central1',\n",
    "    staging_bucket=\"gs://vtx-staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "57b1bd7f-8262-4ed3-a74c-2d0251168e65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/569083142710/locations/us-central1/pipelineJobs/simple-testing-20230323003422\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/569083142710/locations/us-central1/pipelineJobs/simple-testing-20230323003422')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/simple-testing-20230323003422?project=569083142710\n"
     ]
    }
   ],
   "source": [
    "# Create a job via version id.\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"simple-sample-latest\",\n",
    "    template_path=\"https://us-central1-kfp.pkg.dev/jchavezar-demo/simple-samples-repo/simple-testing/\" + versionName,\n",
    "    parameter_values={\"bq_dataset\": \"jchavezar-demo.vertex_datasets_public.credit-openml\"},\n",
    ")\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fc37a-b821-4a24-a065-c90742944bb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2ee359-78e1-4a1d-bef2-74afdcc82503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048a06d8-54bf-4ae2-ab12-7775fda5f52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c82fbc9-dd4d-4cbf-bd06-271c09952305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e1eb5ca-fae1-4d08-a492-d6e9d4f2491a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating PipelineJob\n",
      "PipelineJob created. Resource name: projects/569083142710/locations/us-central1/pipelineJobs/simple-testing-20230322170958\n",
      "To use this PipelineJob in another session:\n",
      "pipeline_job = aiplatform.PipelineJob.get('projects/569083142710/locations/us-central1/pipelineJobs/simple-testing-20230322170958')\n",
      "View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/simple-testing-20230322170958?project=569083142710\n"
     ]
    }
   ],
   "source": [
    "# Create a job via tag and with different \n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"simple-sample-latest\",\n",
    "    template_path=\"https://us-central1-kfp.pkg.dev/jchavezar-demo/simple-samples-repo/simple-testing/v1\",\n",
    "    parameter_values={\"dataset\": \"gs://vtx-datasets-public/pytorch_tabular/synthetic/test.csv\"}\n",
    ")\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1037c22b-cd3f-4df2-8675-9590a98cb013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/datasets/_openml.py:421: UserWarning: Multiple active versions of the dataset matching the name credit-g exist. Versions may be fundamentally different, returning version 1.\n",
      "  \" {version}.\".format(name=name, version=res[0][\"version\"])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(\"credit-g\")  # get the credit data from OpenML\n",
    "X_raw = data.data  # features (pandas DataFrame)\n",
    "y_raw = data.target  # labels (pandas Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fa47630b-6b5d-40a0-baa6-c3b266ce8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw['target']=y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "867850b3-8dd4-4188-ba72-af220c8b74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc6811e-5dac-4e55-be9a-26189b3b6089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
