{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "There are different versions of the Demo, and while we were working on this version by doing online predictions, parallelism (using multiple cores/threads) to get jobs for 100k listings done in 25 minutes, we also used the batch prediction approach that was used for the final demo. **This notebook is for online predictions and parallelism.**"
      ],
      "metadata": {
        "id": "zSlVlZGA8OTc"
      },
      "id": "zSlVlZGA8OTc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocess\n",
        "\n",
        "\n",
        "*   Embeddings\n",
        "*   Questions and Answers for Category 1\n",
        "*   Questions and Answers for Category 2\n",
        "*   Questions and Answers for Category 3\n",
        "\n"
      ],
      "metadata": {
        "id": "ynmMlc1eF_0n"
      },
      "id": "ynmMlc1eF_0n"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "h7WeJI5QG34Q"
      },
      "id": "h7WeJI5QG34Q"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import tqdm\n",
        "import requests\n",
        "import vertexai\n",
        "import threading\n",
        "import concurrent\n",
        "import pandas as pd\n",
        "from urllib.parse import urlparse\n",
        "from google.cloud import bigquery, storage\n",
        "from google.cloud import discoveryengine_v1 as discoveryengine\n",
        "from vertexai.preview.generative_models import grounding, Tool\n",
        "from requests.exceptions import RequestException, MissingSchema\n",
        "from google.cloud import bigquery"
      ],
      "metadata": {
        "id": "QFdnWi6_9km7"
      },
      "id": "QFdnWi6_9km7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vertex AI Q&A Preload Preprocessing\n",
        "\n",
        "- While creating the questions there were 2 approaches, using online predictions and use multiple cores/threas to call the api multiple times once and in batches to speed up the process to generate content. It took 25 minutes to generate 100k Q&A,\n",
        "- While runing this demo we were also testing Batch predictions."
      ],
      "metadata": {
        "id": "pN_g9jsp9Wxc"
      },
      "id": "pN_g9jsp9Wxc"
    },
    {
      "cell_type": "code",
      "source": [
        "df = bigquery.Client(project=\"vtxdemos\").query(\"select * from `demos_us.home_and_living_listings_100k`\").to_dataframe()"
      ],
      "metadata": {
        "id": "oJJCPtQi9Zls"
      },
      "id": "oJJCPtQi9Zls",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Images from Listings Public URL and Store them in Google Cloud Storage\n",
        "- A Google Cloud Global Load Balancer + CDN enabled were used.\n",
        "- Cloudflare for TLS (HTTPS) we used."
      ],
      "metadata": {
        "id": "rG7a7kCr9dcD"
      },
      "id": "rG7a7kCr9dcD"
    },
    {
      "cell_type": "code",
      "source": [
        "public_gcs_link = []\n",
        "private_gcs_link = []\n",
        "public_cdn_link = []\n",
        "bucket_name = \"vtxdemos-fstoresearch-datasets\"  # Replace with your bucket name\n",
        "suffix = \"g-100k\"  # Replace with your suffix\n",
        "\n",
        "storage_client = storage.Client()\n",
        "bucket = storage_client.bucket(bucket_name)\n",
        "\n",
        "total_images = len(df)\n",
        "pbar = tqdm.tqdm(total=total_images, desc=\"Copying Images\")\n",
        "update_frequency = 1000  # Update tqdm every 1000 images\n",
        "\n",
        "def process_image(args):\n",
        "    index, row = args\n",
        "    url = row[\"image_url\"]\n",
        "    if url is None:\n",
        "        return None, None, None\n",
        "\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "        filename = os.path.basename(parsed_url.path)\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        blob = bucket.blob(f\"etsy-{suffix}/\" + filename)\n",
        "        blob.upload_from_string(response.content, content_type='image/jpeg')\n",
        "        public_gcs_url = blob.public_url\n",
        "        private_gcs_url = f\"gs://{bucket_name}/etsy-{suffix}/{filename}\"\n",
        "        public_cdn_url = f\"https://gcpetsy.sonrobots.net/etsy-{suffix}/{filename}\"  # Replace with your CDN URL\n",
        "        if index % update_frequency == 0:\n",
        "            pbar.update(update_frequency)  # Update tqdm less frequently\n",
        "        return public_gcs_url, private_gcs_url, public_cdn_url\n",
        "    except (requests.exceptions.RequestException, MissingSchema) as e:\n",
        "        print(f\"Error processing URL {url} at index {index}: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "with concurrent.futures.ThreadPoolExecutor(max_workers=40) as executor:\n",
        "    results = list(executor.map(process_image, df.iterrows()))\n",
        "\n",
        "for public_url, private_url, cdn_url in results:\n",
        "    public_gcs_link.append(public_url)\n",
        "    private_gcs_link.append(private_url)\n",
        "    public_cdn_link.append(cdn_url)\n",
        "\n",
        "df[\"public_gcs_link\"] = public_gcs_link\n",
        "df[\"private_gcs_link\"] = private_gcs_link\n",
        "df[\"public_cdn_link\"] = public_cdn_link\n",
        "\n",
        "pbar.close()"
      ],
      "metadata": {
        "id": "Biyaon9n9bPb"
      },
      "id": "Biyaon9n9bPb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Variables and Initialize"
      ],
      "metadata": {
        "id": "2-Cy2QGz9ndd"
      },
      "id": "2-Cy2QGz9ndd"
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = \"vtxdemos\"\n",
        "location = \"us-central1\""
      ],
      "metadata": {
        "id": "1oZh5zryG8KB"
      },
      "id": "1oZh5zryG8KB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vertexai.init(project=project_id, location=location)"
      ],
      "metadata": {
        "id": "wD3WgyznHLJJ"
      },
      "id": "wD3WgyznHLJJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_model_name = \"text-embedding-004\"\n",
        "emb_model = TextEmbeddingModel.from_pretrained(embeddings_model_name)"
      ],
      "metadata": {
        "id": "WGBeSaCOHdzq"
      },
      "id": "WGBeSaCOHdzq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = [\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "    SafetySetting(\n",
        "        category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
        "        threshold=SafetySetting.HarmBlockThreshold.OFF\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "sYbEoDF1J1lD"
      },
      "id": "sYbEoDF1J1lD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embeddings"
      ],
      "metadata": {
        "id": "RLCip_oCGV6M"
      },
      "id": "RLCip_oCGV6M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Getting 2k samples -> Materials only has ~1000 out of 2k.*"
      ],
      "metadata": {
        "id": "pCrru5J6GY9h"
      },
      "id": "pCrru5J6GY9h"
    },
    {
      "cell_type": "code",
      "id": "PVbMHW8v67KLTLbpQJ1GfumT",
      "metadata": {
        "tags": [],
        "id": "PVbMHW8v67KLTLbpQJ1GfumT"
      },
      "source": [
        "df = bigquery.Client(project=project_id).query(\"select * from `vtxdemos.demos_us.etsy_10k` limit 2000\").to_dataframe()\n",
        "df['combined_text'] = df['title'].fillna('None') + ' Description: ' + df['description'].fillna('None')  + ' Tags: ' + df['tags'].fillna('None')  + ' Attributes: ' + df['attributes'].fillna('None')\n",
        "df = df.drop([\"min_price_usd\", \"max_price_usd\", \"pct_discount\", \"variations\"], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Join with another table to get the CDN Link*"
      ],
      "metadata": {
        "id": "_18uxJqcGpIe"
      },
      "id": "_18uxJqcGpIe"
    },
    {
      "cell_type": "code",
      "source": [
        "# Join CDN -> New DF\n",
        "cdn_df = bigquery.Client(project=\"vtxdemos\").query(\"select * from `vtxdemos.demos_us.etsy-10k-full`\").to_dataframe()\n",
        "cdn_df[\"listing_id\"]=cdn_df.apply(lambda x: int(x[\"listing_id\"]), axis=1)\n",
        "_ = pd.merge(cdn_df[[\"listing_id\", \"public_cdn_link\"]], df, on=\"listing_id\", how=\"right\")\n",
        "_.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "RoRlsKirGl0T"
      },
      "id": "RoRlsKirGl0T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "star_time = time.time()\n",
        "def get_embedding(text: str):\n",
        "  inputs = [TextEmbeddingInput(text, \"SEMANTIC_SIMILARITY\")]\n",
        "  return emb_model.get_embeddings(inputs)[0].values\n",
        "\n",
        "emb_list = []\n",
        "listing_id = []\n",
        "error_count = 0\n",
        "\n",
        "for num, (index, row) in enumerate(_.iterrows()):\n",
        "  try:\n",
        "    listing_id.append(int(row[\"listing_id\"]))\n",
        "    emb_list.append(get_embedding(row[\"combined_text\"]))\n",
        "  except Exception as e:\n",
        "    print(f\"Error processing row {num}: {e}\")\n",
        "    error_count += 1\n",
        "    continue  # Skip to the next row\n",
        "\n",
        "print(time.time() - star_time)\n",
        "print(f\"Total errors encountered: {error_count}\")"
      ],
      "metadata": {
        "id": "cD-fZMB8HDn4"
      },
      "id": "cD-fZMB8HDn4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emb_df = pd.DataFrame({\"listing_id\": listing_id, \"embedding\": emb_list})\n",
        "emb_df.to_pickle(\"gs://vtxdemos-datasets-private/marketplace/embeddings.pkl\")"
      ],
      "metadata": {
        "id": "NH0A7TgZHwZ0"
      },
      "id": "NH0A7TgZHwZ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vector Search Using ScANN"
      ],
      "metadata": {
        "id": "8x4wPOUhIBjo"
      },
      "id": "8x4wPOUhIBjo"
    },
    {
      "cell_type": "code",
      "source": [
        "emb_df = pd.read_pickle(\"gs://vtxdemos-datasets-private/marketplace/embeddings.pkl\")"
      ],
      "metadata": {
        "id": "eoPAdBABjOWN"
      },
      "id": "eoPAdBABjOWN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vector Retrieval Engine Using ScANN\n",
        "\n",
        "import scann\n",
        "import numpy as np\n",
        "\n",
        "img = np.array([r[\"embedding\"] for i, r in emb_df.iterrows()])\n",
        "k = int(np.sqrt(emb_df.shape[0]))\n",
        "\n",
        "if int(k/20) < 1:\n",
        "    leave_search = 1\n",
        "else:\n",
        "    leave_search = int(k/20)\n",
        "\n",
        "searcher = scann.scann_ops_pybind.builder(img, num_neighbors=5, distance_measure=\"squared_l2\").tree(\n",
        "    num_leaves=k, num_leaves_to_search=int(int(k/20)), training_sample_size=emb_df.shape[0]).score_ah(\n",
        "    2, anisotropic_quantization_threshold=0.2).reorder(5).build()"
      ],
      "metadata": {
        "id": "0KaHoawzHYxm"
      },
      "id": "0KaHoawzHYxm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "texts = [\"Ceramic coffee mug with the words: &quot;Fabu...\"]\n",
        "inputs = [TextEmbeddingInput(text, \"RETRIEVAL_DOCUMENT\") for text in texts]\n",
        "embeddings = text_emb_model.get_embeddings(inputs)[0].values\n",
        "\n",
        "neighbors, distances = searcher.search(embeddings, final_num_neighbors=10)"
      ],
      "metadata": {
        "id": "KwwAeFWXbTAw"
      },
      "id": "KwwAeFWXbTAw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_extracted_data = _.loc[neighbors, :]\n",
        "all_extracted_data"
      ],
      "metadata": {
        "id": "5XOKppiMbdCQ"
      },
      "id": "5XOKppiMbdCQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category 1"
      ],
      "metadata": {
        "id": "jXlEz2y2ITIv"
      },
      "id": "jXlEz2y2ITIv"
    },
    {
      "cell_type": "code",
      "source": [
        "response_schema_cat1 = {\n",
        "    \"type\": \"OBJECT\",\n",
        "    \"properties\": {\n",
        "        \"questions_cat1\": {\n",
        "            \"type\": \"ARRAY\",\n",
        "            \"items\": {\n",
        "                \"type\": \"STRING\"\n",
        "            }\n",
        "        },\n",
        "        \"answers_cat1\": {\n",
        "            \"type\": \"ARRAY\",\n",
        "            \"items\": {\n",
        "                \"type\": \"STRING\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "# Questions Category 1\n",
        "system_instructions_cat_1 = \"\"\"\n",
        "You are a helpful product expert for Etsy, proactively prompting customers to discover the breadth of Etsy.\n",
        "Etsy is an e-commerce company with an emphasis on selling of handmade or vintage items and craft supplies.\n",
        "You will be provided product information and you need to generate exactly 12 questions using this product information.\n",
        "Questions should be interesting and exciting, but very short.\n",
        "\n",
        "<Instructions>\n",
        "  - 4 questions MUST be related to the product that customers usually ask about that product.\n",
        "      Questions should be directly relevant to the product, addressing typical customer inquiries about its features, specifications, or usage as suggested by product details.\n",
        "      Make questions very short and the created questions MUST have answers within product information.\n",
        "      Do not ask very explicit questions.\n",
        "  - Create 4 answers to these questions by looking up product information (context).\n",
        "</Instructions>\n",
        "\n",
        "<Rules>\n",
        "Be concise, clear and smart in your questions, this will be used as a buttonary recommendations for the customer.\n",
        "</Rules>\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "onW5qnSBIUIC"
      },
      "id": "onW5qnSBIUIC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_model = GenerativeModel(\n",
        "    \"gemini-1.5-flash-001\",\n",
        "    generation_config=GenerationConfig(temperature=1, response_mime_type=\"application/json\", response_schema=response_schema_cat1),\n",
        "    system_instruction=system_instructions_cat_1\n",
        ")"
      ],
      "metadata": {
        "id": "zeRRN31fJBU2"
      },
      "id": "zeRRN31fJBU2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gem_1(prompt: str):\n",
        "  try:\n",
        "    return json.loads(context_model.generate_content(prompt, safety_settings=safety_settings).text)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return {\"questions_cat1\": None, \"answers_cat1\": None}"
      ],
      "metadata": {
        "id": "QRcu7fYpJEBm"
      },
      "id": "QRcu7fYpJEBm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_cat_1 = []\n",
        "a_cat_1 = []\n",
        "listing_id_1 = []\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  listing_id_1.append(row[\"listing_id\"])\n",
        "  re = generate_gem_1(row[\"combined_text\"])\n",
        "  q_cat_1.append(re[\"questions_cat1\"])\n",
        "  a_cat_1.append(re[\"answers_cat1\"])"
      ],
      "metadata": {
        "id": "1W7B2FLjJlV8"
      },
      "id": "1W7B2FLjJlV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame({\"listing_id\": listing_id_1, \"q_cat_1\": q_cat_1, \"a_cat_1\": a_cat_1})\n",
        "df1.to_pickle(\"gs://vtxdemos-datasets-private/marketplace/cat1.pkl\")"
      ],
      "metadata": {
        "id": "hUvP9bJvJ3W5"
      },
      "id": "hUvP9bJvJ3W5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category 2"
      ],
      "metadata": {
        "id": "2DDcgfASJ-at"
      },
      "id": "2DDcgfASJ-at"
    },
    {
      "cell_type": "code",
      "source": [
        "response_schema_cat2 = {\n",
        "    \"type\": \"OBJECT\",\n",
        "    \"properties\": {\n",
        "        \"questions_cat2\": {\n",
        "            \"type\": \"ARRAY\",\n",
        "            \"items\": {\n",
        "                \"type\": \"STRING\"\n",
        "            },\n",
        "            \"min_items\": 4,\n",
        "            \"max_items\": 4\n",
        "        },\n",
        "        \"answers_cat2\": {\n",
        "            \"type\": \"ARRAY\",\n",
        "            \"items\": {\n",
        "                \"type\": \"STRING\"\n",
        "            },\n",
        "            \"min_items\": 4,\n",
        "            \"max_items\": 4\n",
        "        },\n",
        "    },\n",
        "    \"required\": [\"questions_cat2\", \"answers_cat2\"]\n",
        "}\n",
        "\n",
        "system_instructions_cat_2 = \"\"\"\n",
        "You are a helpful product expert for Etsy, proactively prompting customers to discover the breadth of Etsy.\n",
        "Etsy is an e-commerce company with an emphasis on selling of handmade or vintage items and craft supplies.\n",
        "You will be provided product information and you need to generate exactly 12 questions using this product information.\n",
        "Questions should be interesting and exciting, but very short.\n",
        "\n",
        "<Instructions>\n",
        "  - 4 questions should be associated with this product information but completely beyond the explicit product details, exploring potential applications, key features to consider, material properties, historical context, or broader industry standards\n",
        "      These questions should pique the customer's interest and encourage them to explore the product.\n",
        "      Should be very general questions for which you can search in Google Search to provide needed information\n",
        "      DO not ask questions about product availability or prices.\n",
        "  - Create 4 answers to these questions by using Google Search.\n",
        "</Instructions>\n",
        "\n",
        "<Rules>\n",
        "Be concise, clear and smart in your questions, this will be used as a buttonary recommendations for the customer.\n",
        "</Rules>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "tools = [\n",
        "    Tool.from_google_search_retrieval(\n",
        "        google_search_retrieval=grounding.GoogleSearchRetrieval()\n",
        "    ),\n",
        "]\n",
        "\n",
        "ground_model = GenerativeModel(\n",
        "    \"gemini-1.5-flash-001\",\n",
        "    generation_config=GenerationConfig(\n",
        "        temperature=1.1,\n",
        "        response_mime_type=\"application/json\",\n",
        "        response_schema=response_schema_cat2,\n",
        "        max_output_tokens=4000),\n",
        "    tools=tools,\n",
        "    system_instruction=system_instructions_cat_2\n",
        ")"
      ],
      "metadata": {
        "id": "P3CS3eY7J_jn"
      },
      "id": "P3CS3eY7J_jn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_gem_2(prompt: str):\n",
        "  try:\n",
        "    return json.loads(ground_model.generate_content(prompt, safety_settings=safety_settings).text)\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    return {\"questions_cat2\": None, \"answers_cat2\": None}"
      ],
      "metadata": {
        "id": "1VnaqBOFKPss"
      },
      "id": "1VnaqBOFKPss",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "q_cat_2 = []\n",
        "a_cat_2 = []\n",
        "listing_id_1 = []\n",
        "\n",
        "for index, row in _.iterrows():\n",
        "  listing_id_1.append(row[\"listing_id\"])\n",
        "  re = generate_gem_2(row[\"combined_text\"])\n",
        "  q_cat_2.append(re[\"questions_cat2\"])\n",
        "  a_cat_2.append(re[\"answers_cat2\"])"
      ],
      "metadata": {
        "id": "SjMMC_HKKRyJ"
      },
      "id": "SjMMC_HKKRyJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame({\"listing_id\": listing_id_1, \"q_cat_2\": q_cat_2, \"a_cat_2\": a_cat_2})\n",
        "df2.to_pickle(\"gs://vtxdemos-datasets-private/marketplace/cat2.pkl\")"
      ],
      "metadata": {
        "id": "doYL71eaKXkD"
      },
      "id": "doYL71eaKXkD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category 3"
      ],
      "metadata": {
        "id": "LR3PCcUmKgDl"
      },
      "id": "LR3PCcUmKgDl"
    },
    {
      "cell_type": "code",
      "source": [
        "_.reset_index(inplace=True)"
      ],
      "metadata": {
        "id": "2-FCQuBwcx2G"
      },
      "id": "2-FCQuBwcx2G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Utility Class\n",
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "model_name = \"gemini-1.5-flash-001\"\n",
        "embeddings_model_name = \"text-embedding-004\"\n",
        "\n",
        "model = GenerativeModel(\n",
        "    model_name=model_name,\n",
        "    generation_config={\"temperature\": 1.1}\n",
        ")\n",
        "\n",
        "text_emb_model = TextEmbeddingModel.from_pretrained(embeddings_model_name)\n",
        "\n",
        "class Gemini:\n",
        "    def __init__(self):\n",
        "        self.retrieval_results = None\n",
        "        self.dataframe = None\n",
        "        self.response_schema = {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"questions\": {\n",
        "                    \"type\": \"array\",\n",
        "                    \"items\": {\n",
        "                        \"type\": \"string\"\n",
        "                    },\n",
        "                    \"min_items\": \"4\"\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "        self.prompt_template_generate_questions = \"\"\"\n",
        "              You are an expert in helping Etsy customers find products that complement their current selections.\n",
        "              Etsy specializes in handmade, vintage items, and craft supplies. Given the provided product information:\n",
        "\n",
        "              your task is to create 4 questions that would lead to the discovery of complementary products.\n",
        "\n",
        "              <Instructions>\n",
        "            - Generate 4 questions that would help a customer find products that pair well with this item.\n",
        "              For example, if the product is a red shirt, a complementary question might be,\n",
        "              \"What pants would match with this shirt?\"\n",
        "              For example, if the product is a pair of shoes, a complementary question might be,\n",
        "              \"What socks would go well with these shoes?\"\n",
        "            - List the questions in plain text without headers, numbers, or hyphens.\n",
        "            </Instructions>\n",
        "            \"\"\"\n",
        "\n",
        "        self.rephraser_prompt_cat3 = \"\"\"\n",
        "        Your task is to rephrase the user's question {question_cat3} to explicitly mention what product it is referring to.\n",
        "        Use the information provided in the product information {product_details}. The result should be a single line question.\n",
        "        \"\"\"\n",
        "\n",
        "        self.prompt_after_rag = \"\"\"\n",
        "        You are Etsy product expert. You are helping users explore the breadth of Etsy. Your task is to answer to user's question: {question_cat3}.\n",
        "\n",
        "        - Your goal is to recommend matching products: {matching_products}\n",
        "        - Use ONLY the matching products to answer the question\n",
        "        - Customer is currently looking at product mentioned in {product_details}. Keep this context in mind\n",
        "        - If there is no matching products, respond with a generic message\n",
        "        - Condense the response into a clear and concise summary, using bullet points whenever appropriate.\n",
        "        - Be kind always and reply as descriptive as needed\n",
        "        \"\"\"\n",
        "\n",
        "    def generate_questions(self, listing_info):\n",
        "        try:\n",
        "            response = model.generate_content(\n",
        "                [self.prompt_template_generate_questions, \"\\n\\n<Product Information>\\n\", listing_info],\n",
        "                generation_config=GenerationConfig(\n",
        "                    response_mime_type=\"application/json\", response_schema=self.response_schema, temperature=1.1\n",
        "                ),\n",
        "                safety_settings=safety_settings\n",
        "            )\n",
        "            return response\n",
        "        except:\n",
        "            print(\"Error In generate_questions\")\n",
        "            return 'error'\n",
        "\n",
        "    def generate_answers(self, question_cat3, matching_products, product_details):\n",
        "      try:\n",
        "        prompt = [self.prompt_after_rag, f\"question_cat3: {question_cat3}\" , f\"matching_products: {matching_products}\\n\", f\"product_details: {product_details}\"]\n",
        "        response = model.generate_content(prompt, safety_settings=safety_settings)\n",
        "        return response\n",
        "      except:\n",
        "        print(\"Error In generate_answers\")\n",
        "        return 'error'\n",
        "\n",
        "    def search_for_item_information(self, query):\n",
        "        texts = [query]\n",
        "        inputs = [TextEmbeddingInput(text, \"RETRIEVAL_DOCUMENT\") for text in texts]\n",
        "        embeddings = text_emb_model.get_embeddings(inputs)[0].values\n",
        "\n",
        "        neighbors, distances = searcher.search(embeddings, final_num_neighbors=10)\n",
        "\n",
        "        all_extracted_data = _.loc[neighbors, :]\n",
        "        self.dataframe = pd.DataFrame(all_extracted_data)\n",
        "\n",
        "    def run(self, content):\n",
        "        recommendations_list = []\n",
        "        try:\n",
        "            re = self.generate_questions(content).text\n",
        "        except:\n",
        "            re = 'error'\n",
        "            print(\"Error In run\")\n",
        "        if re != \"error\":\n",
        "            question_cat3 = json.loads(re)[\"questions\"]\n",
        "            for num, question in enumerate(question_cat3):\n",
        "                recommendations = {\n",
        "                    \"rephrased_question\": \"\",\n",
        "                    \"answer\": \"\",\n",
        "                    \"rec_titles\": [],\n",
        "                    \"rec_prices\": [],\n",
        "                    \"rec_descriptions\": [],\n",
        "                    \"tags\": [],\n",
        "                    \"materials\": [],\n",
        "                    \"attributes\": [],\n",
        "                    \"category\": [],\n",
        "                    \"combined_text\": [],\n",
        "                    \"public_cdn_link\": [],\n",
        "                }\n",
        "\n",
        "                rephraser_contents_cat3 = [\n",
        "                    self.rephraser_prompt_cat3,\n",
        "                    question,\n",
        "                    content,\n",
        "                ]\n",
        "                #rephrased_query = model.generate_content(rephraser_contents_cat3, safety_settings=safety_settings, generation_config={\"temperature\": 1.1}).text\n",
        "                self.search_for_item_information(question)\n",
        "                answer = self.generate_answers(question, self.dataframe, content).text\n",
        "\n",
        "                recommendations[\"rephrased_question\"] = question\n",
        "                recommendations[\"answer\"] = answer\n",
        "\n",
        "                # Optimization: Access DataFrame rows only once\n",
        "                recs = [self.dataframe.iloc[i] for i in range(5)] # Get first 5 recommendations\n",
        "\n",
        "                for rec in recs:\n",
        "                    recommendations[\"rec_titles\"].append(rec[\"title\"])\n",
        "                    recommendations[\"rec_prices\"].append(int(rec[\"price_usd\"])) # Convert to native Python int\n",
        "                    recommendations[\"rec_descriptions\"].append(rec[\"description\"])\n",
        "                    recommendations[\"tags\"].append(rec[\"tags\"])\n",
        "                    recommendations[\"materials\"].append(rec[\"materials\"])\n",
        "                    recommendations[\"attributes\"].append(rec[\"attributes\"])\n",
        "                    recommendations[\"category\"].append(rec[\"category\"])\n",
        "                    recommendations[\"combined_text\"].append(rec[\"combined_text\"])\n",
        "                    recommendations[\"public_cdn_link\"].append(rec[\"public_cdn_link\"])\n",
        "\n",
        "                recommendations_list.append(recommendations)\n",
        "\n",
        "        return recommendations_list"
      ],
      "metadata": {
        "id": "kiSuPlduKhUg"
      },
      "id": "kiSuPlduKhUg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = Gemini()"
      ],
      "metadata": {
        "id": "lnpR-8fBOBPC"
      },
      "id": "lnpR-8fBOBPC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "error_count = 0\n",
        "error_listings = []\n",
        "listing_ids = []\n",
        "cat_3_questions_list = []\n",
        "\n",
        "for num, (index, row) in enumerate(_.iterrows()):  # Iterate through the entire DataFrame\n",
        "    try:\n",
        "        print(num+1)\n",
        "        results = g.run(row[\"combined_text\"])\n",
        "        print(results)\n",
        "        print(results)\n",
        "        if results != 'error':  # Check if g.run returned an error\n",
        "            cat_3_questions = []\n",
        "            for result in results:  # Iterate through the dictionaries in the output\n",
        "                cat_3_questions.append(json.dumps(result)) # Convert dictionary to JSON string\n",
        "            listing_ids.append(str(row['listing_id']))  # Convert listing_id to string\n",
        "            cat_3_questions_list.append(cat_3_questions)\n",
        "        else:\n",
        "            error_count += 1\n",
        "            error_listings.append(str(row['listing_id']))  # Convert listing_id to string\n",
        "            print(f\"Error occurred for listing_id: {row['listing_id']}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        error_count += 1\n",
        "        error_listings.append(str(row['listing_id']))  # Convert listing_id to string\n",
        "        print(f\"Error occurred for listing_id: {row['listing_id']}: {e}\")\n",
        "\n",
        "final_df = pd.DataFrame({\"listing_id\": listing_ids, \"cat_3_questions\": cat_3_questions_list})  # Create the new DataFrame\n",
        "\n",
        "print(f\"Total errors encountered: {error_count}\")\n",
        "print(f\"Listings with errors: {error_listings}\")"
      ],
      "metadata": {
        "id": "lvEGevWtOGon"
      },
      "id": "lvEGevWtOGon",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_pickle('gs://vtxdemos-datasets-private/marketplace/cat3.pkl')"
      ],
      "metadata": {
        "id": "qIuZAgEaOR3b"
      },
      "id": "qIuZAgEaOR3b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Titles"
      ],
      "metadata": {
        "id": "pg37VeLbPGfH"
      },
      "id": "pg37VeLbPGfH"
    },
    {
      "cell_type": "code",
      "source": [
        "generate_title_prompt = '''Based on the product details attached, generate a concise and engaging product title that highlights the key attributes, unique features, and selling points of the item.\n",
        "Focus on creating a title that will attract potential buyers and clearly communicate the most important details about the product.\n",
        "\n",
        "Return only one title that is less than 20 words and is in plain text. Return just the title and nothing else.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "e76rdNmFPHrF"
      },
      "id": "e76rdNmFPHrF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_ai_model=GenerativeModel(model_name=\"gemini-1.5-flash-001\",generation_config={\"temperature\": 1.1})"
      ],
      "metadata": {
        "id": "wIPq5L5HPaPP"
      },
      "id": "wIPq5L5HPaPP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_titles = []\n",
        "for i in range(len(df)):\n",
        "  product_details = df['combined_text'][i]\n",
        "  contents = [\n",
        "    generate_title_prompt,\n",
        "    product_details,\n",
        "  ]\n",
        "\n",
        "  response = gen_ai_model.generate_content(contents, stream=False,\n",
        "                                           safety_settings=safety_settings)\n",
        "  generated_titles.append(response.text)"
      ],
      "metadata": {
        "id": "rsEYCLBwPgWN"
      },
      "id": "rsEYCLBwPgWN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['generated_titles'] = generated_titles\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3kgJRvObPntj"
      },
      "id": "3kgJRvObPntj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Description Trimm"
      ],
      "metadata": {
        "id": "SD_rHdWzQB0P"
      },
      "id": "SD_rHdWzQB0P"
    },
    {
      "cell_type": "code",
      "source": [
        "generate_description_prompt = '''Based on the product details provided, generate a concise yet informative description that highlights the key features, benefits, and unique aspects of the item.\n",
        "Ensure the description is clear, accurate, and includes as much relevant information as possible while remaining easy to understand.\n",
        "\n",
        "Return only one description that fits within a single paragraph and is in plain text. Return just the description and nothing else.\n",
        "'''"
      ],
      "metadata": {
        "id": "-lThkLC0QDOK"
      },
      "id": "-lThkLC0QDOK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_descriptions = []\n",
        "for i in range(len(df)):\n",
        "  product_details = df['combined_text'][i]\n",
        "  contents = [\n",
        "    generate_description_prompt,\n",
        "    product_details,\n",
        "  ]\n",
        "  response = gen_ai_model.generate_content(contents, stream=False,\n",
        "                                           safety_settings=safety_settings)\n",
        "  generated_descriptions.append(response.text)"
      ],
      "metadata": {
        "id": "nVljiN7PQQem"
      },
      "id": "nVljiN7PQQem",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['generated_descriptions'] = generated_descriptions\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3yUl4vcVQSeN"
      },
      "id": "3yUl4vcVQSeN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Query Recommendations"
      ],
      "metadata": {
        "id": "jrCqKmtAQcy9"
      },
      "id": "jrCqKmtAQcy9"
    },
    {
      "cell_type": "code",
      "source": [
        "generate_description_prompt = '''You are a ux developer expert, and you tasked to build\n",
        "a listing text recommendation system for a product listing.\n",
        "\n",
        "The text recommendation will be based on the product title and description. Be concise and short\n",
        "since the text will be shown in the search text window for the user.\n",
        "\n",
        "The output should be short and concise no more than 5 words to represent the listing, remember is the query recommendation.\n",
        "\n",
        "Constraints:\n",
        "- Avoid any markdown, asterisk or any number symbols, punctuation or special characters.\n",
        "- Output (only 1) is in plain text.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "Rhpbcw81QeuR"
      },
      "id": "Rhpbcw81QeuR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_descriptions = []\n",
        "for i in range(len(df)):\n",
        "  product_details = df['combined_text'][i]\n",
        "  contents = [\n",
        "    generate_description_prompt,\n",
        "    product_details,\n",
        "  ]\n",
        "  response = gen_ai_model.generate_content(contents, stream=False,\n",
        "                                           safety_settings=safety_settings)\n",
        "  generated_descriptions.append(response.text)"
      ],
      "metadata": {
        "id": "9OcVhtjBQnqj"
      },
      "id": "9OcVhtjBQnqj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['generated_queries'] = generated_descriptions\n",
        "df.head()"
      ],
      "metadata": {
        "id": "4kn6UGbTQqbp"
      },
      "id": "4kn6UGbTQqbp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "name": "etsy-preprocessing-v1_1_2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}