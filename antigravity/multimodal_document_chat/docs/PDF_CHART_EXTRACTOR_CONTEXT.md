# PDF Chart Extractor - FULL PROJECT CONTEXT

This is a comprehensive reconstruction guide. It includes all root files, backend logic, and frontend components.

## 1. Project Documentation & Findings

### OPTIMIZATION_FINDINGS.md
```markdown
# PDF Chart Extractor Optimization Findings

This document details the performance optimization journey for the **ChartVision Pro** PDF extraction pipeline.

## üöÄ Executive Summary

We achieved a **~2.2x speedup** (from ~7 mins down to ~3 mins) for a 41-page complex PDF by moving from sequential batch processing to a fully parallel, non-blocking asynchronous architecture.

| Metric | Initial State | Optimized State | Improvement |
| :--- | :--- | :--- | :--- |
| **Total Time (41 pages)** | 6m 54s | 3m 02s | **~56% Faster** |
| **Throughput** | ~6 pages/min | ~13.5 pages/min | **2.2x Throughput** |
| **Concurrency Model** | Sequential Batches (Wait-for-all) | Semaphore Queue (Continuous) | **Zero Idle Time** |
| **I/O Handling** | Blocking (Main Thread) | Non-Blocking (Executor Threads) | **True Parallelism** |

---

## üõ†Ô∏è Optimization Strategies Implemented

### 1. Increased Concurrency Limits
*   **Change:** Updated the `limit` variable in `backend/main.py` based on the specific Gemini model being used.
*   **Logic:**
    *   **Gemini 3.0 Flash:** Increased from `5` to **`25`** concurrent requests.
    *   **Gemini 3.0 Pro:** Kept at a conservative `8`.

### 2. Parallel Non-Blocking I/O
*   **Problem:** CPU-bound tasks like `PIL.ImageDraw` and Network I/O (GCS Uploads) were blocking the main `async` loop.
*   **Solution:** Wrapped these blocking calls in `loop.run_in_executor`.

### 3. Semaphore-based Task Queue
*   **Problem:** Sequential batches waited for the slowest page.
*   **Solution:** Switched to `asyncio.Semaphore(limit)` for a continuous task queue.
```

### README.md
```markdown
# üìä ChartVision Pro: Advanced Agentic PDF Intelligence

[![Google Cloud](https://img.shields.io/badge/Google_Cloud-4285F4?style=for-the-badge&logo=google-cloud&logoColor=white)](https://cloud.google.com/)
[![Gemini](https://img.shields.io/badge/Gemini_3_Pro-8E75B2?style=for-the-badge&logo=google-gemini&logoColor=white)](https://deepmind.google/technologies/gemini/)
[![FastAPI](https://img.shields.io/badge/FastAPI-005571?style=for-the-badge&logo=fastapi)](https://fastapi.tiangolo.com/)
[![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=nextdotjs&logoColor=white)](https://nextjs.org/)

**ChartVision Pro** is a high-performance agentic workflow designed to transform unstructured PDF documents into structured, actionable intelligence. Leveraging **Google Gemini 3 Pro** (Global) and the **Google Agent Development Kit (ADK)**, it automates the identification, extraction, and synthesis of charts, tables, and complex diagrams with extreme precision.

![Dashboard Preview](screenshots/dashboard.png)

---

## ‚ú® Key Features

- **üöÄ Parallel Agentic Execution**: Spawns independent extraction agents for every PDF page.
- **üåç Gemini 3.0 Support**: Fully configured for Gemini 3 Pro/Flash in the Global region via Vertex AI.
- **‚ö° High-Throughput Engine**: Supports up to 200 concurrent page extractions for Flash models.
- **üé® Modern Multimodal Extraction**: Utilizes Gemini's deep reasoning to identify axes, legends, and data points.
- **üìç Real-time Bounding Boxes**: Generates pixel-perfect visual annotations.
- **üíé Glassmorphism UX**: A premium Next.js dashboard.
- **üîí Secure Enterprise Access**: Identity-Aware Proxy (IAP) ready.

---

## üèóÔ∏è System Architecture

### 1. Logical Agentic Workflow
```mermaid
graph TD
    A[PDF Upload] --> B[Logical Page Splitting]
    B --> C{Parallel Extraction Pipeline}
    
    subgraph "Agent Orchestration"
    C --> D1[Page 1 Agent]
    C --> D2[Page 2 Agent]
    C --> Dn[Page n Agent]
    end
    
    D1 & D2 & Dn --> E[Quality Evaluation Agent]
    E --> F[Visual Annotation Engine]
    
    subgraph "Persistence Layer"
        F --> G[GCS Image Storage]
        F --> H[BigQuery Table Sync]
    end
    
    G & H --> I[Interactive React Dashboard]
```

### 2. Cloud Infrastructure
```mermaid
graph TD
    User((User)) -->|HTTPS / Custom Domain| GLB[Global External Load Balancer]
    GLB -->|Auth Check| IAP[Identity-Aware Proxy]
    
    subgraph "Google Cloud Run"
        IAP -->|Authorized| FE[Frontend Service<br/>Next.js]
        IAP -->|Authorized| BE[Backend Service<br/>FastAPI]
    end
    
    FE -->|API Calls /extract| BE
    
    BE -->|1. Split PDF| B[Logical Page Splitting]
    B --> C{Parallel Extraction Pipeline}
    
    subgraph "Agent Orchestration"
        C --> D1[Page 1 Agent]
        C --> D2[Page 2 Agent]
        C --> Dn[Page n Agent]
        D1 & D2 & Dn -.->|Vertex AI (Global)| Gemini[Gemini 3 Pro / Flash]
    end
```

---

## üõ†Ô∏è Configuration

To use **Gemini 3.0** on Vertex AI, the following environment variables are required (and pre-configured in this repo):

```env
GOOGLE_GENAI_USE_VERTEXAI=True
GOOGLE_CLOUD_PROJECT=your-project-id
GOOGLE_CLOUD_LOCATION=global
```

**Note:** Gemini 3 Pro/Flash Preview models require the `global` location and the full resource path format:
`projects/{project}/locations/global/publishers/google/models/gemini-3-pro-preview`

---

## üöÄ Quick Start

### 1. Backend Setup
```bash
cd backend
# Install dependencies
python3 -m pip install -r requirements.txt
# Run server
python3 main.py
```
*Backend runs on `http://localhost:8000`*

### 2. Frontend Setup
```bash
cd frontend
# Install dependencies
npm install
# Start development server
npm run dev
```
*Frontend runs on `http://localhost:3000`*

---

## ‚òÅÔ∏è Cloud Deployment

This repository is ready for Google Cloud Run.

### 1. Backend Deployment
```bash
gcloud run deploy pdf-extractor-backend \
    --source backend \
    --region us-central1 \
    --memory 4Gi \
    --cpu 2 \
    --set-env-vars="GOOGLE_CLOUD_PROJECT=your-project,GOOGLE_CLOUD_LOCATION=global,GOOGLE_GENAI_USE_VERTEXAI=True"
```

### 2. Frontend Deployment
```bash
gcloud run deploy pdf-extractor-frontend \
    --source frontend \
    --region us-central1
```

*Note: Ensure your Service Account has access to Vertex AI.*

---

*Built with ‚ù§Ô∏è using Google Vertex AI & Gemini.*
```

## 2. Root Entry Points & Utilities

### agent.py
```python
import asyncio
import os
import sys
import json
import logging
from typing import List, Any
from copy import deepcopy

# Add project root to path
sys.path.append(os.getcwd())

from pydantic import BaseModel, Field
from google.adk.agents import Agent, ParallelAgent
from google.adk.models import LlmRequest
from google.adk.agents.callback_context import CallbackContext
from google.genai import types
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.adk.tools import AgentTool

# Import utils
from pdf_chart_extractor_workflow.utils import (
    split_pdf_logically, 
    insert_into_bigquery, 
    upload_to_gcs, 
    draw_bounding_boxes
)

# Environment
os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "True"
os.environ["GOOGLE_CLOUD_PROJECT"] = "vtxdemos"
os.environ["GOOGLE_CLOUD_LOCATION"] = "global"

# Logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Workflow")

# --- Schemas ---

class BoundingBox(BaseModel):
    ymin: float = Field(description="Normalized Y coordinate (0-1000) for top")
    xmin: float = Field(description="Normalized X coordinate (0-1000) for left")
    ymax: float = Field(description="Normalized Y coordinate (0-1000) for bottom")
    xmax: float = Field(description="Normalized X coordinate (0-1000) for right")

class ChartObject(BaseModel):
    label: str = Field(description="Label or name of the object identified inside the chart")
    text_confidence: float = Field(description="Confidence score for the text/label extracted (0.0 to 1.0)")
    bounding_box: BoundingBox = Field(description="Bounding box of this specific object within the chart")

class ChartData(BaseModel):
    headers: List[str] = Field(description="Column headers of the extracted table")
    rows: List[List[Any]] = Field(description="Data rows corresponding to the headers")

class ChartExtraction(BaseModel):
    page_number: int = Field(description="Page number where the chart was found")
    chart_bounding_box: BoundingBox = Field(description="Bounding box of the entire chart/diagram on the PDF page")
    description: str = Field(description="A very detailed, precise, and lengthy description of the chart/diagram.")
    confidence: float = Field(description="Confidence level of the overall chart extraction (0.0 to 1.0)")
    objects_inside: List[ChartObject] = Field(description="List of distinct objects found inside the chart with their bounding boxes and label confidence")
    extracted_data: ChartData = Field(description="Structured tabular data extracted from the chart")

class TableExtraction(BaseModel):
    page_number: int = Field(description="Page number where the table was found")
    table_bounding_box: BoundingBox = Field(description="Bounding box of the table on the PDF page")
    description: str = Field(description="A detailed description of the table's purpose and content.")
    confidence: float = Field(description="Confidence level of the extraction (0.0 to 1.0)")
    extracted_data: ChartData = Field(description="Structured tabular data")

class PdfExtractionResult(BaseModel):
    charts: List[ChartExtraction] = Field(description="List of all charts/diagrams found in the PDF")
    tables: List[TableExtraction] = Field(description="List of all standalone tables found in the PDF")

# --- Globals ---
CURRENT_PDF_PATH = "example_pdf.pdf"
AGGREGATED_DATA = {"charts": [], "tables": []}

# --- Callbacks ---

def pdf_injection_callback(callback_context: CallbackContext, llm_request: LlmRequest):
    """Injects the PDF file into the prompt."""
    try:
        if os.path.exists(CURRENT_PDF_PATH):
            with open(CURRENT_PDF_PATH, "rb") as f:
                pdf_bytes = f.read()
            pdf_part = types.Part.from_bytes(data=pdf_bytes, mime_type="application/pdf")
            llm_request.contents[-1].parts.append(pdf_part)
    except Exception as e:
        logger.error(f"Error injecting PDF: {e}")

# --- Tool Definitions ---

def store_in_bq_tool():
    """Stores the aggregated data from the workflow into BigQuery in a flattened format."""
    try:
        data = AGGREGATED_DATA
        rows_to_insert = []
        
        def flatten_item(item, item_type, idx):
            item_dict = item if isinstance(item, dict) else item.dict()
            page = item_dict.get('page_number')
            desc = item_dict.get('description')
            conf = item_dict.get('confidence')
            
            # Get data
            ext_data = item_dict.get('extracted_data', {})
            # Handle if it's a dict or object
            if hasattr(ext_data, 'dict'): ext_data = ext_data.dict()
            
            headers = ext_data.get('headers', [])
            data_rows = ext_data.get('rows', [])
            
            element_id = f"{item_type}_{page}_{idx}"
            
            for r_idx, row_vals in enumerate(data_rows):
                for c_idx, cell_val in enumerate(row_vals):
                    # Safety check for column bounds
                    col_name = headers[c_idx] if c_idx < len(headers) else f"Col_{c_idx}"
                    
                    bq_row = {
                        "page": page,
                        "type": item_type,
                        "element_id": element_id,
                        "description": desc,
                        "confidence": conf,
                        "row_index": r_idx,
                        "column_name": str(col_name),
                        "cell_value": str(cell_val)
                    }
                    rows_to_insert.append(bq_row)

        for i, chart in enumerate(data.get('charts', [])):
            flatten_item(chart, "CHART", i)
            
        for i, table in enumerate(data.get('tables', [])):
            flatten_item(table, "TABLE", i)
            
        if not rows_to_insert:
            return "No data found in global state to store."
            
        insert_into_bigquery(rows_to_insert, "vtxdemos", "esg_demo_data", "pdf_extractions")
        return f"Successfully stored {len(rows_to_insert)} flattened cells in BigQuery."
    except Exception as e:
        logger.exception("BQ Store Failed")
        return f"Failed to store data: {e}"

def visualize_tool():
    """Visualizes the aggregated data by drawing bounding boxes and uploading to GCS."""
    try:
        data = AGGREGATED_DATA
        
        # Reconstruct objects for the util
        items = []
        for c in data.get('charts', []):
            items.append(ChartExtraction(**c))
        for t in data.get('tables', []):
            items.append(TableExtraction(**t))
            
        if not items:
            return "No items to visualize."

        output_files = draw_bounding_boxes(CURRENT_PDF_PATH, items, ".")
        
        results = []
        for fpath in output_files:
            fname = os.path.basename(fpath)
            # Add random suffix to avoid collision/caching issues
            blob_name = f"annotated_{os.urandom(4).hex()}_{fname}"
            upload_to_gcs(fpath, "vtxdemos-staging", blob_name)
            results.append(f"gs://vtxdemos-staging/{blob_name}")
            
        return f"Visualization created and uploaded: {', '.join(results)}"
    except Exception as e:
        logger.exception("Visualization Failed")
        return f"Visualization error: {e}"

# --- Agent Factories & Definitions ---

def create_page_extractor(page_num: int) -> Agent:
    return Agent(
        name=f"extractor_page_{page_num}",
        model="gemini-2.5-pro",
        description=f"Extracts charts and tables specifically from page {page_num}.",
        instruction=f"""
        Analyze the provided PDF file.
        FOCUS ONLY ON PAGE {page_num}. Do not extract content from other pages.
        1. Identify charts, diagrams, and standalone tables on Page {page_num}.
        2. Extract structured data, bounding boxes, and object details.
        3. Provide confidence scores for the chart/table and for individual text labels.
        4. Return the result strictly matching the provided schema.
        """,
        output_schema=PdfExtractionResult,
        before_model_callback=pdf_injection_callback
    )

evaluator_agent = Agent(
    name="evaluator_agent",
    model="gemini-2.5-flash",
    description="Evaluates the quality and confidence of extracted data.",
    instruction="""
    You are a Quality Assurance AI.
    Review the provided JSON extraction results.
    1. Check if confidence scores are acceptable (> 0.8).
    2. Verify that bounding boxes are normalized (0-1000).
    3. Summarize the quality of the extraction.
    Return a brief approval or list of warnings.
    """
)

storage_agent = Agent(
    name="storage_agent",
    model="gemini-2.5-flash",
    description="Stores extracted data into BigQuery.",
    instruction="""
    The extraction data is already prepared.
    Use the `store_in_bq_tool` to save it to BigQuery.
    Do not pass any arguments to the tool.
    """,
    tools=[store_in_bq_tool]
)

visualization_agent = Agent(
    name="visualization_agent",
    model="gemini-2.5-flash",
    description="Visualizes bounding boxes and uploads to GCS.",
    instruction="""
    The extraction data is already prepared.
    Use the `visualize_tool` to create and upload the annotated images.
    Do not pass any arguments to the tool.
    """,
    tools=[visualize_tool]
)

# --- Workflow ---

async def main():
    global AGGREGATED_DATA
    if not os.path.exists(CURRENT_PDF_PATH):
        print(f"File {CURRENT_PDF_PATH} not found.")
        sys.exit(1)

    print("--- 1. Splitting PDF Logically ---")
    pages = split_pdf_logically(CURRENT_PDF_PATH)
    print(f"Identified {len(pages)} pages to process.")

    print("\n--- 2. Parallel Extraction ---")
    sub_agents = [create_page_extractor(p) for p in pages]
    parallel_extractor = ParallelAgent(
        name="parallel_extractor",
        sub_agents=sub_agents
    )

    APP_NAME = "PdfWorkflow"
    USER_ID = "user"
    SESSION_ID = "workflow_session"
    
    session_service = InMemorySessionService()
    await session_service.create_session(app_name=APP_NAME, user_id=USER_ID, session_id=SESSION_ID, state={})
    
    runner = Runner(agent=parallel_extractor, app_name=APP_NAME, session_service=session_service)
    
    content = types.Content(role='user', parts=[types.Part(text="Extract charts and tables from all pages.")])
    
    # Run Parallel Extraction
    try:
        async for event in runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=content):
            if event.is_final_response() and event.content and event.content.parts:
                text = event.content.parts[0].text
                try:
                    data = json.loads(text)
                    if "charts" in data:
                        AGGREGATED_DATA["charts"].extend(data["charts"])
                    if "tables" in data:
                        AGGREGATED_DATA["tables"].extend(data["tables"])
                except json.JSONDecodeError:
                    pass
    except Exception as e:
        logger.error(f"Error in parallel extraction: {e}")

    print(f"\nAggregated {len(AGGREGATED_DATA['charts'])} charts and {len(AGGREGATED_DATA['tables'])} tables.")
    
    if not AGGREGATED_DATA["charts"] and not AGGREGATED_DATA["tables"]:
        print("No data extracted. Aborting subsequent steps.")
        return

    json_str = json.dumps(AGGREGATED_DATA) # Still used for evaluator prompt
    
    print("\n--- 3. Evaluation ---")
    eval_runner = Runner(agent=evaluator_agent, app_name=APP_NAME, session_service=session_service)
    eval_content = types.Content(role='user', parts=[types.Part(text=f"Evaluate this extraction: {json_str}")])
    
    try:
        async for event in eval_runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=eval_content):
            if event.is_final_response() and event.content:
                 print("Evaluation Result:", event.content.parts[0].text)
    except Exception as e:
        logger.error(f"Error in evaluation: {e}")

    print("\n--- 4. Storage ---")
    store_runner = Runner(agent=storage_agent, app_name=APP_NAME, session_service=session_service)
    store_content = types.Content(role='user', parts=[types.Part(text="Store the extracted data.")])
    
    try:
        async for event in store_runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=store_content):
            if event.is_final_response() and event.content:
                 print("Storage Result:", event.content.parts[0].text)
    except Exception as e:
        logger.error(f"Error in storage: {e}")

    print("\n--- 5. Visualization ---")
    vis_runner = Runner(agent=visualization_agent, app_name=APP_NAME, session_service=session_service)
    vis_content = types.Content(role='user', parts=[types.Part(text="Visualize the data.")])
    
    try:
        async for event in vis_runner.run_async(user_id=USER_ID, session_id=SESSION_ID, new_message=vis_content):
            if event.is_final_response() and event.content:
                 print("Visualization Result:", event.content.parts[0].text)
    except Exception as e:
        logger.error(f"Error in visualization: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

### utils.py (Root)
```python
import os
import json
import logging
from typing import List, Dict, Any, Tuple
from google.cloud import bigquery
from google.cloud import storage
from google.api_core.exceptions import NotFound
from PIL import Image, ImageDraw

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def get_pdf_page_count(pdf_path: str) -> int:
    """
    Returns the number of pages in the PDF.
    HARDCODED for this environment/example: 3 pages.
    """
    return 3

def split_pdf_logically(pdf_path: str) -> List[int]:
    """
    Returns a list of page numbers to process.
    """
    count = get_pdf_page_count(pdf_path)
    return list(range(1, count + 1))

def insert_into_bigquery(data: Dict[str, Any], project_id: str, dataset_id: str, table_id: str):
    """
    Inserts data into BigQuery. Creates table if not exists.
    Raises exception on failure.
    """
    client = bigquery.Client(project=project_id)
    table_ref = f"{project_id}.{dataset_id}.{table_id}"
    
    # Define schema for flattened "Tidy Data"
    # One row per cell in the extracted table
    schema = [
        bigquery.SchemaField("page", "INTEGER", mode="NULLABLE"),
        bigquery.SchemaField("type", "STRING", mode="NULLABLE"),
        bigquery.SchemaField("element_id", "STRING", mode="NULLABLE"), # unique id for the chart/table
        bigquery.SchemaField("description", "STRING", mode="NULLABLE"),
        bigquery.SchemaField("confidence", "FLOAT", mode="NULLABLE"),
        bigquery.SchemaField("row_index", "INTEGER", mode="NULLABLE"),
        bigquery.SchemaField("column_name", "STRING", mode="NULLABLE"),
        bigquery.SchemaField("cell_value", "STRING", mode="NULLABLE"),
    ]
    
    # Check if table exists
    try:
        table = client.get_table(table_ref)
        # Check for schema mismatch (heuristic: look for 'cell_value')
        field_names = [f.name for f in table.schema]
        if "cell_value" not in field_names:
            logger.info(f"Table {table_ref} schema mismatch (switching to flattened). Dropping and recreating.")
            client.delete_table(table_ref)
            table = bigquery.Table(table_ref, schema=schema)
            client.create_table(table)
            logger.info(f"Recreated table {table_ref}")
    except NotFound:
        logger.info(f"Table {table_ref} not found. Creating it.")
        table = bigquery.Table(table_ref, schema=schema)
        client.create_table(table)
        logger.info(f"Created table {table_ref}")

    # Ensure data is a list of rows
    rows_to_insert = [data] if isinstance(data, dict) else data
    
    # Convert 'extracted_data' dicts/lists to JSON strings if needed? 
    # The JSON type in BQ Client usually accepts dicts directly.
    
    errors = client.insert_rows_json(table_ref, rows_to_insert)
    if errors == []:
        logger.info("New rows have been added.")
    else:
        error_msg = f"Encountered errors while inserting rows: {errors}"
        logger.error(error_msg)
        raise RuntimeError(error_msg)

def upload_to_gcs(file_path: str, bucket_name: str, destination_blob_name: str):
    """
    Uploads a file to the bucket.
    Raises exception on failure.
    """
    storage_client = storage.Client()
    bucket = storage_client.bucket(bucket_name)
    blob = bucket.blob(destination_blob_name)

    blob.upload_from_filename(file_path)

    logger.info(f"File {file_path} uploaded to gs://{bucket_name}/{destination_blob_name}.")

def draw_bounding_boxes(pdf_path: str, extraction_results: List[Any], output_dir: str):
    """
    Draws bounding boxes. Uses sips for Page 1 background if available.
    """
    output_files = []
    
    # Group results by page
    items_by_page = {}
    for item in extraction_results:
        p = item.page_number
        if p not in items_by_page:
            items_by_page[p] = []
        items_by_page[p].append(item)
        
    try:
        # Try to convert Page 1 using sips
        page1_img_path = os.path.join(output_dir, "page1_temp.png")
        use_sips = False
        try:
            import subprocess
            cmd = ["sips", "-s", "format", "png", pdf_path, "--out", page1_img_path]
            subprocess.run(cmd, check=True, capture_output=True)
            if os.path.exists(page1_img_path):
                use_sips = True
        except Exception as e:
            logger.warning(f"Sips conversion failed: {e}")

        for page_num, items in items_by_page.items():
            # Create/Load image
            if page_num == 1 and use_sips:
                img = Image.open(page1_img_path).convert("RGB")
                width, height = img.size
            else:
                width, height = 1000, 1414 # Approx A4
                img = Image.new('RGB', (width, height), color = (255, 255, 255))
                
            draw = ImageDraw.Draw(img)
            
            # Draw placeholder text if not real image
            if not (page_num == 1 and use_sips):
                draw.text((50, 50), f"Page {page_num} (Placeholder)", fill="black")

            for item in items:
                if hasattr(item, 'chart_bounding_box'):
                    bbox = item.chart_bounding_box
                    color = "red"
                    label = f"Chart ({item.confidence:.2f})"
                elif hasattr(item, 'table_bounding_box'):
                    bbox = item.table_bounding_box
                    color = "blue"
                    label = f"Table ({item.confidence:.2f})"
                else:
                    continue
                
                # Scale coordinates
                x1 = bbox.xmin * (width / 1000)
                y1 = bbox.ymin * (height / 1000)
                x2 = bbox.xmax * (width / 1000)
                y2 = bbox.ymax * (height / 1000)
                
                # Draw box
                draw.rectangle([x1, y1, x2, y2], outline=color, width=5)
                # Draw label background
                text_bbox = draw.textbbox((x1, y1), label)
                draw.rectangle(text_bbox, fill=color)
                draw.text((x1, y1), label, fill="white")
                
                # Draw objects inside if any
                if hasattr(item, 'objects_inside'):
                    for obj in item.objects_inside:
                        obbox = obj.bounding_box
                        ox1 = obbox.xmin * (width / 1000)
                        oy1 = obbox.ymin * (height / 1000)
                        ox2 = obbox.xmax * (width / 1000)
                        oy2 = obbox.ymax * (height / 1000)
                        draw.rectangle([ox1, oy1, ox2, oy2], outline="green", width=2)

            out_name = f"annotated_page_{page_num}.png"
            out_path = os.path.join(output_dir, out_name)
            img.save(out_path)
            output_files.append(out_path)
            logger.info(f"Saved {out_path}")
            
        # Clean up temp
        if os.path.exists(page1_img_path):
            os.remove(page1_img_path)
            
        return output_files # Return list

    except Exception as e:
        logger.error(f"Failed to draw bounding boxes: {e}")
        raise e
```

## 3. Backend (FastAPI Service)

### backend/main.py
```python
import os
import asyncio
from contextlib import asynccontextmanager

# --- Configuration: Restore Vertex AI (Global) ---
# Mimic the User's working GCE VM setup exactly
os.environ["GOOGLE_GENAI_USE_VERTEXAI"] = "True"
os.environ["GOOGLE_CLOUD_PROJECT"] = "vtxdemos"
os.environ["GOOGLE_CLOUD_LOCATION"] = "global"

print(f"--- STARTUP ENV CHECK ---")
print(f"GOOGLE_GENAI_USE_VERTEXAI: {os.environ.get('GOOGLE_GENAI_USE_VERTEXAI')}")
print(f"GOOGLE_CLOUD_LOCATION: {os.environ.get('GOOGLE_CLOUD_LOCATION')}")
print(f"-------------------------")

import uuid
import json
import base64
from fastapi import FastAPI, UploadFile, File, Form, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Dict, Any, Optional

from utils import get_pdf_page_count, extract_page_image, draw_legend_sidebar, upload_to_gcs, insert_to_bq
from agent_logic import create_page_extractor_agent, create_evaluator_agent, PdfExtractionResult
from google.adk.runners import Runner
from google.adk.sessions import InMemorySessionService
from google.genai import types

# Import debug script
# import debug_vertex

app = FastAPI(title="PDF Chart Extractor API")

# Enable CORS for frontend
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Ensure static directory exists
STATIC_DIR = "static"
os.makedirs(STATIC_DIR, exist_ok=True)
app.mount("/static", StaticFiles(directory=STATIC_DIR), name="static")

session_service = InMemorySessionService()

class ExtractionResponse(BaseModel):
    session_id: str
    results: Any
    annotated_images: List[str] # List of static URLs
    gcs_urls: List[str] # List of GCS URLs
    bq_status: str
    bq_link: str

import asyncio

@app.post("/extract", response_model=ExtractionResponse)
async def extract_pdf(
    file: UploadFile = File(...),
    extractor_model: str = Form("projects/vtxdemos/locations/global/publishers/google/models/gemini-3-flash-preview"),
    supporting_model: str = Form("projects/vtxdemos/locations/global/publishers/google/models/gemini-3-flash-preview")
):
    session_id = str(uuid.uuid4())
    pdf_bytes = await file.read()
    
    # Get total pages without loading all images into memory
    loop = asyncio.get_running_loop()
    num_pages = await loop.run_in_executor(None, get_pdf_page_count, pdf_bytes)
    print(f"PDF has {num_pages} pages. Starting extraction...")
    
    # Optimized Concurrency Limits based on Model Quotas
    limit = 25 # High throughput for Flash
    if "gemini-3-pro" in extractor_model.lower():
        limit = 8 # Conservative limit for Pro to avoid 429 errors
        
    print(f"Applying optimized concurrency limit: {limit} (Model: {extractor_model})")

    async def process_page(i):
        page_num = i + 1
        # Extract image for this page on demand (non-blocking)
        try:
            img_bytes = await loop.run_in_executor(None, extract_page_image, pdf_bytes, i)
        except Exception as e:
            print(f"Error extracting image for page {page_num}: {e}")
            return [], [], None, None

        # Create agent for this specific page and model
        agent = create_page_extractor_agent(page_num, model_id=extractor_model)
        runner = Runner(agent=agent, app_name="PdfExtractor", session_service=session_service)
        await session_service.create_session(app_name="PdfExtractor", user_id="web_user", session_id=f"{session_id}_{page_num}")

        content = types.Content(
            role='user',
            parts=[
                types.Part.from_bytes(data=img_bytes, mime_type="image/jpeg"),
                types.Part(text=f"Extract charts and tables from page {page_num}")
            ]
        )
        
        print(f"Processing Page {page_num} with model {extractor_model}...")
        result_text = ""
        try:
            async for event in runner.run_async(user_id="web_user", session_id=f"{session_id}_{page_num}", new_message=content):
                if event.is_final_response() and event.content:
                    result_text = event.content.parts[0].text
            
            data = json.loads(result_text)
            page_charts = data.get("charts", [])
            page_tables = data.get("tables", [])
            
            # Combine all for visualization
            boxes = []
            for item in page_charts + page_tables:
                bbox = item.get("chart_bounding_box") or item.get("table_bounding_box")
                desc = item.get("description", "Object")
                if bbox:
                    boxes.append({
                        "box_2d": [bbox["ymin"], bbox["xmin"], bbox["ymax"], bbox["xmax"]],
                        "label": desc[:30] + "..."
                    })
            
            annotated_url = None
            gcs_url = None
            if boxes:
                # Offload blocking image processing to executor
                annotated_img = await loop.run_in_executor(None, draw_legend_sidebar, img_bytes, boxes)
                
                filename = f"{session_id}_page_{page_num}.jpg"
                filepath = os.path.join(STATIC_DIR, filename)
                # File I/O is also blocking, but usually fast. Can be kept or offloaded. 
                # For simplicity, keeping sync write but offloading GCS upload.
                with open(filepath, "wb") as f:
                    f.write(annotated_img)
                annotated_url = f"/static/{filename}"
                
                # Offload blocking GCS upload to executor
                try:
                    gcs_url = await loop.run_in_executor(None, upload_to_gcs, annotated_img, "vtxdemos-staging", filename)
                except Exception as e:
                    print(f"GCS Upload Error: {e}")
                    gcs_url = f"gs://vtxdemos-staging/{filename}"
            
            return page_charts, page_tables, annotated_url, gcs_url
        except Exception as e:
            print(f"Error processing page {page_num}: {e}")
            return [], [], None, None

    # Create a semaphore to bound concurrency
    semaphore = asyncio.Semaphore(limit)

    async def process_page_safe(i):
        async with semaphore:
            return await process_page(i)

    # Launch all tasks immediately, bounded by the semaphore
    print(f"Starting continuous parallel extraction for {num_pages} pages with concurrency {limit}...")
    tasks = [process_page_safe(i) for i in range(num_pages)]
    results = await asyncio.gather(*tasks)

    # Aggregate results
    all_charts = []
    all_tables = []
    annotated_urls = []
    gcs_urls = []
    
    for page_charts, page_tables, annotated_url, gcs_url in results:
        all_charts.extend(page_charts)
        all_tables.extend(page_tables)
        if annotated_url:
            annotated_urls.append(annotated_url)
        if gcs_url:
            gcs_urls.append(gcs_url)

    # Final BQ storage
    bq_status = "Skipped"
    bq_link = "https://console.cloud.google.com/bigquery?project=vtxdemos&p=vtxdemos&d=esg_demo_data&t=pdf_extractions&page=table"
    
    if all_charts or all_tables:
        try:
            rows = []
            
            def flatten_item(item, item_type, idx):
                page = item.get('page_number')
                desc = item.get('description')
                conf = item.get('confidence')
                ext_data = item.get('extracted_data') or {}
                
                headers = ext_data.get('headers', [])
                data_rows = ext_data.get('rows', [])
                element_id = f"{item_type}_{page}_{idx}_{uuid.uuid4().hex[:4]}"
                
                # If no data rows, still insert a metadata row? 
                # Or just skip if the table is empty.
                if not data_rows:
                    rows.append({
                        "page": page,
                        "type": item_type,
                        "element_id": element_id,
                        "description": desc,
                        "confidence": conf,
                        "row_index": 0,
                        "column_name": "Metadata",
                        "cell_value": "No tabular data extracted"
                    })
                    return

                for r_idx, row_vals in enumerate(data_rows):
                    for c_idx, cell_val in enumerate(row_vals):
                        col_name = headers[c_idx] if c_idx < len(headers) else f"Col_{c_idx}"
                        rows.append({
                            "page": page,
                            "type": item_type,
                            "element_id": element_id,
                            "description": desc,
                            "confidence": conf,
                            "row_index": r_idx,
                            "column_name": str(col_name),
                            "cell_value": str(cell_val)
                        })

            for i, chart in enumerate(all_charts):
                flatten_item(chart, "CHART", i)
            for i, table in enumerate(all_tables):
                flatten_item(table, "TABLE", i)

            if rows:
                insert_to_bq(rows, "esg_demo_data", "pdf_extractions")
                bq_status = f"Success: {len(rows)} flattened rows inserted"
        except Exception as e:
            print(f"BQ Insert Error (Schema mismatch?): {e}")
            bq_status = f"Error: {e}"

    return ExtractionResponse(
        session_id=session_id,
        results={"charts": all_charts, "tables": all_tables},
        annotated_images=annotated_urls,
        gcs_urls=gcs_urls,
        bq_status=bq_status,
        bq_link=bq_link
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, timeout_keep_alive=300)
```

### backend/agent_logic.py
```python
import os
from typing import List, Any, Optional
from pydantic import BaseModel, Field
from google.adk.agents import Agent
from google.genai import types

# Model IDs based on USER_REQUEST
GEMINI_3_PRO = "projects/vtxdemos/locations/global/publishers/google/models/gemini-3-pro-preview"
GEMINI_3_FLASH = "projects/vtxdemos/locations/global/publishers/google/models/gemini-3-flash-preview"
GEMINI_2_5_PRO = "gemini-2.5-pro"
GEMINI_2_5_FLASH = "gemini-2.5-flash"

# --- Schemas ---

class BoundingBox(BaseModel):
    ymin: float = Field(description="Normalized Y coordinate (0-1000) for top")
    xmin: float = Field(description="Normalized X coordinate (0-1000) for left")
    ymax: float = Field(description="Normalized Y coordinate (0-1000) for bottom")
    xmax: float = Field(description="Normalized X coordinate (0-1000) for right")

class ChartObject(BaseModel):
    label: str = Field(description="Label or name of the object identified inside the chart")
    text_confidence: float = Field(description="Confidence score for the text/label extracted (0.0 to 1.0)", default=1.0)
    bounding_box: BoundingBox = Field(description="Bounding box of this specific object within the chart")

class ChartData(BaseModel):
    headers: List[str] = Field(description="Column headers of the extracted table")
    rows: List[List[Any]] = Field(description="Data rows corresponding to the headers")

class ChartExtraction(BaseModel):
    page_number: int = Field(description="Page number where the chart was found")
    chart_bounding_box: BoundingBox = Field(description="Bounding box of the entire chart/diagram on the PDF page")
    description: str = Field(description="A very detailed, precise, and lengthy description of the chart/diagram.")
    confidence: float = Field(description="Confidence level of the overall chart extraction (0.0 to 1.0)")
    objects_inside: List[ChartObject] = Field(description="List of distinct objects found inside the chart with their bounding boxes and label confidence")
    extracted_data: Optional[ChartData] = Field(description="Structured tabular data extracted from the chart")

class TableExtraction(BaseModel):
    page_number: int = Field(description="Page number where the table was found")
    table_bounding_box: BoundingBox = Field(description="Bounding box of the table on the PDF page")
    description: str = Field(description="A detailed description of the table's purpose and content.")
    confidence: float = Field(description="Confidence level of the extraction (0.0 to 1.0)")
    extracted_data: ChartData = Field(description="Structured tabular data")

class PdfExtractionResult(BaseModel):
    charts: List[ChartExtraction] = Field(description="List of all charts/diagrams found in the PDF")
    tables: List[TableExtraction] = Field(description="List of all standalone tables found in the PDF", default_factory=list)

# --- Agent Factories ---

def create_page_extractor_agent(page_num: int, model_id: str = GEMINI_3_FLASH) -> Agent:
    """Factory to create an agent focused on a specific page with a configurable model."""
    return Agent(
        name=f"page_{page_num}_extractor",
        model=model_id,
        description=f"Expert extractor focusing on PDF page {page_num}.",
        instruction=f"""
        Analyze the provided image of Page {page_num} and:
        1. Identify any charts, diagrams, or standalone tables.
        2. Provide normalized bounding boxes (0-1000).
        3. Describe each element in extreme detail.
        4. Extract tabular data if present.
        5. Assign confidence scores (0.0-1.0) to elements and labels.
        """,
        output_schema=PdfExtractionResult
    )

def create_evaluator_agent(model_id: str = GEMINI_3_FLASH) -> Agent:
    """Factory for evaluator agent."""
    return Agent(
        name="quality_evaluator",
        model=model_id,
        description="Evaluates extraction quality.",
        instruction="Review the extracted data for consistency, confidence and bounding box accuracy. Provide a quality summary."
    )
```

### backend/utils.py (Backend)
```python
import os
import io
import fitz  # PyMuPDF
from PIL import Image, ImageColor, ImageDraw, ImageFont
from typing import List, Dict, Any
from google.cloud import bigquery
from google.cloud import storage

def get_pdf_page_count(pdf_bytes: bytes) -> int:
    """Returns the number of pages in the PDF."""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    count = doc.page_count
    doc.close()
    return count

def extract_page_image(pdf_bytes: bytes, page_index: int) -> bytes:
    """Extracts a single page as a JPEG image byte string."""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    page = doc.load_page(page_index)
    pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))
    img_data = pix.tobytes("jpeg")
    doc.close()
    return img_data

def pdf_to_images(pdf_bytes: bytes) -> List[bytes]:
    """Converts PDF bytes to a list of JPEG image bytes."""
    doc = fitz.open(stream=pdf_bytes, filetype="pdf")
    images = []
    for page in doc:
        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2)) # Higher res
        img_data = pix.tobytes("jpeg")
        images.append(img_data)
    return images

def draw_legend_sidebar(image_bytes: bytes, boxes: List[Dict[str, Any]]) -> bytes:
    """
    Draws modern bounding boxes with colored 'pill' labels and a styled legend.
    """
    im = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    width, height = im.size
    draw = ImageDraw.Draw(im)
    
    # Modern high-contrast vibrant palette
    VIBRANT_COLORS = [
        "#FF3D00", "#00E676", "#2979FF", "#FFEA00", "#D500F9", 
        "#00E5FF", "#FF9100", "#1DE9B6", "#C6FF00", "#FF1744"
    ]
    
    try:
        # Load a variable font size based on image scale
        base_size = max(20, int(min(width, height) / 35))
        label_font = ImageFont.truetype("Arial.ttf", size=base_size)
    except OSError:
        label_font = ImageFont.load_default()

    for i, bbox in enumerate(boxes):
        box = bbox.get("box_2d") or [bbox.get("ymin"), bbox.get("xmin"), bbox.get("ymax"), bbox.get("xmax")]
        
        y_min, x_min, y_max, x_max = [int(v / 1000 * (height if j%2==0 else width)) for j, v in enumerate(box)]
        
        color = VIBRANT_COLORS[i % len(VIBRANT_COLORS)]
        
        # 1. Draw smooth bounding box with inner & outer stroke for contrast
        draw.rectangle(((x_min, y_min), (x_max, y_max)), outline=color, width=6)
        draw.rectangle(((x_min-1, y_min-1), (x_max+1, y_max+1)), outline="white", width=1)
        
        # 2. Draw 'Pill' Tag Label
        tag_text = f" {i+1} "
        # Calculate text bounding box to size the pill
        try:
            tw, th = label_font.getbbox(tag_text)[2:]
        except:
            tw, th = 30, 30

        pill_padding = 6
        pill_rect = [x_min, y_min - th - (pill_padding * 2), x_min + tw + (pill_padding * 2), y_min]
        
        # Ensure pill doesn't go off top of image
        if pill_rect[1] < 0:
            pill_rect[1] = y_min
            pill_rect[3] = y_min + th + (pill_padding * 2)

        # Draw pill background
        draw.rectangle(pill_rect, fill=color)
        # Draw white text on pill
        draw.text((pill_rect[0] + pill_padding, pill_rect[1] + pill_padding), tag_text, fill="white", font=label_font)

    # 3. Create Premium Dark Sidebar
    sidebar_width = 500
    new_width = width + sidebar_width
    combined = Image.new("RGB", (new_width, height), (15, 15, 20)) # Deep navy-black
    combined.paste(im, (0, 0))
    
    s_draw = ImageDraw.Draw(combined)
    title_size = max(28, int(height / 30))
    body_size = max(22, int(height / 40))
    
    try:
        title_font = ImageFont.truetype("Arial.ttf", size=title_size)
        body_font = ImageFont.truetype("Arial.ttf", size=body_size)
    except OSError:
        title_font = body_font = ImageFont.load_default()

    # Sidebar Header
    s_draw.text((width + 30, 30), "ANALYSIS REPORT", fill="#64B5F6", font=title_font)
    s_draw.line((width + 30, 30 + title_size + 10, width + 470, 30 + title_size + 10), fill="#2C2C3E", width=2)

    current_y = 60 + title_size * 2
    for i, bbox in enumerate(boxes):
        color = VIBRANT_COLORS[i % len(VIBRANT_COLORS)]
        label = bbox.get("label", "Unknown Object")
        
        # Draw Badge Number
        badge_w, badge_h = 45, 45
        s_draw.rounded_rectangle([width + 30, current_y, width + 30 + badge_w, current_y + badge_h], radius=8, fill=color)
        s_draw.text((width + 42, current_y + 8), str(i+1), fill="white", font=body_font)
        
        # Draw Label Text (simplified wrapping for demo)
        text_x = width + 90
        display_text = label[:45] + "..." if len(label) > 45 else label
        s_draw.text((text_x, current_y + 8), display_text, fill="#E0E0E0", font=body_font)
        
        current_y += int(badge_h * 1.6)

    output = io.BytesIO()
    combined.save(output, format="JPEG", quality=95)
    return output.getvalue()

def upload_to_gcs(data: bytes, bucket_name: str, blob_name: str, content_type: str = "image/jpeg"):
    """Uploads bytes to GCS and returns the public URL (if configured) or gs:// path."""
    client = storage.Client()
    bucket = client.bucket(bucket_name)
    blob = bucket.blob(blob_name)
    blob.upload_from_string(data, content_type=content_type)
    return f"https://storage.googleapis.com/{bucket_name}/{blob_name}"

def insert_to_bq(rows: List[Dict[str, Any]], dataset_id: str, table_id: str):
    """Inserts rows into BigQuery."""
    client = bigquery.Client()
    table_ref = f"{client.project}.{dataset_id}.{table_id}"
    errors = client.insert_rows_json(table_ref, rows)
    if errors:
        raise Exception(f"BQ Insert errors: {errors}")
```

### backend/requirements.txt
```text
fastapi
uvicorn
python-multipart
google-adk
google-genai
pillow
pymupdf
google-cloud-storage
google-cloud-bigquery
pydantic
```

### backend/Dockerfile
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies for PyMuPDF/Pillow if needed
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

# Create static directory
RUN mkdir -p static

EXPOSE 8080

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8080"]
```

## 4. Frontend (Next.js Application)

### frontend/package.json
```json
{
  "name": "frontend",
  "version": "0.1.0",
  "private": true,
  "scripts": {
    "dev": "next dev",
    "build": "next build",
    "start": "next start",
    "lint": "eslint"
  },
  "dependencies": {
    "clsx": "^2.1.1",
    "framer-motion": "^12.27.0",
    "lucide-react": "^0.562.0",
    "next": "16.1.3",
    "react": "19.2.3",
    "react-dom": "19.2.3",
    "tailwind-merge": "^3.4.0"
  },
  "devDependencies": {
    "@tailwindcss/postcss": "^4",
    "@types/node": "^20",
    "@types/react": "^19",
    "@types/react-dom": "^19",
    "eslint": "^9",
    "eslint-config-next": "16.1.3",
    "tailwindcss": "^4",
    "typescript": "^5"
  }
}
```

### frontend/src/app/page.tsx
```tsx
"use client";

import React, { useState } from 'react';
import { motion, AnimatePresence } from 'framer-motion';
import {
  Upload,
  FileText,
  ChevronRight,
  BarChart3,
  Layout,
  CheckCircle2,
  Loader2,
  Image as ImageIcon,
  ExternalLink,
  ChevronLeft,
  X,
  Database,
  Cloud,
  Network
} from 'lucide-react';
import { clsx, type ClassValue } from 'clsx';
import { twMerge } from 'tailwind-merge';

function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs));
}

const MODELS = [
  { id: "projects/vtxdemos/locations/global/publishers/google/models/gemini-3-pro-preview", label: "Gemini 3 Pro (Global)" },
  { id: "projects/vtxdemos/locations/global/publishers/google/models/gemini-3-flash-preview", label: "Gemini 3 Flash (Global)" },
  { id: "gemini-2.5-flash", label: "Gemini 2.5 Flash" },
  { id: "gemini-2.5-pro", label: "Gemini 2.5 Pro" },
];

export default function Home() {
  const [file, setFile] = useState<File | null>(null);
  const [isUploading, setIsUploading] = useState(false);
  const [results, setResults] = useState<any>(null);
  const [activePageIndex, setActivePageIndex] = useState(0);
  const [extractorModel, setExtractorModel] = useState(MODELS[0].id); // Default Gemini 3 Pro
  const [supportingModel, setSupportingModel] = useState(MODELS[0].id);
  const [showWorkflow, setShowWorkflow] = useState(false);
  const [timer, setTimer] = useState(0);
  const [lastJobTime, setLastJobTime] = useState<number | null>(null);

  React.useEffect(() => {
    let interval: any;
    if (isUploading) {
      setTimer(0);
      interval = setInterval(() => {
        setTimer(prev => prev + 1);
      }, 1000);
    } else {
      if (timer > 0) setLastJobTime(timer);
      clearInterval(interval);
    }
    return () => clearInterval(interval);
  }, [isUploading]);

  const onFileChange = (e: React.ChangeEvent<HTMLInputElement>) => {
    if (e.target.files && e.target.files[0]) {
      setFile(e.target.files[0]);
    }
  };

  const handleUpload = async () => {
    if (!file) return;
    setIsUploading(true);
    setResults(null);

    const formData = new FormData();
    formData.append('file', file);
    formData.append('extractor_model', extractorModel);
    formData.append('supporting_model', supportingModel);

    try {
      const response = await fetch('/extract', {
        method: 'POST',
        body: formData,
      });

      if (!response.ok) throw new Error('Upload failed');

      const data = await response.json();
      setResults(data);
      setActivePageIndex(0);
    } catch (error) {
      console.error('Error:', error);
      alert('Failed to process PDF. Make sure the backend is accessible.');
    } finally {
      setIsUploading(false);
    }
  };

  return (
    <main className="min-h-screen p-8 lg:p-16 max-w-7xl mx-auto">
      {/* Workflow Overlay */}
      <AnimatePresence>
        {showWorkflow && (
          <motion.div
            initial={{ opacity: 0 }}
            animate={{ opacity: 1 }}
            exit={{ opacity: 0 }}
            className="fixed inset-0 z-50 flex items-center justify-center p-6 bg-black/80 backdrop-blur-md"
            onClick={() => setShowWorkflow(false)}
          >
            <motion.div
              initial={{ scale: 0.9, opacity: 0, y: 20 }}
              animate={{ scale: 1, opacity: 1, y: 0 }}
              exit={{ scale: 0.9, opacity: 0, y: 20 }}
              className="glass-panel w-full max-w-4xl p-8 max-h-[90vh] overflow-y-auto relative"
              onClick={(e) => e.stopPropagation()}
            >
              <button
                onClick={() => setShowWorkflow(false)}
                className="absolute top-4 right-4 p-2 hover:bg-white/10 rounded-full transition-colors"
              >
                <X className="w-6 h-6" />
              </button>

              <h2 className="text-3xl font-bold mb-8 flex items-center gap-3">
                <Network className="text-blue-500" />
                Advanced Agentic Workflow
              </h2>

              <div className="space-y-12 relative before:absolute before:left-6 before:top-4 before:bottom-4 before:w-0.5 before:bg-gradient-to-b before:from-blue-500 before:via-purple-500 before:to-transparent">
                {[
                  { title: "Multimodal Ingestion", desc: "PDF content is logically split into high-resolution images.", icon: <FileText className="text-blue-400" /> },
                  { title: "Parallel Extraction", desc: "For each page, an independent Gemini 3/2.5 agent is spawned to identify visual data structures.", icon: <Loader2 className="text-purple-400" /> },
                  { title: "Deep Visual Analytics", desc: "Gemini 3 Pro analyzes chart axes, legends, and data points, generating precise bounding boxes.", icon: <BarChart3 className="text-cyan-400" /> },
                  { title: "Cross-Agent Quality Evaluation", desc: "A separate Supporting Agent verifies confidence scores and summarizes the extraction fidelity.", icon: <CheckCircle2 className="text-green-400" /> },
                  { title: "Persistent Synthesis", desc: "Data is flattened and stored in BigQuery, while annotated artifacts are preserved in GCS.", icon: <Database className="text-amber-400" /> },
                ].map((step, i) => (
                  <div key={i} className="flex gap-6 items-start relative pl-4">
                    <div className="z-10 w-12 h-12 rounded-full bg-black border-2 border-blue-500/50 flex items-center justify-center shrink-0 shadow-lg shadow-blue-500/20">
                      {step.icon}
                    </div>
                    <div>
                      <h3 className="text-xl font-bold text-white">{step.title}</h3>
                      <p className="text-gray-400 mt-1">{step.desc}</p>
                    </div>
                  </div>
                ))}
              </div>
            </motion.div>
          </motion.div>
        )}
      </AnimatePresence>

      {/* Header */}
      <header className="mb-12 flex flex-col md:flex-row md:items-end justify-between gap-6">
        <div>
          <motion.div
            initial={{ opacity: 0, y: -20 }}
            animate={{ opacity: 1, y: 0 }}
            className="flex items-center gap-3 mb-4"
          >
            <div className="p-2 bg-blue-600 rounded-lg">
              <BarChart3 className="text-white w-6 h-6" />
            </div>
            <h1 className="text-2xl font-bold tracking-tight">ChartVision Pro</h1>
          </motion.div>
          <motion.h2
            initial={{ opacity: 0, y: -10 }}
            animate={{ opacity: 1, y: 0 }}
            transition={{ delay: 0.1 }}
            className="text-5xl font-extrabold text-transparent bg-clip-text bg-gradient-to-r from-blue-400 to-purple-500 mb-6"
          >
            Extract Intelligence from PDFs <br />with Gemini 3 Pro
          </motion.h2>
        </div>

        <motion.button
          initial={{ opacity: 0 }}
          animate={{ opacity: 1 }}
          onClick={() => setShowWorkflow(true)}
          className="px-6 py-3 rounded-xl border border-blue-500/30 bg-blue-500/10 text-blue-400 font-semibold flex items-center gap-2 hover:bg-blue-500/20 transition-all mb-4"
        >
          <Network className="w-5 h-5" />
          View Workflow Diagram
        </motion.button>
      </header>

      <div className="grid grid-cols-1 lg:grid-cols-12 gap-12">
        {/* Left Column: Upload & Config */}
        <div className="lg:col-span-5 space-y-6">
          <section className="glass-panel p-8 space-y-6">
            <h3 className="text-xl font-semibold flex items-center gap-2">
              <Upload className="w-5 h-5 text-blue-400" />
              Configuration
            </h3>

            {/* Model Selectors */}
            <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
              <div className="space-y-2">
                <label className="text-xs font-bold text-gray-500 uppercase">Extractor Model</label>
                <select
                  value={extractorModel}
                  onChange={(e) => setExtractorModel(e.target.value)}
                  className="w-full bg-black/40 border border-gray-700 rounded-lg p-2 text-sm text-gray-300 focus:outline-none focus:border-blue-500"
                >
                  {MODELS.map(m => <option key={m.id} value={m.id}>{m.label}</option>)}
                </select>
              </div>
              <div className="space-y-2">
                <label className="text-xs font-bold text-gray-500 uppercase">Supporting Agents</label>
                <select
                  value={supportingModel}
                  onChange={(e) => setSupportingModel(e.target.value)}
                  className="w-full bg-black/40 border border-gray-700 rounded-lg p-2 text-sm text-gray-300 focus:outline-none focus:border-blue-500"
                >
                  {MODELS.map(m => <option key={m.id} value={m.id}>{m.label}</option>)}
                </select>
              </div>
            </div>

            <div
              className={cn(
                "border-2 border-dashed border-gray-700 rounded-2xl p-10 transition-all cursor-pointer flex flex-col items-center gap-4 hover:border-blue-500/50 hover:bg-white/5",
                file && "border-blue-500/50 bg-blue-500/5"
              )}
              onClick={() => document.getElementById('file-input')?.click()}
            >
              <input
                id="file-input"
                type="file"
                className="hidden"
                accept="application/pdf"
                onChange={onFileChange}
              />
              {file ? (
                <>
                  <FileText className="w-12 h-12 text-blue-400" />
                  <div className="text-center">
                    <p className="font-medium text-white">{file.name}</p>
                    <p className="text-sm text-gray-500">{(file.size / (1024 * 1024)).toFixed(2)} MB</p>
                  </div>
                </>
              ) : (
                <>
                  <div className="p-4 bg-gray-900 rounded-full">
                    <Upload className="w-8 h-8 text-gray-400" />
                  </div>
                  <div className="text-center">
                    <p className="font-medium">Drop your PDF here</p>
                    <p className="text-sm text-gray-500">or click to browse files</p>
                  </div>
                </>
              )}
            </div>

            <button
              disabled={!file || isUploading}
              onClick={handleUpload}
              className={cn(
                "w-full py-4 rounded-xl font-bold flex items-center justify-center gap-3 transition-all",
                file && !isUploading
                  ? "bg-blue-600 hover:bg-blue-500 text-white shadow-lg shadow-blue-500/20"
                  : "bg-gray-800 text-gray-500 cursor-not-allowed"
              )}
            >
              {isUploading ? (
                <>
                  <Loader2 className="w-5 h-5 animate-spin" />
                  Processing... {timer}s
                </>
              ) : (
                <>
                  Analyze Workflow
                  <ChevronRight className="w-5 h-5" />
                </>
              )}
            </button>

            {lastJobTime !== null && (
              <div className="flex items-center justify-center gap-2 text-xs text-gray-400 font-mono">
                <CheckCircle2 className="w-3 h-3 text-green-500" />
                Last Job: {lastJobTime}s
              </div>
            )}
          </section>

          {/* Persistence Links */}
          <AnimatePresence>
            {results && (
              <motion.section
                initial={{ opacity: 0, y: 10 }}
                animate={{ opacity: 1, y: 0 }}
                className="glass-panel p-6 space-y-4"
              >
                <h4 className="text-sm font-bold text-gray-500 uppercase flex items-center gap-2">
                  <Database className="w-4 h-4" />
                  Persistence Status
                </h4>
                <div className="space-y-3">
                  <div className="flex items-center justify-between p-3 bg-black/30 rounded-lg border border-gray-800">
                    <div className="flex items-center gap-3">
                      <Database className="text-orange-400 w-5 h-5" />
                      <div>
                        <p className="text-xs font-bold text-white">BigQuery</p>
                        <p className="text-[10px] text-gray-400">{results.bq_status}</p>
                      </div>
                    </div>
                    <a href={results.bq_link} target="_blank" className="p-2 hover:bg-white/10 rounded-lg">
                      <ExternalLink className="w-4 h-4 text-blue-400" />
                    </a>
                  </div>
                  <div className="flex items-center justify-between p-3 bg-black/30 rounded-lg border border-gray-800">
                    <div className="flex items-center gap-3">
                      <Cloud className="text-blue-400 w-5 h-5" />
                      <div>
                        <p className="text-xs font-bold text-white">Cloud Storage</p>
                        <p className="text-[10px] text-gray-400">{results.gcs_urls[activePageIndex] || "Stored in GCS"}</p>
                      </div>
                    </div>
                    <a href={results.gcs_urls[activePageIndex]} target="_blank" className="p-2 hover:bg-white/10 rounded-lg">
                      <ExternalLink className="w-4 h-4 text-blue-400" />
                    </a>
                  </div>
                </div>
              </motion.section>
            )}
          </AnimatePresence>
        </div>

        {/* Right Column: Visualization */}
        <div className="lg:col-span-7">
          <AnimatePresence mode="wait">
            {!results && !isUploading && (
              <motion.div
                key="empty"
                initial={{ opacity: 0 }}
                animate={{ opacity: 1 }}
                exit={{ opacity: 0 }}
                className="h-full flex flex-col items-center justify-center border border-gray-800 rounded-3xl bg-white/[0.02] p-12 text-center"
              >
                <Layout className="w-16 h-16 text-gray-700 mb-6" />
                <h4 className="text-xl font-medium text-gray-500">No Analysis results yet</h4>
                <p className="text-gray-600 mt-2">Configure models and upload a PDF to begin.</p>
              </motion.div>
            )}

            {isUploading && (
              <motion.div
                key="loading"
                initial={{ opacity: 0 }}
                animate={{ opacity: 1 }}
                exit={{ opacity: 0 }}
                className="h-full space-y-6"
              >
                <div className="aspect-[4/3] w-full rounded-3xl bg-gray-900 overflow-hidden relative border border-gray-800">
                  <div className="absolute inset-0 bg-gradient-to-r from-transparent via-white/5 to-transparent animate-shimmer" style={{ backgroundSize: '200% 100%' }} />
                  <div className="flex flex-col items-center justify-center h-full gap-4">
                    <Loader2 className="w-12 h-12 text-blue-500 animate-spin" />
                    <p className="text-gray-500 animate-pulse">Running Agentic Extractions...</p>
                  </div>
                </div>
              </motion.div>
            )}

            {results && (
              <motion.div
                key="results"
                initial={{ opacity: 0, scale: 0.95 }}
                animate={{ opacity: 1, scale: 1 }}
                className="space-y-8"
              >
                {/* Bounding Box Viewer */}
                <div className="relative group">
                  <div className="flex items-center justify-between mb-4">
                    <h3 className="text-xl font-semibold flex items-center gap-2">
                      <ImageIcon className="w-5 h-5 text-purple-400" />
                      Visual Annotated Feed
                    </h3>
                    <div className="flex items-center gap-2">
                      <button
                        onClick={() => setActivePageIndex(prev => Math.max(0, prev - 1))}
                        disabled={activePageIndex === 0}
                        className="p-1 hover:bg-white/10 rounded disabled:opacity-30"
                      >
                        <ChevronLeft />
                      </button>
                      <span className="text-sm text-gray-400 font-mono">P{activePageIndex + 1} / {results.annotated_images.length}</span>
                      <button
                        onClick={() => setActivePageIndex(prev => Math.min(results.annotated_images.length - 1, prev + 1))}
                        disabled={activePageIndex === results.annotated_images.length - 1}
                        className="p-1 hover:bg-white/10 rounded disabled:opacity-30"
                      >
                        <ChevronRight />
                      </button>
                    </div>
                  </div>

                  <div className="rounded-2xl overflow-hidden border border-gray-700 bg-black/40 backdrop-blur-sm p-4">
                    {results.annotated_images && results.annotated_images.length > 0 ? (
                      <img
                        src={`${results.annotated_images[activePageIndex]}`}
                        alt="Annotated Result"
                        className="w-full h-auto object-contain rounded-lg shadow-2xl"
                      />
                    ) : (
                      <div className="flex flex-col items-center justify-center py-12 text-gray-500">
                        <ImageIcon className="w-12 h-12 mb-2 opacity-50" />
                        <p>No visualizations generated for this page.</p>
                      </div>
                    )}
                  </div>
                </div>

                {/* Data Points */}
                <div className="grid grid-cols-1 md:grid-cols-2 gap-4">
                  {[...results.results.charts, ...results.results.tables].map((item: any, i: number) => (
                    <div key={i} className="glass-panel p-6 border-l-4 border-l-blue-500 hover:bg-white/10 transition-colors">
                      <div className="flex justify-between items-start mb-4">
                        <span className="text-xs font-bold uppercase tracking-widest text-blue-400">
                          {item.chart_bounding_box ? "Chart" : "Table"} ‚Ä¢ P{item.page_number}
                        </span>
                        <span className="px-2 py-1 rounded bg-blue-500/20 text-blue-300 text-[10px] font-bold">
                          {(item.confidence * 100).toFixed(0)}% Conf
                        </span>
                      </div>
                      <p className="text-sm text-gray-300 line-clamp-3 mb-4">{item.description}</p>

                      {item.extracted_data && (
                        <div className="bg-black/40 rounded-lg p-3 overflow-x-auto border border-white/5 scrollbar-thin">
                          <table className="w-full text-[10px] min-w-[300px]">
                            <thead>
                              <tr className="border-b border-gray-800">
                                {item.extracted_data.headers.map((h: string, hi: number) => (
                                  <th key={hi} className="text-left py-2 px-2 text-gray-500 uppercase tracking-tighter break-words max-w-[120px]">{h}</th>
                                ))}
                              </tr>
                            </thead>
                            <tbody>
                              {item.extracted_data.rows.slice(0, 5).map((row: any[], ri: number) => (
                                <tr key={ri} className="border-b border-white/5 last:border-0 hover:bg-white/10 transition-colors">
                                  {row.map((cell: any, ci: number) => (
                                    <td key={ci} className="py-2 px-2 text-gray-300 break-words max-w-[150px]">{cell}</td>
                                  ))}
                                </tr>
                              ))}
                            </tbody>
                          </table>
                          {item.extracted_data.rows.length > 5 && (
                            <p className="text-[10px] text-gray-600 mt-2 text-center">+{item.extracted_data.rows.length - 5} additional rows</p>
                          )}
                        </div>
                      )}
                    </div>
                  ))}
                </div>
              </motion.div>
            )}
          </AnimatePresence>
        </div>
      </div>

      <style jsx global>{`
        @keyframes shimmer {
          0% { background-position: -200% 0; }
          100% { background-position: 200% 0; }
        }
        .animate-shimmer {
          animation: shimmer 2s infinite linear;
        }
      `}</style>
    </main>
  );
}
```

### frontend/src/app/layout.tsx
```tsx
import type { Metadata } from "next";
import { Geist, Geist_Mono } from "next/font/google";
import "./globals.css";

const geistSans = Geist({
  variable: "--font-geist-sans",
  subsets: ["latin"],
});

const geistMono = Geist_Mono({
  variable: "--font-geist-mono",
  subsets: ["latin"],
});

export const metadata: Metadata = {
  title: "Create Next App",
  description: "Generated by create next app",
};

export default function RootLayout({
  children,
}: Readonly<{
  children: React.ReactNode;
}>) {
  return (
    <html lang="en">
      <body
        className={`${geistSans.variable} ${geistMono.variable} antialiased`}
      >
        {children}
      </body>
    </html>
  );
}
```

### frontend/src/app/globals.css
```css
@import "tailwindcss";

:root {
  --background: #0a0a0a;
  --foreground: #ededed;
  --glass: rgba(255, 255, 255, 0.03);
  --glass-border: rgba(255, 255, 255, 0.1);
  --accent: #3b82f6;
  --accent-glow: rgba(59, 130, 246, 0.2);
}

body {
  color: var(--foreground);
  background: var(--background);
  font-family: 'Inter', system-ui, -apple-system, sans-serif;
  background-image: 
    radial-gradient(circle at 10% 20%, rgba(59, 130, 246, 0.05) 0%, transparent 40%),
    radial-gradient(circle at 90% 80%, rgba(139, 92, 246, 0.05) 0%, transparent 40%);
  background-attachment: fixed;
}

@layer components {
  .glass-panel {
    background: var(--glass);
    backdrop-filter: blur(12px);
    border: 1px solid var(--glass-border);
    border-radius: 1rem;
  }
}

/* Custom Scrollbar */
::-webkit-scrollbar {
  width: 8px;
}
::-webkit-scrollbar-track {
  background: transparent;
}
::-webkit-scrollbar-thumb {
  background: var(--glass-border);
  border-radius: 4px;
}
::-webkit-scrollbar-thumb:hover {
  background: rgba(255, 255, 255, 0.2);
}
```

## 5. Environment & Infrastructure

### .env
```env
# Google Cloud Configuration
GOOGLE_CLOUD_PROJECT=vtxdemos
GOOGLE_CLOUD_LOCATION=global
GOOGLE_GENAI_USE_VERTEXAI=True

# Optional: For local testing without Vertex AI
# GEMINI_API_KEY=your_api_key_here
```

