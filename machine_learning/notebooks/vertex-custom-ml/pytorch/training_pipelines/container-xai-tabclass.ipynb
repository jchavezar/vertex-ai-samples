{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562aa9cd-ee99-4676-9806-a6df224f0b18",
   "metadata": {},
   "source": [
    "![](../../images/ml_flow_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d852287-c347-4c93-a151-3e872f1d929f",
   "metadata": {},
   "source": [
    "## Pipelines Components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb1ac78-9e90-4a3d-b051-baf51cc9aaa7",
   "metadata": {},
   "source": [
    "### Create Code/Folder Structure and Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "640a2ead-cc84-443b-b8f4-7ad245ab0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jchavezar-demo'\n",
    "TRAIN_IMAGE = 'gcr.io/jchavezar-demo/pytorch-custom-random-t:v2'\n",
    "PREDICTION_IMAGE = 'gcr.io/jchavezar-demo/pytorch-custom-random-p:v2'\n",
    "STAGING_BUCKET = 'gs://vtx-staging'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e144478-206d-43df-b8b1-426d10b92a85",
   "metadata": {},
   "source": [
    "#### Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d53a77-361f-4cf3-bb6d-9de1fd2472bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr training\n",
    "!mkdir training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c4767e-4758-46d3-b143-58789f16d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training/train.py\n",
    "#%%\n",
    "import pandas as pd\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig\n",
    "\n",
    "train = pd.read_csv('gs://vtx-datasets-public/pytorch_tabular/synthetic/train.csv')\n",
    "test = pd.read_csv('gs://vtx-datasets-public/pytorch_tabular/synthetic/test.csv')\n",
    "val = pd.read_csv('gs://vtx-datasets-public/pytorch_tabular/synthetic/val.csv')\n",
    "\n",
    "cat_col_names = [col for col in train.columns if 'cat' in col]\n",
    "num_col_names = [col for col in train.columns if 'num' in col]\n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=['target'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=num_col_names,\n",
    "    categorical_cols=cat_col_names,\n",
    ")\n",
    "trainer_config = TrainerConfig(\n",
    "    auto_lr_find=True, # Runs the LRFinder to automatically derive a learning rate\n",
    "    batch_size=1024,\n",
    "    max_epochs=100,\n",
    "    accelerator=\"auto\", # can be 'cpu','gpu', 'tpu', or 'ipu' \n",
    ")\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"32-16\", # Number of nodes in each layer\n",
    "    activation=\"LeakyReLU\", # Activation between each layers\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\",\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    "    learning_rate = 1e-3\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train, validation=val)\n",
    "tabular_model.save_model('/gcs/vtx-models/pytorch/tabular_random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0def7e53-c338-44c6-8650-dd625ba74b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile training/Dockerfile\n",
    "FROM pytorch/pytorch:1.12.1-cuda11.3-cudnn8-devel\n",
    "\n",
    "COPY . .\n",
    "RUN pip install pytorch_tabular[extra]\n",
    "RUN pip install gcsfs\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fff6d-f878-4cc4-af76-e63439d31b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit -t $TRAIN_IMAGE training/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b1d24c-d486-414c-a3b5-1f52e493513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.upload_model.component.UnmanagedContainerModel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c5a4b-44cc-4d10-9eca-ef3eb1a337d3",
   "metadata": {},
   "source": [
    "#### Prediction Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db44de-d37e-441f-b894-4e740e86a6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr prediction\n",
    "!mkdir prediction\n",
    "!mkdir prediction/app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea5310f-4a00-4a51-9f0a-c0cabbf7937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile prediction/app/main.py\n",
    "\n",
    "#%%\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "from starlette.responses import JSONResponse\n",
    "from fastapi import Request, FastAPI\n",
    "from pytorch_tabular import TabularModel\n",
    "\n",
    "app = FastAPI()\n",
    "#columns = pd.read_csv('gs://vtx-datasets-public/pytorch_tabular/synthetic/train.csv', nrows=0).iloc[:,:-1].columns.to_list()\n",
    "loaded_model = TabularModel.load_from_checkpoint(\"tabular_random\")\n",
    "#%%\n",
    "@app.get('/health_check')\n",
    "def health():\n",
    "    return 200\n",
    "if os.environ.get('AIP_PREDICT_ROUTE') is not None:\n",
    "    method = os.environ['AIP_PREDICT_ROUTE']\n",
    "else:\n",
    "    method = '/predict'\n",
    "\n",
    "@app.post(method)\n",
    "async def predict(request: Request):\n",
    "    print(\"----------------- PREDICTING -----------------\")\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    data_pred = pd.DataFrame.from_dict(instances)\n",
    "    outputs = loaded_model.predict(data_pred)\n",
    "    response = outputs['prediction'].tolist()\n",
    "    print(\"----------------- OUTPUTS -----------------\")\n",
    "    return JSONResponse({\n",
    "        \"predictions\": {\"probability\": response}\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc29947-a0ab-4811-8c16-38396823b749",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile prediction/Dockerfile\n",
    "\n",
    "FROM pytorch/pytorch:1.12.1-cuda11.3-cudnn8-devel\n",
    "\n",
    "COPY app /app\n",
    "WORKDIR /app\n",
    "\n",
    "RUN pip install pytorch_tabular[extra]\n",
    "RUN pip install uvicorn fastapi\n",
    "RUN pip install gcsfs\n",
    "\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa964a2-f340-4c04-93fa-874017ff0cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp -r gs://vtx-models/pytorch/tabular_random prediction/app/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e1a78-caaa-44c6-b216-e73acf182679",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit -t $PREDICTION_IMAGE prediction/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68e9928-1aa9-4adf-ad77-7050517e8367",
   "metadata": {},
   "source": [
    "### Data Extraction and Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dedc4e14-db5a-4a09-bf91-06c78e61e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_cloud_pipeline_components.v1 import custom_job, model\n",
    "from google_cloud_pipeline_components.types import artifact_types\n",
    "from google_cloud_pipeline_components.aiplatform import ModelUploadOp\n",
    "from kfp.dsl import pipeline, importer\n",
    "from kfp import compiler\n",
    "\n",
    "## Worker pool spec for training\n",
    "worker_pool_specs = [\n",
    "        {\n",
    "            \"machine_spec\": {\n",
    "                \"machine_type\": \"n1-standard-4\",\n",
    "                \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "                \"accelerator_count\": 1,\n",
    "            },\n",
    "            \"replica_count\": 1,\n",
    "            \"container_spec\": {\n",
    "                \"image_uri\": TRAIN_IMAGE,\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "@pipeline(name=\"pytorch-tabular-gpu\")\n",
    "def pipeline(\n",
    "    project_id: str,\n",
    "    display_name: str,\n",
    "):\n",
    "    train_task = custom_job.CustomTrainingJobOp(\n",
    "        display_name=f\"{display_name}-train\",\n",
    "        project=project_id,\n",
    "        worker_pool_specs=worker_pool_specs\n",
    "    )\n",
    "    import_unmanaged_model_task = importer(\n",
    "    artifact_uri= \"gs://vtx-models/pytorch/tabular_random\",\n",
    "    artifact_class=artifact_types.UnmanagedContainerModel, \n",
    "    metadata={\n",
    "        \"containerSpec\": {\n",
    "            \"imageUri\": PREDICTION_IMAGE,\n",
    "            \"healthRoute\": \"/health_check\",\n",
    "            \"ports\": [{\"containerPort\": 8080}]\n",
    "        }\n",
    "    }\n",
    "    ).after(train_task)\n",
    "    upload_task = model.ModelUploadOp(\n",
    "        display_name=f\"{display_name}-model\",\n",
    "        project=project_id,\n",
    "        unmanaged_container_model=import_unmanaged_model_task.outputs[\"artifact\"],\n",
    "        #explanation_parameters=parameters,\n",
    "        #explanation_metadata=EXPLANATION_METADATA,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b59b347-b4c8-4ea9-8194-f6be6d3bbd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile File\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path='pytorch-tabular-gpu.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c768976-5729-4da8-a432-b321f044588b",
   "metadata": {},
   "source": [
    "## [OPTIONAL]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7da333e6-b561-4c56-a77b-4bfc85c02b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create Template:\n",
    "from kfp.registry import RegistryClient\n",
    "\n",
    "client = RegistryClient(host=f\"https://us-central1-kfp.pkg.dev/jchavezar-demo/pipe-repo\")\n",
    "\n",
    "## Upload Template\n",
    "\n",
    "templateName, versionName = client.upload_pipeline(\n",
    "  file_name=\"pytorch-tabular-gpu.yaml\",\n",
    "  tags=[\"v5\", \"latest\"],\n",
    "  extra_headers={\"description\":\"This is an example pipeline template.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3457b9e3-7b5a-47d5-94bd-f16412d7fcc3",
   "metadata": {},
   "source": [
    "## Creating Pipelines from Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e793a74a-a89b-4ba0-80ec-22cbb1c311ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "# Initialize the aiplatform package\n",
    "aiplatform.init(\n",
    "    project=\"jchavezar-demo\",\n",
    "    location='us-central1',\n",
    "    staging_bucket=\"gs://vtx-staging\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "06feb1d7-a284-4ac0-ac04-ccedd53e3061",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://us-central1-kfp.pkg.dev/jchavezar-demo/pipe-repo/pytorch-tabular-gpu/v5'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17428/2958192012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     parameter_values={\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"project_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"jchavezar-demo\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \"display_name\": \"pytorch-tab-pipe\"}\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, display_name, template_path, job_id, pipeline_root, parameter_values, enable_caching, encryption_spec_key_name, labels, credentials, project, location)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# this loads both .yaml and .json files because YAML is a superset of JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         pipeline_json = yaml_utils.load_yaml(\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mtemplate_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         )\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/utils/yaml_utils.py\u001b[0m in \u001b[0;36mload_yaml\u001b[0;34m(path, project, credentials)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_yaml_from_gs_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_yaml_from_local_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/utils/yaml_utils.py\u001b[0m in \u001b[0;36m_load_yaml_from_local_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;34m'Please install the SDK using \"pip install google-cloud-aiplatform[pipelines]\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://us-central1-kfp.pkg.dev/jchavezar-demo/pipe-repo/pytorch-tabular-gpu/v5'"
     ]
    }
   ],
   "source": [
    "# Create a job via tag and with different \n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"pytorch-tabular-run\",\n",
    "    template_path=\"https://us-central1-kfp.pkg.dev/jchavezar-demo/pipe-repo/pytorch-tabular-gpu/v5\",\n",
    "    parameter_values={\n",
    "        \"project_id\": \"jchavezar-demo\", \n",
    "        \"display_name\": \"pytorch-tab-pipe\"}\n",
    ")\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57b1bd7f-8262-4ed3-a74c-2d0251168e65",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'https://us-central1-kfp.pkg.dev/jchavezar-demo/pipe-repo/pytorch-tabular/sha256:9782bda73edd2ec2c4a6e471d4405cab0ac7a768bdd2cf320b66d00aecfa7591'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17428/105297272.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     parameter_values={\n\u001b[1;32m      6\u001b[0m         \u001b[0;34m\"project_id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPROJECT_ID\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0;34m\"display_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pytorch-tabular\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     },\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, display_name, template_path, job_id, pipeline_root, parameter_values, enable_caching, encryption_spec_key_name, labels, credentials, project, location)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;31m# this loads both .yaml and .json files because YAML is a superset of JSON\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         pipeline_json = yaml_utils.load_yaml(\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0mtemplate_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         )\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/utils/yaml_utils.py\u001b[0m in \u001b[0;36mload_yaml\u001b[0;34m(path, project, credentials)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_yaml_from_gs_uri\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_yaml_from_local_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/utils/yaml_utils.py\u001b[0m in \u001b[0;36m_load_yaml_from_local_file\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;34m'Please install the SDK using \"pip install google-cloud-aiplatform[pipelines]\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0myaml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'https://us-central1-kfp.pkg.dev/jchavezar-demo/pipe-repo/pytorch-tabular/sha256:9782bda73edd2ec2c4a6e471d4405cab0ac7a768bdd2cf320b66d00aecfa7591'"
     ]
    }
   ],
   "source": [
    "# Create a job via version id.\n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"pytorch-tabular-latest\",\n",
    "    template_path=\"https://us-central1-kfp.pkg.dev/jchavezar-demo/pipe-repo/pytorch-tabular/sha256:9782bda73edd2ec2c4a6e471d4405cab0ac7a768bdd2cf320b66d00aecfa7591\",\n",
    "    parameter_values={\n",
    "        \"project_id\": PROJECT_ID,\n",
    "        \"display_name\": \"pytorch-tabular\"\n",
    "    },\n",
    ")\n",
    "job.submit(experiment='pytorch-tabular-pipe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1eb5ca-fae1-4d08-a492-d6e9d4f2491a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a job via tag and with different \n",
    "job = aiplatform.PipelineJob(\n",
    "    display_name=\"simple-sample-latest\",\n",
    "    template_path=\"https://us-central1-kfp.pkg.dev/jchavezar-demo/simple-samples-repo/simple-testing/v1\",\n",
    "    parameter_values={\"dataset\": \"gs://vtx-datasets-public/pytorch_tabular/synthetic/test.csv\"}\n",
    ")\n",
    "job.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1037c22b-cd3f-4df2-8675-9590a98cb013",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "data = fetch_openml(\"credit-g\")  # get the credit data from OpenML\n",
    "X_raw = data.data  # features (pandas DataFrame)\n",
    "y_raw = data.target  # labels (pandas Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47630b-6b5d-40a0-baa6-c3b266ce8947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw['target']=y_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867850b3-8dd4-4188-ba72-af220c8b74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw.to_csv('dataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc6811e-5dac-4e55-be9a-26189b3b6089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
