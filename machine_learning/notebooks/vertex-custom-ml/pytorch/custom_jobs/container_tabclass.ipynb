{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0e559f1-467e-4d72-a118-1065a718cdeb",
   "metadata": {},
   "source": [
    "# Vertex Tabular Binary Classification with .CustomJob() / Container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b72fd-ec25-47b7-a229-3d9297ef2653",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/jchavezar/vertex-ai-samples/blob/main/vertex-custom-ml/pytorch/custom_jobs/pypackage_from_local_tabclass.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfe67ba-1a9e-459a-80da-d0d8e904c1e1",
   "metadata": {},
   "source": [
    "**Use case: predict if a customer will buy on return visit.**\n",
    "\n",
    "The ecommerce dataset has different training features:\n",
    "- latest_ecommerce_progress\n",
    "- bounces\n",
    "- time_on_site\n",
    "- pageviews\n",
    "- source\n",
    "- medium\n",
    "- channel_grouping\n",
    "- device_category\n",
    "- country\n",
    "\n",
    "The label: will_buy_on_return_visit\n",
    "\n",
    "Data is imbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba3f4c9-1275-4579-b2d9-652d5fd4ccd5",
   "metadata": {},
   "source": [
    "<img src=\"../../../images/custom-container-tabclass.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e6e41e-80c2-43bd-947b-5b5007c4933f",
   "metadata": {},
   "source": [
    "## Colab Only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a81e1c-980f-49c2-8d6f-8c08abe714ce",
   "metadata": {},
   "source": [
    "*Uncomment and execute if colab*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4428f453-64db-4711-96f0-216cb098438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip3 install --upgrade google-cloud-aiplatform -q google-cloud-bigquery db-dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda42ed3-182d-4550-a009-777c8b553598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42a4daa-ab19-4a96-a168-ec73eae2f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61df73e-7eec-495d-aea7-bd7fb908c888",
   "metadata": {},
   "source": [
    "## Set Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4520f22-e76a-40ed-a86a-92cc2f7bd3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jchavezar-demo'\n",
    "REGION = 'us-central1'\n",
    "DATASET_URI = 'gs://vtx-datasets-public/ecommerce/datasets.csv'\n",
    "MODEL_URI = 'gs://vtx-models/pytorch/ecommerce/c-container'\n",
    "MODEL_DISPLAY_NAME = 'pytorch-ecommerce-c-container'\n",
    "STAGING_URI = 'gs://vtx-staging/pytorch/ecommerce/c-container'\n",
    "TRAIN_IMAGE_URI = f'gcr.io/{PROJECT_ID}/pytorch-train:latest'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6de79d-1e07-4b1f-89f3-af62fb4791a6",
   "metadata": {},
   "source": [
    "## Create Folder Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f7e95b-72e6-4b32-a827-5c40247f0d3e",
   "metadata": {},
   "source": [
    "```\n",
    "source\n",
    "|  Dockerfile\n",
    "└─── trainer\n",
    "     |  train.py\n",
    "     |\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2fa50e3-a932-493e-9c0b-8e2b7c0249ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr source\n",
    "!mkdir -p source/trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa183da4-3d69-4176-8d10-78855ca2a8f6",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Below we have the code for the training, it was made with PyTorch by building a neural network with these components:\n",
    "\n",
    "- 2 types of features set: categorical and numerical.\n",
    "- Shape detection of embedding layer for categorical.\n",
    "- Drouput to avoid overfit during the training.\n",
    "- Batch Normalization to standarize the data.\n",
    "- 1 input layer, shape: 114x32: \n",
    "  - 114 is the number of total features (categorical and numerical) after the embedding.\n",
    "  - 32 is the number of the neurons.\n",
    "- Activation function applied to the last input layer to fix non-linearity.\n",
    "- 1 output layer, shape: 32x2.\n",
    "\n",
    "The following diagram shows the neural netowkr with steps ordered used during the Model building class: ShelterOutcomeModel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb9b09e-ff79-48c1-a05b-97d3df6716bc",
   "metadata": {},
   "source": [
    "<center><img src=\"../../../images/04-pytorch-nn.png\"/></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f41f6a6-0a2f-47ae-ae14-1d13724ccac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing source/trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile source/trainer/train.py\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as torch_optim\n",
    "from google.cloud import storage\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument(\n",
    "    '--dataset_uri',\n",
    "    type = str,\n",
    "    help = 'Dataset uri in the format gs://[BUCKET]/*suffix*/file_name.extension')\n",
    "parser.add_argument(\n",
    "    '--project',\n",
    "    type = str,\n",
    "    help = 'This is the tenant or the Google Cloud project id name')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "## Prepare Data\n",
    "\n",
    "def preprocessing_data(df):\n",
    "    target = 'will_buy_on_return_visit'\n",
    "    cat_columns = [i for i in df.columns if df[i].dtypes == 'object']\n",
    "    num_columns = [i for i in df.columns if df[i].dtypes == 'int64' or df[i].dtypes == 'float']\n",
    "    num_columns.remove(target)\n",
    "\n",
    "    cat_train_df = df[cat_columns]\n",
    "    num_train_df = df[num_columns]\n",
    "    label = df[target].to_numpy()\n",
    "    \n",
    "    labelencoder = defaultdict(LabelEncoder)\n",
    "    cat_train_df[cat_columns] = cat_train_df[cat_columns].apply(lambda x: labelencoder[x.name].fit_transform(x))\n",
    "    cat_train_df[cat_columns] = cat_train_df[cat_columns].astype('category')\n",
    "    \n",
    "    train_df = pd.concat([cat_train_df,num_train_df], axis=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_df, label, test_size=0.10, random_state=0)\n",
    "    \n",
    "    ## Numerical columns standarization\n",
    "    scaler = StandardScaler()\n",
    "    X_train[num_columns] = scaler.fit_transform(X_train[num_columns])\n",
    "    X_val[num_columns] = scaler.transform(X_val[num_columns])\n",
    "    \n",
    "    # Categorical Embedding\n",
    "    embedded_cols = {n: len(col.cat.categories) for n,col in X_train[cat_columns].items() if len(col.cat.categories) > 2}\n",
    "    embedded_col_names = embedded_cols.keys()\n",
    "    embedding_sizes = [(n_categories, min(50, (n_categories+1)//2)) for _,n_categories in embedded_cols.items()]\n",
    "    embedding_sizes = nn.ModuleList([nn.Embedding(categories, size) for categories,size in embedding_sizes])\n",
    "    pickle.dump(labelencoder, open('label.pkl', 'wb'))\n",
    "    pickle.dump(scaler, open('std_scaler.pkl', 'wb'))\n",
    "    pickle.dump(embedding_sizes, open('emb.pkl', 'wb'))\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val, embedded_col_names, embedding_sizes\n",
    "\n",
    "df = pd.read_csv(args.dataset_uri)\n",
    "X_train, X_val, y_train, y_val, embedded_col_names, embedding_sizes = preprocessing_data(df)\n",
    "\n",
    "## PyTorch Dataset\n",
    "\n",
    "class ShelterOutcomeDataset(Dataset):\n",
    "    def __init__(self, X, Y, embedded_col_names):\n",
    "        X = X.copy()\n",
    "        self.X1 = X.loc[:,embedded_col_names].copy().values.astype(np.int64) #categorical columns\n",
    "        self.X2 = X.drop(columns=embedded_col_names).copy().values.astype(np.float32) #numerical columns\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X1[idx], self.X2[idx], self.y[idx]\n",
    "    \n",
    "## Train and Valid datasets\n",
    "\n",
    "train_ds = ShelterOutcomeDataset(X_train, y_train, embedded_col_names)\n",
    "valid_ds = ShelterOutcomeDataset(X_val, y_val, embedded_col_names)\n",
    "\n",
    "## CPU or GPU selection\n",
    "\n",
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "    \n",
    "\n",
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
    "    if isinstance(data, (list,tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "\n",
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl: \n",
    "            yield to_device(b, self.device)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "device = get_default_device()\n",
    "\n",
    "\n",
    "## Model\n",
    "\n",
    "class ShelterOutcomeModel(nn.Module):\n",
    "    def __init__(self, embedding_sizes, n_cont):\n",
    "        super().__init__()\n",
    "        self.embeddings = embedding_sizes\n",
    "        n_emb = sum(e.embedding_dim for e in self.embeddings) #length of all embeddings combined\n",
    "        self.n_emb, self.n_cont = n_emb, n_cont\n",
    "        self.lin1 = nn.Linear(self.n_emb + self.n_cont, 200)\n",
    "        self.lin2 = nn.Linear(200, 70)\n",
    "        self.lin3 = nn.Linear(70, 2)\n",
    "        self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "        self.bn2 = nn.BatchNorm1d(200)\n",
    "        self.bn3 = nn.BatchNorm1d(70)\n",
    "        self.emb_drop = nn.Dropout(0.6)\n",
    "        self.drops = nn.Dropout(0.3)\n",
    "        \n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.emb_drop(x)\n",
    "        x2 = self.bn1(x_cont)\n",
    "        x = torch.cat([x, x2], 1)\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.drops(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lin3(x)\n",
    "        return x\n",
    "    \n",
    "model = ShelterOutcomeModel(embedding_sizes, 4)\n",
    "to_device(model, device)\n",
    "\n",
    "## Define Optimizer\n",
    "\n",
    "def get_optimizer(model, lr = 0.001, wd = 0.0):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
    "    return optim\n",
    "\n",
    "## Train Model\n",
    "\n",
    "def train_model(model, optim, train_dl):\n",
    "    model.train()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    for x1, x2, y in train_dl:\n",
    "        batch = y.shape[0]\n",
    "        output = model(x1, x2)\n",
    "        loss = F.cross_entropy(output, y)   \n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        total += batch\n",
    "        sum_loss += batch*(loss.item())\n",
    "    return sum_loss/total\n",
    "\n",
    "\n",
    "def val_loss(model, valid_dl):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    sum_loss = 0\n",
    "    correct = 0\n",
    "    for x1, x2, y in valid_dl:\n",
    "        current_batch_size = y.shape[0]\n",
    "        out = model(x1, x2)\n",
    "        loss = F.cross_entropy(out, y)\n",
    "        sum_loss += current_batch_size*(loss.item())\n",
    "        total += current_batch_size\n",
    "        pred = torch.max(out, 1)[1]\n",
    "        correct += (pred == y).float().sum().item()\n",
    "    print(\"valid loss %.3f and accuracy %.3f\" % (sum_loss/total, correct/total))\n",
    "    return sum_loss/total, correct/total\n",
    "\n",
    "def train_loop(model, epochs, lr=0.01, wd=0.0):\n",
    "    optim = get_optimizer(model, lr = lr, wd = wd)\n",
    "    for i in range(epochs): \n",
    "        loss = train_model(model, optim, train_dl)\n",
    "        print(\"training loss: \", loss)\n",
    "        val_loss(model, valid_dl)\n",
    "        \n",
    "        \n",
    "batch_size = 1000\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size,shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=batch_size,shuffle=True)\n",
    "\n",
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)\n",
    "\n",
    "\n",
    "train_loop(model, epochs=8, lr=0.05, wd=0.00001)\n",
    "torch.save(model.state_dict(), \"state_model.pt\")\n",
    "\n",
    "bucket = os.environ['AIP_MODEL_DIR'].split('/')[2]\n",
    "blob_name = '/'.join(os.environ['AIP_MODEL_DIR'].split('/')[3:])\n",
    "\n",
    "storage_client = storage.Client(project=args.project)\n",
    "bucket = storage_client.bucket(bucket)\n",
    "\n",
    "files_to_upload = [\"label.pkl\", \"std_scaler.pkl\", \"state_model.pt\", \"emb.pkl\"]\n",
    "\n",
    "for i in files_to_upload:\n",
    "    blob = bucket.blob(blob_name+i)\n",
    "    blob.upload_from_filename(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f06611d-fefc-43fc-8275-576128db4a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting source/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile source/Dockerfile\n",
    "FROM python:3.8\n",
    "\n",
    "COPY . /\n",
    "\n",
    "RUN pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 && \\\n",
    "    pip install google-cloud-storage && \\\n",
    "    pip install pandas && \\\n",
    "    pip install gcsfs && \\\n",
    "    pip install scikit-learn\n",
    "\n",
    "ENTRYPOINT [\"python\", \"trainer/train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e42fa9-debb-47f3-8d8e-b8b46d48493d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!gcloud builds submit -t $TRAIN_IMAGE_URI source/."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c511604d-3c13-43e2-b251-5ed504848116",
   "metadata": {},
   "source": [
    "## Training Job (CustomJob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd16c2c-6796-46c7-811d-d159a5884d3b",
   "metadata": {},
   "source": [
    "To speed up the training a GPU NVIDIA Tesla T4 is used, it should take around 2 minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2214fe8c-804d-4c8b-88b5-5a3601b9d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as aip\n",
    "\n",
    "aip.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION)\n",
    "\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        'machine_spec' : {\n",
    "            'machine_type': 'n1-standard-4',\n",
    "            'accelerator_type': 'NVIDIA_TESLA_T4',\n",
    "            'accelerator_count': 1\n",
    "        },\n",
    "        'replica_count': 1,\n",
    "        \n",
    "        'container_spec': {\n",
    "            'image_uri': TRAIN_IMAGE_URI,\n",
    "            'args': [\n",
    "                '--dataset_uri='+f'{DATASET_URI}',\n",
    "                '--project='+f'{PROJECT_ID}',\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "job = aip.CustomJob(\n",
    "    display_name = 'ecommerce_custom_py',\n",
    "    worker_pool_specs = worker_pool_specs,\n",
    "    base_output_dir = MODEL_URI,\n",
    "    staging_bucket = STAGING_URI\n",
    ")\n",
    "\n",
    "model = job.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169928f-3d93-47ae-83dc-dbf10e923d29",
   "metadata": {},
   "source": [
    "## Creating Custom Container for Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2bd063-39bb-435e-877f-ca6095f7d9d0",
   "metadata": {},
   "source": [
    "#### The method I'm using is called Custom Prediction Routines, where we specify load, preprocess and prediction methods and Vertex will do the rest for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce845f0b-b8af-4d3a-a02d-4d4516d251c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_SRC_DIR = \"src_dir_pytorch\"  # @param {type:\"string\"}\n",
    "IMAGE_URI = \"us-central1-docker.pkg.dev/jchavezar-demo/custom-predictions/pytorch-ecommerce-container:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16b6cabc-0dff-4104-afa2-c16236814489",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr $USER_SRC_DIR\n",
    "!mkdir $USER_SRC_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e4e2a7b-daa8-41d9-870b-107ea75ea884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src_dir_pytorch/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile $USER_SRC_DIR/requirements.txt\n",
    "fastapi\n",
    "uvicorn==0.17.6\n",
    "pandas\n",
    "torch\n",
    "scikit-learn\n",
    "google-cloud-storage>=1.26.0,<2.0.0dev\n",
    "google-cloud-aiplatform[prediction]>=1.16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17c60eb-c3ab-4e0c-a310-f8b7d9588a72",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -r $USER_SRC_DIR/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34f41d67-01cf-429c-9fbe-cd720a6055e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://vtx-models/pytorch/ecommerce/c-container/model/emb.pkl...\n",
      "Copying gs://vtx-models/pytorch/ecommerce/c-container/model/label.pkl...        \n",
      "Copying gs://vtx-models/pytorch/ecommerce/c-container/model/state_model.pt...   \n",
      "Copying gs://vtx-models/pytorch/ecommerce/c-container/model/std_scaler.pkl...   \n",
      "/ [4 files][379.2 KiB/379.2 KiB]                                                \n",
      "Operation completed over 4 objects/379.2 KiB.                                    \n"
     ]
    }
   ],
   "source": [
    "## Copy all the Artifacts from Vertex Custom Training\n",
    "!gsutil cp $MODEL_URI/model/* $USER_SRC_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c9c287-06fc-4586-a80a-1f89afaeebd1",
   "metadata": {},
   "source": [
    "#### PyTorch has issues with libraries so I highly recommend install their packages with conda:\n",
    "\n",
    "$ conda install pytorch torchvision torchaudio cpuonly -c pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bcf3f2c0-c09e-4052-8731-dd51509d03bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing src_dir_pytorch/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $USER_SRC_DIR/predictor.py\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from typing import Dict\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as torch_optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "\n",
    "\n",
    "class CustomPyTorchPredictor(Predictor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.embedded_col_names = ['source', 'medium', 'channelGrouping', 'deviceCategory', 'country']\n",
    "        self.columns = [ \"latest_ecommerce_progress\" , \"bounces\", \"time_on_site\", \"pageviews\", \"source\", \"medium\", \"channelGrouping\", \"deviceCategory\", \"country\"]\n",
    "\n",
    "            \n",
    "    def preprocess(self, prediction_input: Dict) -> torch.utils.data.dataloader.DataLoader:\n",
    "        instances = prediction_input[\"instances\"]\n",
    "        data = pd.DataFrame(instances, columns = self.columns)\n",
    "        ## Prepare Data        \n",
    "        embedded_col_names = ['source', 'medium', 'channelGrouping', 'deviceCategory', 'country']\n",
    "        \n",
    "        def preprocessing_data(df):\n",
    "            import pickle\n",
    "            \n",
    "            standarization = pickle.load(open(\"std_scaler.pkl\", \"rb\"))\n",
    "            labelencoder = pickle.load(open(\"label.pkl\", \"rb\"))\n",
    "    \n",
    "            target = 'will_buy_on_return_visit'\n",
    "            cat_columns = [i for i in df.columns if df[i].dtypes == 'object']\n",
    "            num_columns = [i for i in df.columns if df[i].dtypes == 'int64' or df[i].dtypes == 'float']\n",
    "\n",
    "            cat_df = df[cat_columns]\n",
    "            num_df = df[num_columns]\n",
    "    \n",
    "            cat_df = cat_df.apply(lambda x: labelencoder[x.name].transform(x))\n",
    "            cat_df = cat_df.astype('category')\n",
    "    \n",
    "            df = pd.concat([cat_df, num_df], axis=1)\n",
    "            df[num_columns] = standarization.transform(df[num_columns])\n",
    "            \n",
    "            return df\n",
    "\n",
    "        class PredictData(Dataset):\n",
    "            def __init__(self, X):\n",
    "                embedded_col_names = ['source', 'medium', 'channelGrouping', 'deviceCategory', 'country']\n",
    "                self.X1 = X.loc[:,embedded_col_names].copy().values.astype(np.int64)\n",
    "                self.X2 = X.drop(columns=embedded_col_names).copy().values.astype(np.float32)\n",
    "\n",
    "            def __getitem__(self, index):\n",
    "                return self.X1[index], self.X2[index]\n",
    "\n",
    "            def __len__ (self):\n",
    "                return len(self.X1)\n",
    "        \n",
    "        prep_df = DataLoader(PredictData(preprocessing_data(data)))\n",
    "        return prep_df\n",
    "    \n",
    "    def load(self, artifacts_uri: str):\n",
    "        \"\"\"Loads the model artifacts.\"\"\"\n",
    "        prediction_utils.download_model_artifacts(artifacts_uri)\n",
    "        self.embeddings = pickle.load(open('emb.pkl', 'rb'))\n",
    "        class ShelterOutcomeModel(nn.Module):\n",
    "            def __init__(self, embedding_sizes, n_cont):\n",
    "                super().__init__()\n",
    "                self.embeddings = embedding_sizes\n",
    "                n_emb = sum(e.embedding_dim for e in self.embeddings) #length of all embeddings combined\n",
    "                self.n_emb, self.n_cont = n_emb, 4\n",
    "                self.lin1 = nn.Linear(self.n_emb + self.n_cont, 200)\n",
    "                self.lin2 = nn.Linear(200, 70)\n",
    "                self.lin3 = nn.Linear(70, 2)\n",
    "                self.bn1 = nn.BatchNorm1d(self.n_cont)\n",
    "                self.bn2 = nn.BatchNorm1d(200)\n",
    "                self.bn3 = nn.BatchNorm1d(70)\n",
    "                self.emb_drop = nn.Dropout(0.6)\n",
    "                self.drops = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "            def forward(self, x_cat, x_cont):\n",
    "                x = [e(x_cat[:,i]) for i,e in enumerate(self.embeddings)]\n",
    "                x = torch.cat(x, 1)\n",
    "                x = self.emb_drop(x)\n",
    "                x2 = self.bn1(x_cont)\n",
    "                x = torch.cat([x, x2], 1)\n",
    "                x = F.relu(self.lin1(x))\n",
    "                x = self.drops(x)\n",
    "                x = self.bn2(x)\n",
    "                x = F.relu(self.lin2(x))\n",
    "                x = self.drops(x)\n",
    "                x = self.bn3(x)\n",
    "                x = self.lin3(x)\n",
    "                return x\n",
    "            \n",
    "        device = torch.device('cpu')\n",
    "        self._model = ShelterOutcomeModel(self.embeddings, 4)\n",
    "        self._model.load_state_dict(torch.load(\"state_model.pt\", map_location=device))\n",
    "        \n",
    "    @torch.inference_mode()\n",
    "    def predict(self, instances: torch.utils.data.dataloader.DataLoader) -> list:\n",
    "        \"\"\"Performs prediction.\"\"\"\n",
    "        preds = []\n",
    "        self._model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x1,x2 in instances:\n",
    "                out = self._model(x1,x2)\n",
    "                prob = F.softmax(out, dim=1)\n",
    "                preds.append(prob)\n",
    "        final_probs = [item for sublist in preds for item in sublist]\n",
    "        predicted = [0 if t[0] > 0.5 else 1 for t in final_probs]\n",
    "        print(predicted)\n",
    "        return predicted\n",
    "\n",
    "    def postprocess(self, prediction_results: list) -> Dict:\n",
    "        return {\"predictions\": prediction_results}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f7fafe-6348-4efa-96bd-b22fe7970392",
   "metadata": {},
   "source": [
    "## Authentication\n",
    "\n",
    "The easiest way to handle AuthN/AuthZ for next steps is by login with application credentials, this method will store json credential locally here: **/home/jupyter/.config/gcloud/application_default_credentials.json**\n",
    "\n",
    "!gcloud auth application-default login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22334484-dd5b-40f5-9e03-ada467788e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREDENTIALS_FILE = \"/home/jupyter/.config/gcloud/application_default_credentials.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ebc51ec8-f52e-49a7-9646-7d56345f7ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cpr/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/envs/cpr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from src_dir_pytorch.predictor import \\\n",
    "    CustomPyTorchPredictor  # Update this path as the variable $USER_SRC_DIR to import the custom predictor.\n",
    "\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    USER_SRC_DIR,\n",
    "    IMAGE_URI,\n",
    "    predictor=CustomPyTorchPredictor,\n",
    "    requirements_path=os.path.join(USER_SRC_DIR, \"requirements.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d492b37-1ea8-47b9-9f5c-14a2d6098998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-central1-docker.pkg.dev/jchavezar-demo/custom-predictions/pytorch-ecommerce-container:latest\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbef1317-6736-43c4-a9a2-a05cbdfe83e0",
   "metadata": {},
   "source": [
    "##  Test Model Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a042807-064e-4207-901e-afa7534a8f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb6e39c6-7939-420e-b881-b2fc112f9ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "{\n",
    "    \"instances\": [\n",
    "        [0, 0, 142, 5.0, \"(direct)\", \"(none)\", \"Direct\", \"mobile\", \"Argentina\"]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4760d5ca-43c8-4660-9106-1d6abf59d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"{MODEL_URI}/model\",\n",
    "    credential_path = CREDENTIALS_FILE,\n",
    ") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file = INPUT_FILE,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e616c6-74a8-42b9-badf-fe02d2c91b25",
   "metadata": {},
   "source": [
    "*To verify if the container returns response expected, go to terminal and run* **docker ps -a** and *then* **docker logs 'container_latest_name'**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a7b93-1e7f-473d-9c0a-57f0212ebc1e",
   "metadata": {},
   "source": [
    "## Deploy to Vertex AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "410ba357-ae48-4f34-aeae-01e93bc161ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cpr/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/envs/cpr/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "local_model.push_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeb2b67-cebd-4c07-a152-ad25afadaec1",
   "metadata": {},
   "source": [
    "## Upload Model to Vertex Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b8320140-5b45-4986-b787-261843137f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/569083142710/locations/us-central1/models/1271794104732221440/operations/5628930880543129600\n",
      "Model created. Resource name: projects/569083142710/locations/us-central1/models/1271794104732221440@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/569083142710/locations/us-central1/models/1271794104732221440@1')\n"
     ]
    }
   ],
   "source": [
    "model = aip.Model.upload(\n",
    "    local_model=local_model,\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=f\"{MODEL_URI}/model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51a39c-3cd4-445f-b44b-33e8288ba5de",
   "metadata": {},
   "source": [
    "## Deploy Model using Vertex Endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bd5a22b2-56ea-4f9a-9670-e72e61593272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/569083142710/locations/us-central1/endpoints/5553628833850064896/operations/5093002524886040576\n",
      "Endpoint created. Resource name: projects/569083142710/locations/us-central1/endpoints/5553628833850064896\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/569083142710/locations/us-central1/endpoints/5553628833850064896')\n",
      "Deploying model to Endpoint : projects/569083142710/locations/us-central1/endpoints/5553628833850064896\n",
      "Deploy Endpoint model backing LRO: projects/569083142710/locations/us-central1/endpoints/5553628833850064896/operations/8475205845041283072\n",
      "Endpoint model deployed. Resource name: projects/569083142710/locations/us-central1/endpoints/5553628833850064896\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d0e919-79dc-4402-a9a8-d005da08a853",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b9d2b428-f9c0-4ec2-893d-57a48e04ed38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"predictions\": [\n",
      "    0\n",
      "  ],\n",
      "  \"deployedModelId\": \"6247860475627831296\",\n",
      "  \"model\": \"projects/569083142710/locations/us-central1/models/1271794104732221440\",\n",
      "  \"modelDisplayName\": \"pytorch-ecommerce-c-container\",\n",
      "  \"modelVersionId\": \"1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "! curl -X POST -H \"Authorization: Bearer $(gcloud auth print-access-token)\" -H \"Content-Type: application/json\" https://us-central1-aiplatform.googleapis.com/v1/$endpoint.gca_resource.name:predict -d \"@$INPUT_FILE\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d3f4aa-a86e-40cf-aeee-a887b5e25ee8",
   "metadata": {},
   "source": [
    "## Destroy Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "685c1af4-9504-4618-b785-e7f31705f58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Undeploying Endpoint model: projects/569083142710/locations/us-central1/endpoints/5553628833850064896\n",
      "Undeploy Endpoint model backing LRO: projects/569083142710/locations/us-central1/endpoints/5553628833850064896/operations/8163331570845876224\n",
      "Endpoint model undeployed. Resource name: projects/569083142710/locations/us-central1/endpoints/5553628833850064896\n"
     ]
    }
   ],
   "source": [
    "endpoint.undeploy(deployed_model_id=endpoint.gca_resource.deployed_models[0].id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f06e5b71-b05b-4c00-9f61-c41ec37da923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Endpoint : projects/569083142710/locations/us-central1/endpoints/5553628833850064896\n",
      "Delete Endpoint  backing LRO: projects/569083142710/locations/us-central1/operations/732392185684557824\n",
      "Endpoint deleted. . Resource name: projects/569083142710/locations/us-central1/endpoints/5553628833850064896\n"
     ]
    }
   ],
   "source": [
    "endpoint.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45f3654f-35bc-48ca-b8a7-cddd1e2408f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting Model : projects/569083142710/locations/us-central1/models/1271794104732221440\n",
      "Delete Model  backing LRO: projects/569083142710/locations/us-central1/operations/3946836419720249344\n",
      "Model deleted. . Resource name: projects/569083142710/locations/us-central1/models/1271794104732221440\n"
     ]
    }
   ],
   "source": [
    "model.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "84a7b65f-1407-452c-8dbe-4952516a831a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr $USER_SRC_DIR\n",
    "!rm -fr instances.json\n",
    "!rm -fr source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa7a326-7ad2-4b03-b150-448159b81c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "cpr",
   "name": "tf2-gpu.2-10.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
