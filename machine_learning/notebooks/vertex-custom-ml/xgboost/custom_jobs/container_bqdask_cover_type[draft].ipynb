{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73ed3c99-40e5-4c84-8f27-73fedcff2d5f",
   "metadata": {},
   "source": [
    "CoverType is a dataset with forest cartographic variables, this is a multiclassification tabular job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b7a80c-6122-4e76-abbe-6e58146eef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'jchavezar-demo'\n",
    "REGION = 'us-central1'\n",
    "DIR = 'xgboost_custom'\n",
    "#DATASET_URI = 'gs://vtx-datasets-public/ecommerce/datasets.csv'\n",
    "MODEL_URI = 'gs://vtx-models/xgboost/cover_type'\n",
    "STAGING_URI = 'gs://vtx-staging/xgboost/cover_type/'\n",
    "TRAIN_IMAGE_URI = 'us-central1-docker.pkg.dev/jchavezar-demo/trainings/xgboost-dask-gpu:latest'\n",
    "#PREDICTION_IMAGE_URI = 'us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-9:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a81c3519-92d4-4199-952d-b263352b1baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform as aip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dde5868e-4299-4f0e-894d-4e9f5873820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr $DIR\n",
    "!mkdir $DIR\n",
    "!mkdir $DIR/trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "176a264a-aa9e-4915-8e78-4c24a5329a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting xgboost_custom/trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $DIR/trainer/train.py\n",
    "import os\n",
    "import json\n",
    "import dask\n",
    "import argparse\n",
    "import subprocess\n",
    "import dask_bigquery\n",
    "import xgboost as xgb\n",
    "from google.cloud import storage\n",
    "from xgboost import dask as dxgb\n",
    "from dask.distributed import Client\n",
    "from dask_cuda import LocalCUDACluster\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--project',\n",
    "        type = str,\n",
    "        default = os.environ['CLOUD_ML_PROJECT_ID'],\n",
    "        help = 'This is the tenant or the Google Cloud project id name'\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--bq_table_dir\",\n",
    "        type = str,\n",
    "        help = \"BigQuery Dataset URI in the format [DATASET].[TABLE]\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--num_workers', type=int, help='num of workers',\n",
    "        default=2\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        '--threads_per_worker', type=int, help='num of threads per worker',\n",
    "        default=4\n",
    "    )\n",
    "    return parser.parse_args()\n",
    "\n",
    "def load_data(dataset: str):\n",
    "    '''Load data from BigQuery to Dask'''\n",
    "    _ = dataset.split('.')\n",
    "    \n",
    "    ddf = dask_bigquery.read_gbq(\n",
    "        project_id='jchavezar-demo',\n",
    "        dataset_id=_[0],\n",
    "        table_id=_[1]\n",
    "    ).dropna()\n",
    "    \n",
    "    print(f\"[INFO] ------ Splitting dataset\")\n",
    "    df_train, df_eval = ddf.random_split([0.8, 0.2], random_state=123)\n",
    "    df_train_features = df_train.drop('Cover_Type', axis=1)\n",
    "    df_eval_features = df_eval.drop('Cover_Type', axis=1)\n",
    "    df_train_labels = df_train.pop('Cover_Type')\n",
    "    df_eval_labels = df_eval.pop('Cover_Type')\n",
    "    \n",
    "    return df_train_features, df_eval_features, df_train_labels, df_eval_labels\n",
    "    \n",
    "def model_train(\n",
    "    args,\n",
    "    df_train_features: dask.dataframe, \n",
    "    df_eval_features: dask.dataframe, \n",
    "    df_train_labels: dask.dataframe, \n",
    "    df_eval_labels: dask.dataframe\n",
    "):\n",
    "    print(\"[INFO] ------ Creating dask cluster\")\n",
    "    scheduler_ip =  subprocess.check_output(['hostname','--all-ip-addresses'])\n",
    "    scheduler_ip = scheduler_ip.decode('UTF-8').split()[0]\n",
    "    \n",
    "    with LocalCUDACluster(\n",
    "        ip=scheduler_ip,\n",
    "        n_workers=args.num_workers, \n",
    "        threads_per_worker=args.threads_per_worker\n",
    "    ) as cluster:\n",
    "        with Client(cluster) as client:\n",
    "            print('[INFO]: ------ Calling main function ')\n",
    "            \n",
    "            print(\"[INFO] ------ Dataset for dask\")\n",
    "            dtrain = dxgb.DaskDeviceQuantileDMatrix(client, df_train_features, df_train_labels)\n",
    "            dvalid = dxgb.DaskDeviceQuantileDMatrix(client, df_eval_features, df_eval_labels)\n",
    "            \n",
    "            output = xgb.dask.train(\n",
    "                client,\n",
    "                {\n",
    "                    \"verbosity\": 2, \n",
    "                    \"tree_method\": \"gpu_hist\", \n",
    "                    \"objective\": \"multi:softprob\",\n",
    "                    \"eval_metric\": [\"mlogloss\"],\n",
    "                    \"learning_rate\": 0.1,\n",
    "                    \"gamma\": 0.9,\n",
    "                    \"subsample\": 0.5,\n",
    "                    \"max_depth\": 9,\n",
    "                    \"num_class\": 8\n",
    "                },\n",
    "                dtrain,\n",
    "                num_boost_round=10,\n",
    "                evals=[(dvalid, \"valid1\")],\n",
    "                early_stopping_rounds=5\n",
    "            )\n",
    "\n",
    "        model = output[\"booster\"]\n",
    "        best_model = output[\"booster\"][: model.best_iteration]\n",
    "        best_model.save('/tmp/model.json')\n",
    "        model_metrics = output[\"history\"][\"valid1\"]\n",
    "        with open(\"/tmp/metadata.json\", \"w\") as outfile:\n",
    "            json.dump(model_metrics, outfile)\n",
    "            \n",
    "def store_artifacts(args, model_file, model_metrics_files):\n",
    "    print('[INFO] ------ Storing Artifacts on Google Cloud Storage')\n",
    "    artifacts = [model_file, model_metrics_files]\n",
    "    bucket = os.environ['AIP_MODEL_DIR'].split('/')[2]\n",
    "    blob_name = '/'.join(os.environ['AIP_MODEL_DIR'].split('/')[3:])\n",
    "    print(args.project)\n",
    "    storage_client = storage.Client(project=args.project)\n",
    "    bucket = storage_client.bucket(bucket)\n",
    "\n",
    "    for i in artifacts:\n",
    "        blob = bucket.blob(f'cover_type/{i}')\n",
    "        blob.upload_from_filename(f'/tmp/{i}')\n",
    "        \n",
    "def main():\n",
    "    # set constants\n",
    "    model_file = \"model.json\"\n",
    "    model_metrics_file = \"metadata.json\"\n",
    "    args = get_args()\n",
    "    df_train_features, df_eval_features, df_train_labels, df_eval_labels = load_data(args.bq_table_dir)\n",
    "    model_train(args, df_train_features, df_eval_features, df_train_labels, df_eval_labels)\n",
    "    store_artifacts(args, model_file, model_metrics_file)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "493fb0ff-d53a-4a6f-aee1-ca52fb822d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting xgboost_custom/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile $DIR/Dockerfile\n",
    "FROM rapidsai/rapidsai-nightly:22.12-cuda11.2-base-ubuntu20.04-py3.8\n",
    "\n",
    "RUN pip install google-cloud-storage \\\n",
    "  && pip install gcsfs \\\n",
    "  && pip install pandas \\\n",
    "  && pip install dask-bigquery\n",
    "\n",
    "COPY trainer trainer/\n",
    "\n",
    "ENTRYPOINT [\"python\", \"trainer/train.py\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343159b8-355f-4d41-8c56-17326f91ae66",
   "metadata": {},
   "source": [
    "## Crete Image and Push it to Google Artifacts Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "82e5c2f8-5d85-4642-8756-1cf2c66d0127",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon   7.68kB\n",
      "Step 1/4 : FROM rapidsai/rapidsai-nightly:22.12-cuda11.2-base-ubuntu20.04-py3.8\n",
      " ---> fbadf85eb205\n",
      "Step 2/4 : RUN pip install google-cloud-storage   && pip install gcsfs   && pip install pandas   && pip install dask-bigquery\n",
      " ---> Using cache\n",
      " ---> c82daf08c0ca\n",
      "Step 3/4 : COPY trainer trainer/\n",
      " ---> c4031350fda1\n",
      "Step 4/4 : ENTRYPOINT [\"python\", \"trainer/train.py\"]\n",
      " ---> Running in 1d828d83a5b2\n",
      "Removing intermediate container 1d828d83a5b2\n",
      " ---> 5828321237af\n",
      "Successfully built 5828321237af\n",
      "Successfully tagged us-central1-docker.pkg.dev/jchavezar-demo/trainings/xgboost-dask-gpu:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t $TRAIN_IMAGE_URI $DIR/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ddee9fa8-6cc2-46aa-a6f3-2556848d985c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [us-central1-docker.pkg.dev/jchavezar-demo/trainings/xgboost-dask-gpu]\n",
      "\n",
      "\u001b[1B55002f17: Preparing \n",
      "\u001b[1B7871a528: Preparing \n",
      "\u001b[1B10f8ab46: Preparing \n",
      "\u001b[1Ba60296d0: Preparing \n",
      "\u001b[1B04ce2dbe: Preparing \n",
      "\u001b[1B8d70af49: Preparing \n",
      "\u001b[1B57cc060a: Preparing \n",
      "\u001b[1Bf22f7d2b: Preparing \n",
      "\u001b[1Be8b67dbb: Preparing \n",
      "\u001b[1B4e28b8f7: Preparing \n",
      "\u001b[1Bfdd7be17: Preparing \n",
      "\u001b[1B070c6f18: Preparing \n",
      "\u001b[13B5002f17: Pushed lready exists 2kB\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2K\u001b[13A\u001b[2Klatest: digest: sha256:b6b7dc92fb4c5676951d468859843b50e1b1b98f2b1c2c4df413ddb92437e339 size: 3064\n"
     ]
    }
   ],
   "source": [
    "!docker push $TRAIN_IMAGE_URI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548506d3-8adb-402f-b697-191d5668d9b2",
   "metadata": {},
   "source": [
    "## Create Vertex Training from Code [CustomJob]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9dd518d0-afad-4153-a307-980cc9c0497c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CustomJob\n",
      "CustomJob created. Resource name: projects/569083142710/locations/us-central1/customJobs/8907149331610468352\n",
      "To use this CustomJob in another session:\n",
      "custom_job = aiplatform.CustomJob.get('projects/569083142710/locations/us-central1/customJobs/8907149331610468352')\n",
      "View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8907149331610468352?project=569083142710\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "CustomJob projects/569083142710/locations/us-central1/customJobs/8907149331610468352 current state:\n",
      "JobState.JOB_STATE_FAILED\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 3\nmessage: \"The replica workerpool0-0 exited with a non-zero status of 1. To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=569083142710&resource=ml_job%2Fjob_id%2F8907149331610468352&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%228907149331610468352%22\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28757/3418631971.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m model = job.run(\n\u001b[0m\u001b[1;32m     34\u001b[0m )\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, timeout, restart_job_on_worker_restart, enable_web_access, tensorboard, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m   1581\u001b[0m             \u001b[0mtensorboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m             \u001b[0msync\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1583\u001b[0;31m             \u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_request_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1584\u001b[0m         )\n\u001b[1;32m   1585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    808\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, service_account, network, timeout, restart_job_on_worker_restart, enable_web_access, tensorboard, sync, create_request_timeout)\u001b[0m\n\u001b[1;32m   1679\u001b[0m             )\n\u001b[1;32m   1680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_JOB_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 3\nmessage: \"The replica workerpool0-0 exited with a non-zero status of 1. To find out more about why your job exited please check the logs: https://console.cloud.google.com/logs/viewer?project=569083142710&resource=ml_job%2Fjob_id%2F8907149331610468352&advancedFilter=resource.type%3D%22ml_job%22%0Aresource.labels.job_id%3D%228907149331610468352%22\"\n"
     ]
    }
   ],
   "source": [
    "aip.init(\n",
    "    project=PROJECT_ID,\n",
    "    location=REGION)\n",
    "\n",
    "num_gpus = 4\n",
    "\n",
    "worker_pool_specs = [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-32\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": 4\n",
    "        },\n",
    "        \"replica_count\": \"1\",\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_IMAGE_URI,\n",
    "            \"args\": [\n",
    "                \"--bq_table_dir\", \"vertex_datasets_public.cover_type_4Mrows\",\n",
    "                \"--num_workers\", f\"{num_gpus}\",\n",
    "                \"--threads_per_worker\", \"4\" \n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    ]\n",
    "\n",
    "job = aip.CustomJob(\n",
    "    display_name = '05cb-bqdask-xgboost-customjob',\n",
    "    worker_pool_specs = worker_pool_specs,\n",
    "    base_output_dir = MODEL_URI,\n",
    "    staging_bucket = STAGING_URI\n",
    ")\n",
    "\n",
    "model = job.run(\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423f67b6-2704-415a-9377-5d39d5c2cc72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb49ea-222c-4ad4-8599-45b6dda4e227",
   "metadata": {},
   "outputs": [],
   "source": [
    "            \"command\": [\n",
    "                \"python\",\n",
    "                \"trainer/train.py\"\n",
    "            ],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b7e20504-b226-4e34-a546-7d8a01588337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "testing\n"
     ]
    }
   ],
   "source": [
    "def test(data: str):\n",
    "    print(args)\n",
    "    print(data)\n",
    "    \n",
    "def main():\n",
    "    args = 'x'\n",
    "    test('testing')\n",
    "\n",
    "main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca79ba-2836-47ed-9f91-c60478642c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
