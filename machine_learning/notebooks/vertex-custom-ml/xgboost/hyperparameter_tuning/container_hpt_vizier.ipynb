{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperpot\n",
    "\n",
    "Regular training local with hyper parameter tuning using Hyperpot and Vizier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/Wholesale customers data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('datasets/'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>29703</td>\n",
       "      <td>12051</td>\n",
       "      <td>16027</td>\n",
       "      <td>13135</td>\n",
       "      <td>182</td>\n",
       "      <td>2204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>39228</td>\n",
       "      <td>1431</td>\n",
       "      <td>764</td>\n",
       "      <td>4510</td>\n",
       "      <td>93</td>\n",
       "      <td>2346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>14531</td>\n",
       "      <td>15488</td>\n",
       "      <td>30243</td>\n",
       "      <td>437</td>\n",
       "      <td>14841</td>\n",
       "      <td>1867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10290</td>\n",
       "      <td>1981</td>\n",
       "      <td>2232</td>\n",
       "      <td>1038</td>\n",
       "      <td>168</td>\n",
       "      <td>2125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2787</td>\n",
       "      <td>1698</td>\n",
       "      <td>2510</td>\n",
       "      <td>65</td>\n",
       "      <td>477</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>440 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Channel  Region  Fresh   Milk  Grocery  Frozen  Detergents_Paper  \\\n",
       "0          2       3  12669   9656     7561     214              2674   \n",
       "1          2       3   7057   9810     9568    1762              3293   \n",
       "2          2       3   6353   8808     7684    2405              3516   \n",
       "3          1       3  13265   1196     4221    6404               507   \n",
       "4          2       3  22615   5410     7198    3915              1777   \n",
       "..       ...     ...    ...    ...      ...     ...               ...   \n",
       "435        1       3  29703  12051    16027   13135               182   \n",
       "436        1       3  39228   1431      764    4510                93   \n",
       "437        2       3  14531  15488    30243     437             14841   \n",
       "438        1       3  10290   1981     2232    1038               168   \n",
       "439        1       3   2787   1698     2510      65               477   \n",
       "\n",
       "     Delicassen  \n",
       "0          1338  \n",
       "1          1776  \n",
       "2          7844  \n",
       "3          1788  \n",
       "4          5185  \n",
       "..          ...  \n",
       "435        2204  \n",
       "436        2346  \n",
       "437        1867  \n",
       "438        2125  \n",
       "439          52  \n",
       "\n",
       "[440 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'datasets/{filename}')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops\n",
    "\n",
    "X = df.drop('Channel', axis=1)\n",
    "y = df['Channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels into binary values\n",
    "\n",
    "y[y == 2] = 0\n",
    "y[y == 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for training\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "space={\n",
    "    'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "    'gamma': hp.uniform ('gamma', 1,9),\n",
    "    'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "    'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "    'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "    'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "    'n_estimators': 180,\n",
    "    'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators =space['n_estimators'], \n",
    "                    max_depth = int(space['max_depth']), \n",
    "                    gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),\n",
    "                    min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "\n",
    "    xgb_params = {}\n",
    "    xgb_params['eval_metric']='auc'\n",
    "    xgb_params['early_stopping_rounds']=10 \n",
    "\n",
    "    clf.set_params(**xgb_params)\n",
    "    \n",
    "    clf.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        eval_set=evaluation, \n",
    "        verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_metric': 'auc', 'early_stopping_rounds': 10}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "xgb_params = {}\n",
    "xgb_params['eval_metric']='auc'\n",
    "xgb_params['early_stopping_rounds']=10 \n",
    "xgb_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                 \n",
      "0.3484848484848485                                     \n",
      "SCORE:                                                                            \n",
      "0.3484848484848485                                                                \n",
      "SCORE:                                                                            \n",
      "0.3484848484848485                                                                \n",
      "SCORE:                                                                            \n",
      "0.8712121212121212                                                                \n",
      "SCORE:                                                                            \n",
      "0.8863636363636364                                                                \n",
      "SCORE:                                                                            \n",
      "0.3484848484848485                                                                \n",
      "SCORE:                                                                            \n",
      "0.3484848484848485                                                                \n",
      "SCORE:                                                                            \n",
      "0.3484848484848485                                                                \n",
      "SCORE:                                                                            \n",
      "0.3484848484848485                                                                \n",
      "SCORE:                                                                            \n",
      "0.8939393939393939                                                                \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.6515151515151515                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.6515151515151515                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.6515151515151515                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.6515151515151515                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8939393939393939                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.3484848484848485                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8712121212121212                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8863636363636364                                                                 \n",
      "100%|██████████| 100/100 [00:13<00:00,  7.30trial/s, best loss: -0.8939393939393939]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8015834851378087, 'gamma': 4.160392182471469, 'max_depth': 9.0, 'min_child_weight': 7.0, 'reg_alpha': 74.0, 'reg_lambda': 0.8708226877745266}\n"
     ]
    }
   ],
   "source": [
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.8939393939393939\n"
     ]
    }
   ],
   "source": [
    "colsample_bytree=best_hyperparams[\"colsample_bytree\"]\n",
    "max_depth=best_hyperparams[\"max_depth\"]\n",
    "gamma=best_hyperparams[\"gamma\"]\n",
    "reg_alpha=best_hyperparams[\"reg_alpha\"]\n",
    "min_child_weight=best_hyperparams[\"min_child_weight\"]\n",
    "colsample_bytree=best_hyperparams[\"colsample_bytree\"]\n",
    "\n",
    "clf=xgb.XGBClassifier(\n",
    "    n_estimators =180, \n",
    "    max_depth = int(max_depth), \n",
    "    gamma = gamma,\n",
    "    reg_alpha = reg_alpha,\n",
    "    min_child_weight=min_child_weight,\n",
    "    colsample_bytree=colsample_bytree)\n",
    "\n",
    "evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "\n",
    "clf.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=evaluation, \n",
    "    verbose=False)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred>0.5)\n",
    "print (\"SCORE:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE: 0.8939393939393939\n"
     ]
    }
   ],
   "source": [
    "clf=xgb.XGBClassifier()\n",
    "\n",
    "evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "\n",
    "clf.fit(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    eval_set=evaluation, \n",
    "    verbose=False)\n",
    "\n",
    "pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred>0.5)\n",
    "print (\"SCORE:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel</th>\n",
       "      <th>Region</th>\n",
       "      <th>Fresh</th>\n",
       "      <th>Milk</th>\n",
       "      <th>Grocery</th>\n",
       "      <th>Frozen</th>\n",
       "      <th>Detergents_Paper</th>\n",
       "      <th>Delicassen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12669</td>\n",
       "      <td>9656</td>\n",
       "      <td>7561</td>\n",
       "      <td>214</td>\n",
       "      <td>2674</td>\n",
       "      <td>1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7057</td>\n",
       "      <td>9810</td>\n",
       "      <td>9568</td>\n",
       "      <td>1762</td>\n",
       "      <td>3293</td>\n",
       "      <td>1776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6353</td>\n",
       "      <td>8808</td>\n",
       "      <td>7684</td>\n",
       "      <td>2405</td>\n",
       "      <td>3516</td>\n",
       "      <td>7844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>13265</td>\n",
       "      <td>1196</td>\n",
       "      <td>4221</td>\n",
       "      <td>6404</td>\n",
       "      <td>507</td>\n",
       "      <td>1788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22615</td>\n",
       "      <td>5410</td>\n",
       "      <td>7198</td>\n",
       "      <td>3915</td>\n",
       "      <td>1777</td>\n",
       "      <td>5185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n",
       "0        0       3  12669  9656     7561     214              2674        1338\n",
       "1        0       3   7057  9810     9568    1762              3293        1776\n",
       "2        0       3   6353  8808     7684    2405              3516        7844\n",
       "3        1       3  13265  1196     4221    6404               507        1788\n",
       "4        0       3  22615  5410     7198    3915              1777        5185"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction Single Row\n",
    "\n",
    "x=pd.DataFrame(X_test.iloc[1,:]).T\n",
    "pred=clf.predict(x)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Vertex Vizier\n",
    "\n",
    "Standalone, vizier only gives you recommendations about the next trial but doesn't run the trial for you, for that we'll create a separate section called Using Vertex HPT+Vizier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "PROJECT_ID = \"jchavezar-demo\"\n",
    "REGION = \"us-central1\"\n",
    "STUDY_DISPLAY_NAME = \"{}_study_{}\".format(\n",
    "    PROJECT_ID.replace(\"-\", \"\"), datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\"))\n",
    "ENDPOINT = REGION + \"-aiplatform.googleapis.com\"\n",
    "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID, REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENDPOINT: us-central1-aiplatform.googleapis.com\n",
      "REGION: us-central1\n",
      "PARENT: projects/jchavezar-demo/locations/us-central1\n"
     ]
    }
   ],
   "source": [
    "print(\"ENDPOINT: {}\".format(ENDPOINT))\n",
    "print(\"REGION: {}\".format(REGION))\n",
    "print(\"PARENT: {}\".format(PARENT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter Configuration\n",
    "\n",
    "max_depth = {\"parameter_id\": \"max_depth\", \"integer_value_spec\": {\"min_value\": 3, \"max_value\": 18}}\n",
    "gamma = {\"parameter_id\": \"gamma\", \"integer_value_spec\": {\"min_value\": 1, \"max_value\": 9}}\n",
    "reg_alpha = {\"parameter_id\": \"reg_alpha\", \"integer_value_spec\": {\"min_value\": 1, \"max_value\": 9}}\n",
    "reg_lambda = {\"parameter_id\": \"reg_lambda\", \"integer_value_spec\": {\"min_value\": 0, \"max_value\": 1}}\n",
    "colsample_bytree = {\"parameter_id\": \"colsample_bytree\", \"double_value_spec\": {\"min_value\": 0.5, \"max_value\": 1.0}}\n",
    "min_child_weight = {\"parameter_id\": \"min_child_weight\", \"integer_value_spec\": {\"min_value\": 0, \"max_value\": 10.0}}\n",
    "\n",
    "metrics = {\"metric_id\": \"accuracy\", \"goal\": \"MAXIMIZE\"}\n",
    "\n",
    "study = {\n",
    "    \"display_name\": STUDY_DISPLAY_NAME,\n",
    "    \"study_spec\": {\n",
    "        \"algorithm\": \"RANDOM_SEARCH\",\n",
    "        \"parameters\": [\n",
    "            max_depth,\n",
    "            gamma,\n",
    "            reg_alpha,\n",
    "            reg_lambda,\n",
    "            colsample_bytree,\n",
    "            min_child_weight\n",
    "        ],\n",
    "        \"metrics\": [metrics],\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"display_name\": \"jchavezardemo_study_20220803_105855\",\n",
      "  \"study_spec\": {\n",
      "    \"algorithm\": \"RANDOM_SEARCH\",\n",
      "    \"metrics\": [\n",
      "      {\n",
      "        \"goal\": \"MAXIMIZE\",\n",
      "        \"metric_id\": \"accuracy\"\n",
      "      }\n",
      "    ],\n",
      "    \"parameters\": [\n",
      "      {\n",
      "        \"integer_value_spec\": {\n",
      "          \"max_value\": 18,\n",
      "          \"min_value\": 3\n",
      "        },\n",
      "        \"parameter_id\": \"max_depth\"\n",
      "      },\n",
      "      {\n",
      "        \"integer_value_spec\": {\n",
      "          \"max_value\": 9,\n",
      "          \"min_value\": 1\n",
      "        },\n",
      "        \"parameter_id\": \"gamma\"\n",
      "      },\n",
      "      {\n",
      "        \"integer_value_spec\": {\n",
      "          \"max_value\": 9,\n",
      "          \"min_value\": 1\n",
      "        },\n",
      "        \"parameter_id\": \"reg_alpha\"\n",
      "      },\n",
      "      {\n",
      "        \"integer_value_spec\": {\n",
      "          \"max_value\": 1,\n",
      "          \"min_value\": 0\n",
      "        },\n",
      "        \"parameter_id\": \"reg_lambda\"\n",
      "      },\n",
      "      {\n",
      "        \"double_value_spec\": {\n",
      "          \"max_value\": 1.0,\n",
      "          \"min_value\": 0.5\n",
      "        },\n",
      "        \"parameter_id\": \"colsample_bytree\"\n",
      "      },\n",
      "      {\n",
      "        \"integer_value_spec\": {\n",
      "          \"max_value\": 10.0,\n",
      "          \"min_value\": 0\n",
      "        },\n",
      "        \"parameter_id\": \"min_child_weight\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(study, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STUDY_ID: projects/569083142710/locations/us-central1/studies/2824667673603\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "vizier_client = aiplatform.gapic.VizierServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")\n",
    "study = vizier_client.create_study(parent=PARENT, study=study)\n",
    "STUDY_ID = study.name\n",
    "print(\"STUDY_ID: {}\".format(STUDY_ID))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "def objective(trial_id, max_depth, gamma, reg_alpha, reg_lambda, colsample_bytree, min_child_weight):\n",
    "    print((\"=========== Start Trial: [{}] =============\").format(trial_id))\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators =180, \n",
    "                    max_depth = max_depth, \n",
    "                    gamma = gamma,\n",
    "                    reg_alpha = reg_alpha,\n",
    "                    min_child_weight= min_child_weight,\n",
    "                    colsample_bytree= colsample_bytree)\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "\n",
    "    xgb_params = {}\n",
    "    xgb_params['eval_metric']='auc'\n",
    "    xgb_params['early_stopping_rounds']=10 \n",
    "\n",
    "    clf.set_params(**xgb_params)\n",
    "    \n",
    "    clf.fit(\n",
    "        X_train, \n",
    "        y_train,\n",
    "        eval_set=evaluation, \n",
    "        verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    metric = {\"metric_id\": \"accuracy\", \"value\": accuracy}\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return [metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id: client1\n",
      "suggestion_count_per_request: 5\n",
      "max_trial_id_to_stop: 4\n"
     ]
    }
   ],
   "source": [
    "client_id = \"client1\"  # @param {type: 'string'}\n",
    "suggestion_count_per_request = 5  # @param {type: 'integer'}\n",
    "max_trial_id_to_stop = 4  # @param {type: 'integer'}\n",
    "\n",
    "print(\"client_id: {}\".format(client_id))\n",
    "print(\"suggestion_count_per_request: {}\".format(suggestion_count_per_request))\n",
    "print(\"max_trial_id_to_stop: {}\".format(max_trial_id_to_stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Trial : max_depth is 15, \n",
      "        gamma is 8, \n",
      "        reg_alpha is 6, \n",
      "        reg_lambda is 0, \n",
      "        colsample_bytree is 0.5452238771161251,\n",
      "        min_child_weight is 9\n",
      "        \n",
      "=========== Start Trial: [projects/569083142710/locations/us-central1/studies/2824667673603/trials/1] =============\n",
      "SCORE: 0.8863636363636364\n",
      "\n",
      "        Trial : max_depth is 18, \n",
      "        gamma is 1, \n",
      "        reg_alpha is 9, \n",
      "        reg_lambda is 1, \n",
      "        colsample_bytree is 0.6815091398605306,\n",
      "        min_child_weight is 9\n",
      "        \n",
      "=========== Start Trial: [projects/569083142710/locations/us-central1/studies/2824667673603/trials/2] =============\n",
      "SCORE: 0.8939393939393939\n",
      "\n",
      "        Trial : max_depth is 17, \n",
      "        gamma is 3, \n",
      "        reg_alpha is 1, \n",
      "        reg_lambda is 0, \n",
      "        colsample_bytree is 0.5358641343776482,\n",
      "        min_child_weight is 8\n",
      "        \n",
      "=========== Start Trial: [projects/569083142710/locations/us-central1/studies/2824667673603/trials/3] =============\n",
      "SCORE: 0.8863636363636364\n",
      "\n",
      "        Trial : max_depth is 13, \n",
      "        gamma is 9, \n",
      "        reg_alpha is 1, \n",
      "        reg_lambda is 1, \n",
      "        colsample_bytree is 0.6408736101451502,\n",
      "        min_child_weight is 9\n",
      "        \n",
      "=========== Start Trial: [projects/569083142710/locations/us-central1/studies/2824667673603/trials/4] =============\n",
      "SCORE: 0.8939393939393939\n",
      "\n",
      "        Trial : max_depth is 9, \n",
      "        gamma is 3, \n",
      "        reg_alpha is 4, \n",
      "        reg_lambda is 1, \n",
      "        colsample_bytree is 0.5367755137699964,\n",
      "        min_child_weight is 0\n",
      "        \n",
      "=========== Start Trial: [projects/569083142710/locations/us-central1/studies/2824667673603/trials/5] =============\n",
      "SCORE: 0.8863636363636364\n"
     ]
    }
   ],
   "source": [
    "trial_id = 0\n",
    "while int(trial_id) < max_trial_id_to_stop:\n",
    "    suggest_response = vizier_client.suggest_trials(\n",
    "        {\n",
    "            \"parent\": STUDY_ID,\n",
    "            \"suggestion_count\": suggestion_count_per_request,\n",
    "            \"client_id\": client_id,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for suggested_trial in suggest_response.result().trials:\n",
    "        trial_id = suggested_trial.name.split(\"/\")[-1]\n",
    "        trial = vizier_client.get_trial({\"name\": suggested_trial.name})\n",
    "\n",
    "        if trial.state in [\"COMPLETED\", \"INFEASIBLE\"]:\n",
    "            continue\n",
    "\n",
    "        for param in trial.parameters:\n",
    "            if param.parameter_id == \"max_depth\":\n",
    "                max_depth = int(param.value)\n",
    "            elif param.parameter_id == \"gamma\":\n",
    "                gamma = int(param.value)\n",
    "            elif param.parameter_id == \"reg_alpha\":\n",
    "                reg_alpha = int(param.value)\n",
    "            elif param.parameter_id == \"reg_lambda\":\n",
    "                reg_lambda = int(param.value)\n",
    "            elif param.parameter_id == \"colsample_bytree\":\n",
    "                colsample_bytree = param.value\n",
    "            elif param.parameter_id == \"min_child_weight\":\n",
    "                min_child_weight = int(param.value)        \n",
    "        print(\"\"\"\n",
    "        Trial : max_depth is {}, \n",
    "        gamma is {}, \n",
    "        reg_alpha is {}, \n",
    "        reg_lambda is {}, \n",
    "        colsample_bytree is {},\n",
    "        min_child_weight is {}\n",
    "        \"\"\".format(max_depth, gamma, reg_alpha, reg_lambda, colsample_bytree, min_child_weight))\n",
    "\n",
    "        vizier_client.add_trial_measurement(\n",
    "            {\n",
    "                \"trial_name\": suggested_trial.name,\n",
    "                \"measurement\": {\n",
    "                    \"metrics\": objective(suggested_trial.name, max_depth, gamma, reg_alpha, reg_lambda, colsample_bytree, min_child_weight)\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "\n",
    "        response = vizier_client.complete_trial(\n",
    "            {\"name\": suggested_trial.name, \"trial_infeasible\": False}\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal_trials: optimal_trials {\n",
      "  name: \"projects/569083142710/locations/us-central1/studies/2824667673603/trials/2\"\n",
      "  state: SUCCEEDED\n",
      "  parameters {\n",
      "    parameter_id: \"colsample_bytree\"\n",
      "    value {\n",
      "      number_value: 0.6815091398605306\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"gamma\"\n",
      "    value {\n",
      "      number_value: 1.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"max_depth\"\n",
      "    value {\n",
      "      number_value: 18.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"min_child_weight\"\n",
      "    value {\n",
      "      number_value: 9.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"reg_alpha\"\n",
      "    value {\n",
      "      number_value: 9.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"reg_lambda\"\n",
      "    value {\n",
      "      number_value: 1.0\n",
      "    }\n",
      "  }\n",
      "  final_measurement {\n",
      "    metrics {\n",
      "      metric_id: \"accuracy\"\n",
      "      value: 0.8939393939393939\n",
      "    }\n",
      "  }\n",
      "  measurements {\n",
      "    metrics {\n",
      "      metric_id: \"accuracy\"\n",
      "      value: 0.8939393939393939\n",
      "    }\n",
      "  }\n",
      "  start_time {\n",
      "    seconds: 1659538745\n",
      "  }\n",
      "  end_time {\n",
      "    seconds: 1659538789\n",
      "  }\n",
      "  client_id: \"client1\"\n",
      "}\n",
      "optimal_trials {\n",
      "  name: \"projects/569083142710/locations/us-central1/studies/2824667673603/trials/4\"\n",
      "  state: SUCCEEDED\n",
      "  parameters {\n",
      "    parameter_id: \"colsample_bytree\"\n",
      "    value {\n",
      "      number_value: 0.6408736101451502\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"gamma\"\n",
      "    value {\n",
      "      number_value: 9.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"max_depth\"\n",
      "    value {\n",
      "      number_value: 13.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"min_child_weight\"\n",
      "    value {\n",
      "      number_value: 9.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"reg_alpha\"\n",
      "    value {\n",
      "      number_value: 1.0\n",
      "    }\n",
      "  }\n",
      "  parameters {\n",
      "    parameter_id: \"reg_lambda\"\n",
      "    value {\n",
      "      number_value: 1.0\n",
      "    }\n",
      "  }\n",
      "  final_measurement {\n",
      "    metrics {\n",
      "      metric_id: \"accuracy\"\n",
      "      value: 0.8939393939393939\n",
      "    }\n",
      "  }\n",
      "  measurements {\n",
      "    metrics {\n",
      "      metric_id: \"accuracy\"\n",
      "      value: 0.8939393939393939\n",
      "    }\n",
      "  }\n",
      "  start_time {\n",
      "    seconds: 1659538745\n",
      "  }\n",
      "  end_time {\n",
      "    seconds: 1659538790\n",
      "  }\n",
      "  client_id: \"client1\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# List Optimal Trials\n",
    "\n",
    "optimal_trials = vizier_client.list_optimal_trials({\"parent\": STUDY_ID})\n",
    "\n",
    "print(\"optimal_trials: {}\".format(optimal_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean\n",
    "\n",
    "\n",
    "vizier_client.delete_study({\"name\": \"projects/569083142710/locations/us-central1/studies/1176465079566\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "ENDPOINT = \"us-central1\" + \"-aiplatform.googleapis.com\"\n",
    "\n",
    "\n",
    "vizier_client = aiplatform.gapic.VizierServiceClient(\n",
    "    client_options=dict(api_endpoint=ENDPOINT)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Vertex HPT+Vizier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR = \"gs://vtx-models/hpt-model\"\n",
    "IMAGE_URI = \"us-central1-docker.pkg.dev/jchavezar-demo/trainings/train_hpt_xgb:latest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Package Assembly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make folder for Python hyperparameter tuning script\n",
    "! rm -rf custom\n",
    "! mkdir custom\n",
    "\n",
    "# Make the training subfolder\n",
    "! mkdir custom/trainer\n",
    "! touch custom/trainer/__init__.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom/trainer/task.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom/trainer/task.py\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import logging\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from hypertune import HyperTune\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.cloud import storage\n",
    "\n",
    "def make_dataset(dataset_uri):\n",
    "    df = pd.read_csv(dataset_uri)\n",
    "    X = df.drop('Channel', axis=1)\n",
    "    y = df['Channel']\n",
    "    y[y == 2] = 0\n",
    "    y[y == 1] = 1\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def create_model( \n",
    "    max_depth, \n",
    "    gamma, \n",
    "    reg_alpha, \n",
    "    colsample_bytree, \n",
    "    min_child_weight,\n",
    "    ):\n",
    "    \n",
    "    print((\"=========== Start Trial: [] =============\"))\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators =180,\n",
    "                    max_depth = max_depth, \n",
    "                    gamma = gamma,\n",
    "                    reg_alpha = reg_alpha,\n",
    "                    min_child_weight= min_child_weight,\n",
    "                    colsample_bytree= colsample_bytree)\n",
    "    \n",
    "    xgb_params = {}\n",
    "    xgb_params['eval_metric']='auc'\n",
    "    xgb_params['early_stopping_rounds']=10 \n",
    "\n",
    "    clf.set_params(**xgb_params)\n",
    "    \n",
    "    return clf\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--dataset_dir',\n",
    "                    type=str, \n",
    "                    help='Dataset dir.')\n",
    "    parser.add_argument('--model_dir',\n",
    "                    default=os.getenv('AIP_MODEL_DIR'), \n",
    "                    type=str, \n",
    "                    help='Model dir.')\n",
    "    parser.add_argument('--max_depth',\n",
    "                    default=3, type=int,\n",
    "                    help='Maximum tree depth.')\n",
    "    parser.add_argument('--gamma',\n",
    "                    default=1, type=int,\n",
    "                    help='Tree gamma.')\n",
    "    parser.add_argument('--reg_alpha',\n",
    "                    default=1, type=int,\n",
    "                    help='Alpha Reg.')\n",
    "    parser.add_argument('--colsample_bytree',\n",
    "                    default=0.5, type=float,\n",
    "                    help='Colum sample tree depth.')\n",
    "    parser.add_argument('--min_child_weight',\n",
    "                    default=0, type=int,\n",
    "                    help='Colum sample tree depth.')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = make_dataset(args.dataset_dir)\n",
    "    print(X_train.head(2))\n",
    "\n",
    "    model = create_model(args.max_depth, args.gamma, args.reg_alpha, args.colsample_bytree, args.min_child_weight)\n",
    "    evaluation = [(X_train, y_train), (X_test, y_test)]\n",
    "    model.fit(X_train, y_train, eval_set=evaluation, verbose=False)\n",
    "    pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    metric = {\"metric_id\": \"accuracy\", \"value\": accuracy}\n",
    "    print (\"SCORE:\", accuracy)\n",
    "\n",
    "    hpt = HyperTune()\n",
    "    hpt.report_hyperparameter_tuning_metric(\n",
    "    hyperparameter_metric_tag='accuracy',\n",
    "    metric_value=accuracy,\n",
    "    global_step=1)\n",
    "    \n",
    "    # GCSFuse conversion\n",
    "    gs_prefix = 'gs://'# Export the classifier to a file\n",
    "    gcsfuse_prefix = '/gcs/'\n",
    "    if args.model_dir.startswith(gs_prefix):\n",
    "        args.model_dir = args.model_dir.replace(gs_prefix, gcsfuse_prefix)\n",
    "        dirpath = os.path.split(args.model_dir)[0]\n",
    "        if not os.path.isdir(dirpath):\n",
    "            os.makedirs(dirpath)\n",
    "\n",
    "    print(args.model_dir)\n",
    "\n",
    "    # Export the classifier to a file\n",
    "    gcs_model_path = os.path.join(args.model_dir, 'model.bst')\n",
    "    logging.info(\"Saving model artifacts to {}\". format(gcs_model_path))\n",
    "    model.save_model(gcs_model_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom/requirements.txt\n",
    "cloudml-hypertune\n",
    "xgboost\n",
    "pandas\n",
    "gcsfs\n",
    "sklearn\n",
    "google-cloud-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile custom/Dockerfile\n",
    "FROM python:3.7\n",
    "\n",
    "WORKDIR /\n",
    "\n",
    "COPY trainer /trainer\n",
    "COPY requirements.txt requirements.txt\n",
    "\n",
    "# Installs hypertune library\n",
    "RUN pip install -r requirements.txt\n",
    "\n",
    "\n",
    "# Copies the trainer code to the docker image.print(\n",
    "COPY trainer /trainer\n",
    "\n",
    "# Sets up the entry point to invoke the trainer.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 4 file(s) totalling 3.8 KiB before compression.\n",
      "Uploading tarball of [custom/.] to [gs://jchavezar-demo_cloudbuild/source/1659637393.979326-cb9d5bfd64824deeb9597e709509578f.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jchavezar-demo/locations/global/builds/67a76bea-8484-4f6e-afe2-c47031e27d40].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/67a76bea-8484-4f6e-afe2-c47031e27d40?project=569083142710].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"67a76bea-8484-4f6e-afe2-c47031e27d40\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jchavezar-demo_cloudbuild/source/1659637393.979326-cb9d5bfd64824deeb9597e709509578f.tgz#1659637394373831\n",
      "Copying gs://jchavezar-demo_cloudbuild/source/1659637393.979326-cb9d5bfd64824deeb9597e709509578f.tgz#1659637394373831...\n",
      "/ [1 files][  1.6 KiB/  1.6 KiB]                                                \n",
      "Operation completed over 1 objects/1.6 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  8.192kB\n",
      "Step 1/7 : FROM python:3.7\n",
      "3.7: Pulling from library/python\n",
      "001c52e26ad5: Pulling fs layer\n",
      "d9d4b9b6e964: Pulling fs layer\n",
      "2068746827ec: Pulling fs layer\n",
      "9daef329d350: Pulling fs layer\n",
      "8a335986117b: Pulling fs layer\n",
      "588423e31bcf: Pulling fs layer\n",
      "f47d4a4d89de: Pulling fs layer\n",
      "752b3732aeaf: Pulling fs layer\n",
      "dc3975411432: Pulling fs layer\n",
      "9daef329d350: Waiting\n",
      "8a335986117b: Waiting\n",
      "588423e31bcf: Waiting\n",
      "f47d4a4d89de: Waiting\n",
      "752b3732aeaf: Waiting\n",
      "dc3975411432: Waiting\n",
      "d9d4b9b6e964: Verifying Checksum\n",
      "d9d4b9b6e964: Download complete\n",
      "2068746827ec: Verifying Checksum\n",
      "2068746827ec: Download complete\n",
      "001c52e26ad5: Verifying Checksum\n",
      "001c52e26ad5: Download complete\n",
      "9daef329d350: Verifying Checksum\n",
      "9daef329d350: Download complete\n",
      "588423e31bcf: Verifying Checksum\n",
      "588423e31bcf: Download complete\n",
      "752b3732aeaf: Verifying Checksum\n",
      "752b3732aeaf: Download complete\n",
      "dc3975411432: Verifying Checksum\n",
      "dc3975411432: Download complete\n",
      "f47d4a4d89de: Verifying Checksum\n",
      "f47d4a4d89de: Download complete\n",
      "8a335986117b: Verifying Checksum\n",
      "8a335986117b: Download complete\n",
      "001c52e26ad5: Pull complete\n",
      "d9d4b9b6e964: Pull complete\n",
      "2068746827ec: Pull complete\n",
      "9daef329d350: Pull complete\n",
      "8a335986117b: Pull complete\n",
      "588423e31bcf: Pull complete\n",
      "f47d4a4d89de: Pull complete\n",
      "752b3732aeaf: Pull complete\n",
      "dc3975411432: Pull complete\n",
      "Digest: sha256:bf5ae24e891fb8a59f735b4ed76629738c1aa4e82aacf3089c03ea9887153b80\n",
      "Status: Downloaded newer image for python:3.7\n",
      " ---> 3bd0cc625ac6\n",
      "Step 2/7 : WORKDIR /\n",
      " ---> Running in 344b0c555c67\n",
      "Removing intermediate container 344b0c555c67\n",
      " ---> 79198bc47381\n",
      "Step 3/7 : COPY trainer /trainer\n",
      " ---> b1e255a01c93\n",
      "Step 4/7 : COPY requirements.txt requirements.txt\n",
      " ---> 929ed13e5c45\n",
      "Step 5/7 : RUN pip install -r requirements.txt\n",
      " ---> Running in c6d0a02ea9d3\n",
      "Collecting cloudml-hypertune\n",
      "  Downloading cloudml-hypertune-0.1.0.dev6.tar.gz (3.2 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.6.1-py3-none-manylinux2014_x86_64.whl (192.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 192.9/192.9 MB 4.3 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.3/11.3 MB 47.7 MB/s eta 0:00:00\n",
      "Collecting gcsfs\n",
      "  Downloading gcsfs-2022.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting google-cloud-storage\n",
      "  Downloading google_cloud_storage-2.5.0-py2.py3-none-any.whl (106 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 107.0/107.0 KB 16.2 MB/s eta 0:00:00\n",
      "Collecting scipy\n",
      "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 38.1/38.1 MB 23.7 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 42.4 MB/s eta 0:00:00\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 503.5/503.5 KB 37.3 MB/s eta 0:00:00\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 KB 26.8 MB/s eta 0:00:00\n",
      "Collecting google-auth>=1.2\n",
      "  Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 167.8/167.8 KB 21.1 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 65.5 MB/s eta 0:00:00\n",
      "Collecting requests\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 KB 8.9 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib\n",
      "  Downloading google_auth_oauthlib-0.5.2-py2.py3-none-any.whl (19 kB)\n",
      "Collecting decorator>4.1.2\n",
      "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
      "Collecting fsspec==2022.7.1\n",
      "  Downloading fsspec-2022.7.1-py3-none-any.whl (141 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.2/141.2 KB 18.9 MB/s eta 0:00:00\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 24.8/24.8 MB 30.1 MB/s eta 0:00:00\n",
      "Collecting google-resumable-media>=2.3.2\n",
      "  Downloading google_resumable_media-2.3.3-py2.py3-none-any.whl (76 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.9/76.9 KB 9.4 MB/s eta 0:00:00\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0\n",
      "  Downloading google_cloud_core-2.3.2-py2.py3-none-any.whl (29 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.2-py3-none-any.whl (114 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.6/114.6 KB 4.5 MB/s eta 0:00:00\n",
      "Collecting protobuf<5.0.0dev,>=3.15.0\n",
      "  Downloading protobuf-4.21.4-cp37-abi3-manylinux2014_x86_64.whl (408 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 408.4/408.4 KB 35.0 MB/s eta 0:00:00\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
      "  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.7/211.7 KB 19.5 MB/s eta 0:00:00\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 KB 25.1 MB/s eta 0:00:00\n",
      "Collecting six>=1.9.0\n",
      "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0\n",
      "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.6.15-py3-none-any.whl (160 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 160.2/160.2 KB 19.2 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<3,>=2\n",
      "  Downloading charset_normalizer-2.1.0-py3-none-any.whl (39 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.11-py2.py3-none-any.whl (139 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.9/139.9 KB 16.3 MB/s eta 0:00:00\n",
      "Collecting idna<4,>=2.5\n",
      "  Downloading idna-3.3-py3-none-any.whl (61 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.2/61.2 KB 8.5 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 KB 7.6 MB/s eta 0:00:00\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (231 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 231.3/231.3 KB 23.1 MB/s eta 0:00:00\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (148 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 148.0/148.0 KB 18.4 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 94.8/94.8 KB 15.2 MB/s eta 0:00:00\n",
      "Collecting typing-extensions>=3.7.4\n",
      "  Downloading typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting asynctest==0.13.0\n",
      "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.0/307.0 KB 28.6 MB/s eta 0:00:00\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 KB 10.5 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.5/151.5 KB 20.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: cloudml-hypertune, sklearn\n",
      "  Building wheel for cloudml-hypertune (setup.py): started\n",
      "  Building wheel for cloudml-hypertune (setup.py): finished with status 'done'\n",
      "  Created wheel for cloudml-hypertune: filename=cloudml_hypertune-0.1.0.dev6-py2.py3-none-any.whl size=3987 sha256=6240552c45db8ee15bdcff83627a7ffeba489966b9f3949fc2f75de749e03a90\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/ff/87/e7bed0c2741fe219b3d6da67c2431d7f7fedb183032e00f81e\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1310 sha256=bd00a91356d828f6c39e47a3c9796339a9efc86cec69998708394a7dafd1859d\n",
      "  Stored in directory: /root/.cache/pip/wheels/46/ef/c3/157e41f5ee1372d1be90b09f74f82b10e391eaacca8f22d33e\n",
      "Successfully built cloudml-hypertune sklearn\n",
      "Installing collected packages: pytz, pyasn1, cloudml-hypertune, urllib3, typing-extensions, threadpoolctl, six, rsa, pyasn1-modules, protobuf, oauthlib, numpy, multidict, joblib, idna, google-crc32c, fsspec, frozenlist, decorator, charset-normalizer, certifi, cachetools, attrs, asynctest, yarl, scipy, requests, python-dateutil, googleapis-common-protos, google-resumable-media, google-auth, async-timeout, aiosignal, xgboost, scikit-learn, requests-oauthlib, pandas, google-api-core, aiohttp, sklearn, google-cloud-core, google-auth-oauthlib, google-cloud-storage, gcsfs\n",
      "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 attrs-22.1.0 cachetools-5.2.0 certifi-2022.6.15 charset-normalizer-2.1.0 cloudml-hypertune-0.1.0.dev6 decorator-5.1.1 frozenlist-1.3.1 fsspec-2022.7.1 gcsfs-2022.7.1 google-api-core-2.8.2 google-auth-2.9.1 google-auth-oauthlib-0.5.2 google-cloud-core-2.3.2 google-cloud-storage-2.5.0 google-crc32c-1.3.0 google-resumable-media-2.3.3 googleapis-common-protos-1.56.4 idna-3.3 joblib-1.1.0 multidict-6.0.2 numpy-1.21.6 oauthlib-3.2.0 pandas-1.3.5 protobuf-4.21.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 python-dateutil-2.8.2 pytz-2022.1 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-1.0.2 scipy-1.7.3 six-1.16.0 sklearn-0.0 threadpoolctl-3.1.0 typing-extensions-4.3.0 urllib3-1.26.11 xgboost-1.6.1 yarl-1.8.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 22.0.4; however, version 22.2.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container c6d0a02ea9d3\n",
      " ---> e27c86145e6f\n",
      "Step 6/7 : COPY trainer /trainer\n",
      " ---> e3e856f2b984\n",
      "Step 7/7 : ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]\n",
      " ---> Running in d37efff99019\n",
      "Removing intermediate container d37efff99019\n",
      " ---> 7ed847c8a27e\n",
      "Successfully built 7ed847c8a27e\n",
      "Successfully tagged us-central1-docker.pkg.dev/jchavezar-demo/trainings/train_hpt_xgb:latest\n",
      "PUSH\n",
      "Pushing us-central1-docker.pkg.dev/jchavezar-demo/trainings/train_hpt_xgb:latest\n",
      "The push refers to repository [us-central1-docker.pkg.dev/jchavezar-demo/trainings/train_hpt_xgb]\n",
      "7264643d4522: Preparing\n",
      "10bf503b4f7f: Preparing\n",
      "ef4f1fb5ee31: Preparing\n",
      "8f889f80fbce: Preparing\n",
      "6dddb432194c: Preparing\n",
      "5f71c8685acb: Preparing\n",
      "583a78313b06: Preparing\n",
      "2143381c9922: Preparing\n",
      "12228ba7a3b1: Preparing\n",
      "9b55156abf26: Preparing\n",
      "293d5db30c9f: Preparing\n",
      "03127cdb479b: Preparing\n",
      "9c742cd6c7a5: Preparing\n",
      "5f71c8685acb: Waiting\n",
      "583a78313b06: Waiting\n",
      "2143381c9922: Waiting\n",
      "12228ba7a3b1: Waiting\n",
      "9b55156abf26: Waiting\n",
      "293d5db30c9f: Waiting\n",
      "03127cdb479b: Waiting\n",
      "9c742cd6c7a5: Waiting\n",
      "6dddb432194c: Layer already exists\n",
      "5f71c8685acb: Layer already exists\n",
      "583a78313b06: Layer already exists\n",
      "2143381c9922: Layer already exists\n",
      "12228ba7a3b1: Layer already exists\n",
      "8f889f80fbce: Pushed\n",
      "ef4f1fb5ee31: Pushed\n",
      "9b55156abf26: Layer already exists\n",
      "293d5db30c9f: Layer already exists\n",
      "03127cdb479b: Layer already exists\n",
      "9c742cd6c7a5: Layer already exists\n",
      "7264643d4522: Pushed\n",
      "10bf503b4f7f: Pushed\n",
      "latest: digest: sha256:8ba15770f1aea225ac4849d29fee5551ec5fcb4f0a72a844a39abaa09e9c9d73 size: 3055\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                        IMAGES                                                                       STATUS\n",
      "67a76bea-8484-4f6e-afe2-c47031e27d40  2022-08-04T18:23:14+00:00  2M1S      gs://jchavezar-demo_cloudbuild/source/1659637393.979326-cb9d5bfd64824deeb9597e709509578f.tgz  us-central1-docker.pkg.dev/jchavezar-demo/trainings/train_hpt_xgb (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit -t $IMAGE_URI custom/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "aip.init(project=\"jchavezar-demo\", staging_bucket=\"gs://vtx-staging/\")\n",
    "\n",
    "CMDARGS = [\n",
    "    \"--dataset_dir=gs://vtx-datasets-public/wholesale_data.csv\"\n",
    "]\n",
    "\n",
    "worker_pool_spec = [\n",
    "    {\n",
    "        \"replica_count\": 1,\n",
    "        \"machine_spec\": {\"machine_type\":\"n1-standard-4\", \"accelerator_count\":0},\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": IMAGE_URI,\n",
    "            \"args\": CMDARGS,\n",
    "        },\n",
    "    }\n",
    "]\n",
    "job = aip.CustomJob(\n",
    "    display_name=\"xgboost_hpt\", \n",
    "    worker_pool_specs=worker_pool_spec,\n",
    ")\n",
    "\n",
    "hpt_job = aip.HyperparameterTuningJob(\n",
    "    display_name=\"xgboost_hpt\",\n",
    "    custom_job=job,\n",
    "    metric_spec={\n",
    "        \"accuracy\": \"maximize\",\n",
    "    },\n",
    "    parameter_spec={\n",
    "        \"max_depth\": hpt.IntegerParameterSpec(min=3, max=18, scale=\"linear\"),\n",
    "        \"gamma\": hpt.IntegerParameterSpec(min=1, max=9, scale=\"linear\"),\n",
    "        \"reg_alpha\": hpt.IntegerParameterSpec(min=1, max=9, scale=\"linear\"),\n",
    "        \"colsample_bytree\": hpt.DoubleParameterSpec(min=0.5, max=1, scale=\"log\"),\n",
    "        \"min_child_weight\": hpt.IntegerParameterSpec(min=1, max=9, scale=\"linear\"),\n",
    "    },\n",
    "    search_algorithm=\"random\",\n",
    "    max_trial_count=4,\n",
    "    parallel_trial_count=4,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating HyperparameterTuningJob\n",
      "HyperparameterTuningJob created. Resource name: projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408\n",
      "To use this HyperparameterTuningJob in another session:\n",
      "hpt_job = aiplatform.HyperparameterTuningJob.get('projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408')\n",
      "View HyperparameterTuningJob:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/4514033168084369408?project=569083142710\n",
      "HyperparameterTuningJob projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "HyperparameterTuningJob projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "HyperparameterTuningJob projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "HyperparameterTuningJob run completed. Resource name: projects/569083142710/locations/us-central1/hyperparameterTuningJobs/4514033168084369408\n"
     ]
    }
   ],
   "source": [
    "hpt_job.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', 0.9580971742324845, 8.0, 12.0, 6.0, 2.0, 0.8939393939393939)\n"
     ]
    }
   ],
   "source": [
    "best = (None, None, None, None, None, None, 0.0)\n",
    "for trial in hpt_job.trials:\n",
    "    # Keep track of the best outcome\n",
    "    if float(trial.final_measurement.metrics[0].value) > best[6]:\n",
    "        try:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                float(trial.parameters[0].value),\n",
    "                float(trial.parameters[1].value),\n",
    "                float(trial.parameters[2].value),\n",
    "                float(trial.parameters[3].value),\n",
    "                float(trial.parameters[4].value),\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n",
    "            print(best)\n",
    "        except:\n",
    "            best = (\n",
    "                trial.id,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "                None,\n",
    "                float(trial.final_measurement.metrics[0].value),\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://vtx-staging/aiplatform-custom-job-2022-08-04-14:26:28.960/1/model/\n",
      "gs://vtx-staging/aiplatform-custom-job-2022-08-04-14:26:28.960/1/model/model.bst\n"
     ]
    }
   ],
   "source": [
    "# Best Model is under vtx-staging/custom-job-date/trial_id:\n",
    "\n",
    "!gsutil ls gs://vtx-staging/aiplatform-custom-job-2022-08-04-14:26:28.960/1/model"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-10.m98",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-10:m98"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "61f821d259e852bb8dda541b337ba40be66c16e8431d3e97d4d2c7f8d54d4461"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
