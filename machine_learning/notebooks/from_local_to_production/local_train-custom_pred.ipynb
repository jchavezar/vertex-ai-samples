{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "039138f6-d11d-4e80-b090-68b79e714231",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5a5689-3334-4df4-a488-d671d7abbb35",
   "metadata": {},
   "source": [
    "![](images/ml-artifacts-1.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d3f584-231b-4fe8-9f38-d58e955c06dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr train\n",
    "!mkdir train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e995d54-77cf-4a45-ace7-86aee8e51a06",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 18:22:21.111108: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                640       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,865\n",
      "Trainable params: 4,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 18:22:24.116057: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 42ms/step - loss: 564.8606 - mae: 22.5435 - mse: 564.8606 - val_loss: 553.4888 - val_mae: 22.3036 - val_mse: 553.4888\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 513.1585 - mae: 21.4281 - mse: 513.1585 - val_loss: 499.9730 - val_mae: 21.1418 - val_mse: 499.9730\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 462.6396 - mae: 20.3071 - mse: 462.6396 - val_loss: 443.6070 - val_mae: 19.8434 - val_mse: 443.6070\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 408.4442 - mae: 19.0185 - mse: 408.4442 - val_loss: 381.9565 - val_mae: 18.3183 - val_mse: 381.9565\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.4197 - mae: 17.5306 - mse: 350.4197 - val_loss: 318.0355 - val_mae: 16.5966 - val_mse: 318.0355\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 291.3926 - mae: 15.8563 - mse: 291.3926 - val_loss: 255.4471 - val_mae: 14.7068 - val_mse: 255.4471\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 233.0835 - mae: 14.0175 - mse: 233.0835 - val_loss: 194.2625 - val_mae: 12.6031 - val_mse: 194.2625\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 178.2350 - mae: 12.0579 - mse: 178.2350 - val_loss: 141.3688 - val_mae: 10.4598 - val_mse: 141.3688\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 130.7254 - mae: 10.0786 - mse: 130.7254 - val_loss: 98.7798 - val_mae: 8.5243 - val_mse: 98.7798\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 92.9316 - mae: 8.1990 - mse: 92.9316 - val_loss: 68.3842 - val_mae: 7.0032 - val_mse: 68.3842\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 65.6831 - mae: 6.6013 - mse: 65.6831 - val_loss: 50.1087 - val_mae: 5.9359 - val_mse: 50.1087\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 47.7943 - mae: 5.5226 - mse: 47.7943 - val_loss: 39.7082 - val_mae: 5.2582 - val_mse: 39.7082\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 36.2317 - mae: 4.7941 - mse: 36.2317 - val_loss: 34.0153 - val_mae: 4.8572 - val_mse: 34.0153\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 28.9875 - mae: 4.2621 - mse: 28.9875 - val_loss: 30.2512 - val_mae: 4.4914 - val_mse: 30.2512\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23.8264 - mae: 3.8531 - mse: 23.8264 - val_loss: 25.9527 - val_mae: 4.1352 - val_mse: 25.9527\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20.2124 - mae: 3.5154 - mse: 20.2124 - val_loss: 23.1866 - val_mae: 3.8562 - val_mse: 23.1866\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 17.4690 - mae: 3.2685 - mse: 17.4690 - val_loss: 21.6636 - val_mae: 3.6383 - val_mse: 21.6636\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15.5606 - mae: 3.0640 - mse: 15.5606 - val_loss: 19.1951 - val_mae: 3.4323 - val_mse: 19.1951\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 14.1596 - mae: 2.8919 - mse: 14.1596 - val_loss: 17.6658 - val_mae: 3.2395 - val_mse: 17.6658\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 13.0006 - mae: 2.7877 - mse: 13.0006 - val_loss: 15.3786 - val_mae: 3.1491 - val_mse: 15.3786\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 12.0257 - mae: 2.6122 - mse: 12.0257 - val_loss: 14.1503 - val_mae: 3.0213 - val_mse: 14.1503\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 11.2761 - mae: 2.5186 - mse: 11.2761 - val_loss: 12.8855 - val_mae: 2.8449 - val_mse: 12.8855\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 10.8600 - mae: 2.4237 - mse: 10.8600 - val_loss: 12.0960 - val_mae: 2.7273 - val_mse: 12.0960\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10.1502 - mae: 2.3353 - mse: 10.1502 - val_loss: 11.5030 - val_mae: 2.6428 - val_mse: 11.5030\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 9.6612 - mae: 2.2709 - mse: 9.6612 - val_loss: 11.2662 - val_mae: 2.6022 - val_mse: 11.2662\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.4188 - mae: 2.2125 - mse: 9.4188 - val_loss: 10.8903 - val_mae: 2.4981 - val_mse: 10.8903\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.2666 - mae: 2.2113 - mse: 9.2666 - val_loss: 10.3028 - val_mae: 2.4880 - val_mse: 10.3028\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.7796 - mae: 2.1083 - mse: 8.7796 - val_loss: 10.2041 - val_mae: 2.4429 - val_mse: 10.2041\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.7426 - mae: 2.1099 - mse: 8.7426 - val_loss: 9.7583 - val_mae: 2.4320 - val_mse: 9.7583\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.4858 - mae: 2.0896 - mse: 8.4858 - val_loss: 10.0028 - val_mae: 2.4003 - val_mse: 10.0028\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.3939 - mae: 2.0572 - mse: 8.3939 - val_loss: 9.5037 - val_mae: 2.3751 - val_mse: 9.5037\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.1806 - mae: 2.0223 - mse: 8.1806 - val_loss: 9.5656 - val_mae: 2.3322 - val_mse: 9.5656\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.2777 - mae: 2.0505 - mse: 8.2777 - val_loss: 9.5656 - val_mae: 2.3184 - val_mse: 9.5656\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 8.0659 - mae: 2.0120 - mse: 8.0659 - val_loss: 9.1982 - val_mae: 2.3116 - val_mse: 9.1982\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.9869 - mae: 2.0184 - mse: 7.9869 - val_loss: 9.0896 - val_mae: 2.3272 - val_mse: 9.0896\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.9578 - mae: 2.0185 - mse: 7.9578 - val_loss: 9.2640 - val_mae: 2.2826 - val_mse: 9.2640\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.9208 - mae: 2.0048 - mse: 7.9208 - val_loss: 9.2113 - val_mae: 2.3344 - val_mse: 9.2113\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.7130 - mae: 1.9579 - mse: 7.7130 - val_loss: 9.0830 - val_mae: 2.3331 - val_mse: 9.0830\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.5292 - mae: 1.9334 - mse: 7.5292 - val_loss: 9.3142 - val_mae: 2.2782 - val_mse: 9.3142\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.5252 - mae: 1.9397 - mse: 7.5252 - val_loss: 9.2045 - val_mae: 2.2741 - val_mse: 9.2045\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.5479 - mae: 1.9333 - mse: 7.5479 - val_loss: 8.9383 - val_mae: 2.3205 - val_mse: 8.9383\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.4383 - mae: 1.9092 - mse: 7.4383 - val_loss: 9.1521 - val_mae: 2.2467 - val_mse: 9.1521\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 7ms/step - loss: 7.4927 - mae: 1.9039 - mse: 7.4927 - val_loss: 9.1911 - val_mae: 2.2407 - val_mse: 9.1911\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.3587 - mae: 1.9197 - mse: 7.3587 - val_loss: 9.1546 - val_mae: 2.2445 - val_mse: 9.1546\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.3499 - mae: 1.9248 - mse: 7.3499 - val_loss: 9.0917 - val_mae: 2.2572 - val_mse: 9.0917\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.3413 - mae: 1.9131 - mse: 7.3413 - val_loss: 9.3210 - val_mae: 2.2529 - val_mse: 9.3210\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.3605 - mae: 1.9262 - mse: 7.3605 - val_loss: 9.0999 - val_mae: 2.2382 - val_mse: 9.0999\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.1999 - mae: 1.9070 - mse: 7.1999 - val_loss: 9.0336 - val_mae: 2.2422 - val_mse: 9.0336\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.1192 - mae: 1.9253 - mse: 7.1192 - val_loss: 8.8404 - val_mae: 2.3112 - val_mse: 8.8404\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.0656 - mae: 1.8912 - mse: 7.0656 - val_loss: 9.1635 - val_mae: 2.2271 - val_mse: 9.1635\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.0661 - mae: 1.9427 - mse: 7.0661 - val_loss: 8.9193 - val_mae: 2.2618 - val_mse: 8.9193\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.1234 - mae: 1.8821 - mse: 7.1234 - val_loss: 9.0519 - val_mae: 2.4022 - val_mse: 9.0519\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.1457 - mae: 1.8899 - mse: 7.1457 - val_loss: 8.9413 - val_mae: 2.2395 - val_mse: 8.9413\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.1997 - mae: 1.8853 - mse: 7.1997 - val_loss: 8.7933 - val_mae: 2.2647 - val_mse: 8.7933\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.9828 - mae: 1.8784 - mse: 6.9828 - val_loss: 8.8793 - val_mae: 2.2607 - val_mse: 8.8793\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.1460 - mae: 1.8755 - mse: 7.1460 - val_loss: 8.8417 - val_mae: 2.2320 - val_mse: 8.8417\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.9254 - mae: 1.8784 - mse: 6.9254 - val_loss: 8.7968 - val_mae: 2.2518 - val_mse: 8.7968\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.8327 - mae: 1.8776 - mse: 6.8327 - val_loss: 9.0518 - val_mae: 2.3536 - val_mse: 9.0518\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.9652 - mae: 1.8772 - mse: 6.9652 - val_loss: 9.0217 - val_mae: 2.2581 - val_mse: 9.0217\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.8161 - mae: 1.8450 - mse: 6.8161 - val_loss: 8.7834 - val_mae: 2.2816 - val_mse: 8.7834\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7349 - mae: 1.8251 - mse: 6.7349 - val_loss: 8.7893 - val_mae: 2.2259 - val_mse: 8.7893\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.9124 - mae: 1.8466 - mse: 6.9124 - val_loss: 8.8710 - val_mae: 2.2809 - val_mse: 8.8710\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7702 - mae: 1.8246 - mse: 6.7702 - val_loss: 8.7608 - val_mae: 2.2375 - val_mse: 8.7608\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7605 - mae: 1.8342 - mse: 6.7605 - val_loss: 9.0398 - val_mae: 2.1941 - val_mse: 9.0398\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.8328 - mae: 1.8288 - mse: 6.8328 - val_loss: 8.8789 - val_mae: 2.1914 - val_mse: 8.8789\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.6398 - mae: 1.8353 - mse: 6.6398 - val_loss: 8.7035 - val_mae: 2.2476 - val_mse: 8.7035\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.6910 - mae: 1.8041 - mse: 6.6910 - val_loss: 8.8856 - val_mae: 2.1929 - val_mse: 8.8856\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.6320 - mae: 1.8203 - mse: 6.6320 - val_loss: 8.6064 - val_mae: 2.2570 - val_mse: 8.6064\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7198 - mae: 1.8308 - mse: 6.7198 - val_loss: 8.5407 - val_mae: 2.2498 - val_mse: 8.5407\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.6554 - mae: 1.8584 - mse: 6.6554 - val_loss: 8.8133 - val_mae: 2.2053 - val_mse: 8.8133\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.5429 - mae: 1.8131 - mse: 6.5429 - val_loss: 8.9672 - val_mae: 2.1956 - val_mse: 8.9672\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.4566 - mae: 1.8102 - mse: 6.4566 - val_loss: 9.0900 - val_mae: 2.3569 - val_mse: 9.0900\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7892 - mae: 1.8109 - mse: 6.7892 - val_loss: 8.7557 - val_mae: 2.2061 - val_mse: 8.7557\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.5362 - mae: 1.8080 - mse: 6.5362 - val_loss: 8.5178 - val_mae: 2.2429 - val_mse: 8.5178\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.5023 - mae: 1.7938 - mse: 6.5023 - val_loss: 8.7080 - val_mae: 2.1857 - val_mse: 8.7080\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.4815 - mae: 1.8176 - mse: 6.4815 - val_loss: 8.6788 - val_mae: 2.1884 - val_mse: 8.6788\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.3775 - mae: 1.7988 - mse: 6.3775 - val_loss: 8.6495 - val_mae: 2.2400 - val_mse: 8.6495\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.7201 - mae: 1.8409 - mse: 6.7201 - val_loss: 8.6575 - val_mae: 2.2039 - val_mse: 8.6575\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.3479 - mae: 1.7907 - mse: 6.3479 - val_loss: 8.7289 - val_mae: 2.1813 - val_mse: 8.7289\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.6228 - mae: 1.8295 - mse: 6.6228 - val_loss: 8.6481 - val_mae: 2.2878 - val_mse: 8.6481\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.3330 - mae: 1.7676 - mse: 6.3330 - val_loss: 8.4931 - val_mae: 2.2216 - val_mse: 8.4931\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2683 - mae: 1.7699 - mse: 6.2683 - val_loss: 8.6779 - val_mae: 2.1757 - val_mse: 8.6779\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1808 - mae: 1.7618 - mse: 6.1808 - val_loss: 9.5427 - val_mae: 2.2016 - val_mse: 9.5427\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.4527 - mae: 1.8182 - mse: 6.4527 - val_loss: 8.5486 - val_mae: 2.2674 - val_mse: 8.5486\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.2483 - mae: 1.7481 - mse: 6.2483 - val_loss: 8.8808 - val_mae: 2.2562 - val_mse: 8.8808\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.2812 - mae: 1.7536 - mse: 6.2812 - val_loss: 8.6229 - val_mae: 2.1778 - val_mse: 8.6229\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.2426 - mae: 1.7644 - mse: 6.2426 - val_loss: 8.8097 - val_mae: 2.1776 - val_mse: 8.8097\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.2348 - mae: 1.7756 - mse: 6.2348 - val_loss: 8.5334 - val_mae: 2.1975 - val_mse: 8.5334\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.4605 - mae: 1.7914 - mse: 6.4605 - val_loss: 8.7456 - val_mae: 2.2590 - val_mse: 8.7456\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.3197 - mae: 1.7688 - mse: 6.3197 - val_loss: 8.4633 - val_mae: 2.1966 - val_mse: 8.4633\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1547 - mae: 1.7434 - mse: 6.1547 - val_loss: 8.5412 - val_mae: 2.2012 - val_mse: 8.5412\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1452 - mae: 1.7551 - mse: 6.1452 - val_loss: 8.4338 - val_mae: 2.1871 - val_mse: 8.4338\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.1350 - mae: 1.7433 - mse: 6.1350 - val_loss: 8.6790 - val_mae: 2.1972 - val_mse: 8.6790\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.2845 - mae: 1.7663 - mse: 6.2845 - val_loss: 8.5653 - val_mae: 2.2708 - val_mse: 8.5653\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1310 - mae: 1.7400 - mse: 6.1310 - val_loss: 8.6806 - val_mae: 2.2261 - val_mse: 8.6806\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2200 - mae: 1.7324 - mse: 6.2200 - val_loss: 8.6189 - val_mae: 2.1870 - val_mse: 8.6189\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.1714 - mae: 1.7525 - mse: 6.1714 - val_loss: 8.7366 - val_mae: 2.1788 - val_mse: 8.7366\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.1485 - mae: 1.7396 - mse: 6.1485 - val_loss: 8.4798 - val_mae: 2.2204 - val_mse: 8.4798\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.0397 - mae: 1.7363 - mse: 6.0397 - val_loss: 8.4669 - val_mae: 2.2032 - val_mse: 8.4669\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.9799 - mae: 1.7302 - mse: 5.9799 - val_loss: 8.3917 - val_mae: 2.1832 - val_mse: 8.3917\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.2133 - mae: 1.7321 - mse: 6.2133 - val_loss: 8.5888 - val_mae: 2.1818 - val_mse: 8.5888\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.0466 - mae: 1.7386 - mse: 6.0466 - val_loss: 8.5533 - val_mae: 2.1839 - val_mse: 8.5533\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.0690 - mae: 1.7196 - mse: 6.0690 - val_loss: 8.6813 - val_mae: 2.1808 - val_mse: 8.6813\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1595 - mae: 1.7693 - mse: 6.1595 - val_loss: 8.7583 - val_mae: 2.2943 - val_mse: 8.7583\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1570 - mae: 1.7431 - mse: 6.1570 - val_loss: 8.5259 - val_mae: 2.2209 - val_mse: 8.5259\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.0731 - mae: 1.7242 - mse: 6.0731 - val_loss: 8.4778 - val_mae: 2.1937 - val_mse: 8.4778\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.9801 - mae: 1.7121 - mse: 5.9801 - val_loss: 8.5655 - val_mae: 2.1889 - val_mse: 8.5655\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.1673 - mae: 1.7415 - mse: 6.1673 - val_loss: 8.6109 - val_mae: 2.1515 - val_mse: 8.6109\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 6.0166 - mae: 1.7221 - mse: 6.0166 - val_loss: 8.8163 - val_mae: 2.1746 - val_mse: 8.8163\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.9880 - mae: 1.7269 - mse: 5.9880 - val_loss: 8.4710 - val_mae: 2.1711 - val_mse: 8.4710\n",
      "train/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: train/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: train/assets\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "BUCKET = 'train/'\n",
    "\n",
    "# Extraction process\n",
    "dataset = pd.read_csv('https://storage.googleapis.com/jchavezar-public-datasets/auto-mpg.csv')\n",
    "dataset.tail()\n",
    "\n",
    "dataset.isna().sum()\n",
    "dataset = dataset.dropna()\n",
    "dataset['Origin'] = dataset['Origin'].map({1: 'USA', 2: 'Europe', 3: 'Japan'})\n",
    "dataset = pd.get_dummies(dataset, prefix='', prefix_sep='')\n",
    "dataset.tail()\n",
    "\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)\n",
    "\n",
    "train_stats = train_dataset.describe()\n",
    "train_stats.pop(\"MPG\")\n",
    "train_stats = train_stats.transpose()\n",
    "\n",
    "train_labels = train_dataset.pop('MPG')\n",
    "test_labels = test_dataset.pop('MPG')\n",
    "\n",
    "\n",
    "def norm(x):\n",
    "    return (x - train_stats['mean']) / train_stats['std']\n",
    "\n",
    "\n",
    "normed_train_data = norm(train_dataset)\n",
    "normed_test_data = norm(test_dataset)\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    model_ai = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[len(train_dataset.keys())]),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "    model_ai.compile(loss='mse',\n",
    "                     optimizer=optimizer,\n",
    "                     metrics=['mae', 'mse'])\n",
    "    return model_ai\n",
    "\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "EPOCHS = 1000\n",
    "\n",
    "# The patience parameter is the amount of epochs to check for improvement\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "early_history = model.fit(normed_train_data, train_labels,\n",
    "                          epochs=EPOCHS, validation_split=0.2,\n",
    "                          callbacks=[early_stop])\n",
    "\n",
    "# Export model and save to GCS\n",
    "print(BUCKET)\n",
    "model.save(BUCKET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029d5eba-9b37-409e-a3f4-389a9a415417",
   "metadata": {},
   "source": [
    "## Create Container Image and Save it on Google Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d2fa74-cb4d-4c90-a51a-ebae64589615",
   "metadata": {},
   "source": [
    "![](images/ml-artifacts-2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c9b9d63-f612-4e5a-b934-dca09badd3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fr app\n",
    "!mkdir app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "571f5c24-d442-4606-9a1e-cd232abe0475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rapids/notebooks/vertex-ai-mlops/from_local_to_production\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60f29925-e732-4e95-a1ca-c2e058337b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app/main.py\n",
    "from fastapi import Request, FastAPI\n",
    "from tensorflow import keras\n",
    "import json\n",
    "import os\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "model = keras.models.load_model('.')\n",
    "\n",
    "@app.get('/')\n",
    "def get_root():\n",
    "    return {'message': 'Welcome mpg API: miles per gallon prediction'}\n",
    "\n",
    "\n",
    "@app.get('/health_check')\n",
    "def health():\n",
    "    return 200\n",
    "\n",
    "\n",
    "if os.environ.get('AIP_PREDICT_ROUTE') is not None:\n",
    "    method = os.environ['AIP_PREDICT_ROUTE']\n",
    "else:\n",
    "    method = '/predict'\n",
    "\n",
    "print(method)\n",
    "@app.post(method)\n",
    "async def predict(request: Request):\n",
    "    print(\"----------------- PREDICTING -----------------\")\n",
    "    body = await request.json()\n",
    "    instances = body[\"instances\"]\n",
    "    outputs = model.predict(instances)\n",
    "    response = outputs.tolist()\n",
    "    print(\"----------------- OUTPUTS -----------------\")\n",
    "\n",
    "    return {\"predictions\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d57f1acf-87f3-4713-8870-eb28df3a2811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile Dockerfile\n",
    "FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
    "\n",
    "COPY train /app\n",
    "COPY app /app\n",
    "WORKDIR /app\n",
    "RUN pip install sklearn joblib pandas tensorflow\n",
    "CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
    "\n",
    "EXPOSE 8080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13727e20-762a-49fb-b160-ed4b0e31a0d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 11 file(s) totalling 549.0 KiB before compression.\n",
      "Some files were not included in the source upload.\n",
      "\n",
      "Check the gcloud log [/root/.config/gcloud/logs/2023.02.03/18.38.52.481156.log] to see which files and the contents of the\n",
      "default gcloudignore file used (see `$ gcloud topic gcloudignore` to learn\n",
      "more).\n",
      "\n",
      "Uploading tarball of [.] to [gs://jchavezar-demo_cloudbuild/source/1675449532.587196-1333156387d849c8aca34a55f8631671.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/jchavezar-demo/locations/global/builds/aa47cc52-1390-4263-a5bb-27d3fdd70158].\n",
      "Logs are available at [ https://console.cloud.google.com/cloud-build/builds/aa47cc52-1390-4263-a5bb-27d3fdd70158?project=569083142710 ].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"aa47cc52-1390-4263-a5bb-27d3fdd70158\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://jchavezar-demo_cloudbuild/source/1675449532.587196-1333156387d849c8aca34a55f8631671.tgz#1675449532951109\n",
      "Copying gs://jchavezar-demo_cloudbuild/source/1675449532.587196-1333156387d849c8aca34a55f8631671.tgz#1675449532951109...\n",
      "/ [1 files][367.3 KiB/367.3 KiB]                                                \n",
      "Operation completed over 1 objects/367.3 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  574.5kB\n",
      "Step 1/7 : FROM tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
      "python3.7: Pulling from tiangolo/uvicorn-gunicorn-fastapi\n",
      "bbeef03cda1f: Already exists\n",
      "f049f75f014e: Already exists\n",
      "56261d0e6b05: Already exists\n",
      "9bd150679dbd: Already exists\n",
      "5b282ee9da04: Already exists\n",
      "03f027d5e312: Already exists\n",
      "0ea9f83baea6: Pulling fs layer\n",
      "c7aa48634589: Pulling fs layer\n",
      "0e6a1071cff6: Pulling fs layer\n",
      "cda96f6684fb: Pulling fs layer\n",
      "43abb64ffa5e: Pulling fs layer\n",
      "57185d57e74d: Pulling fs layer\n",
      "774a06429c8b: Pulling fs layer\n",
      "59041ebce779: Pulling fs layer\n",
      "b16f78273812: Pulling fs layer\n",
      "85a92ce532da: Pulling fs layer\n",
      "65718fcc47ee: Pulling fs layer\n",
      "ad7b87e6b52e: Pulling fs layer\n",
      "bd673b9b9014: Pulling fs layer\n",
      "5dfc5da02c33: Pulling fs layer\n",
      "cda96f6684fb: Waiting\n",
      "43abb64ffa5e: Waiting\n",
      "57185d57e74d: Waiting\n",
      "774a06429c8b: Waiting\n",
      "59041ebce779: Waiting\n",
      "b16f78273812: Waiting\n",
      "85a92ce532da: Waiting\n",
      "65718fcc47ee: Waiting\n",
      "ad7b87e6b52e: Waiting\n",
      "bd673b9b9014: Waiting\n",
      "5dfc5da02c33: Waiting\n",
      "c7aa48634589: Verifying Checksum\n",
      "c7aa48634589: Download complete\n",
      "0e6a1071cff6: Verifying Checksum\n",
      "0e6a1071cff6: Download complete\n",
      "0ea9f83baea6: Verifying Checksum\n",
      "0ea9f83baea6: Download complete\n",
      "cda96f6684fb: Verifying Checksum\n",
      "cda96f6684fb: Download complete\n",
      "57185d57e74d: Verifying Checksum\n",
      "57185d57e74d: Download complete\n",
      "43abb64ffa5e: Verifying Checksum\n",
      "43abb64ffa5e: Download complete\n",
      "774a06429c8b: Verifying Checksum\n",
      "774a06429c8b: Download complete\n",
      "b16f78273812: Verifying Checksum\n",
      "b16f78273812: Download complete\n",
      "59041ebce779: Verifying Checksum\n",
      "59041ebce779: Download complete\n",
      "85a92ce532da: Download complete\n",
      "65718fcc47ee: Verifying Checksum\n",
      "65718fcc47ee: Download complete\n",
      "ad7b87e6b52e: Verifying Checksum\n",
      "ad7b87e6b52e: Download complete\n",
      "0ea9f83baea6: Pull complete\n",
      "bd673b9b9014: Verifying Checksum\n",
      "bd673b9b9014: Download complete\n",
      "c7aa48634589: Pull complete\n",
      "5dfc5da02c33: Verifying Checksum\n",
      "5dfc5da02c33: Download complete\n",
      "0e6a1071cff6: Pull complete\n",
      "cda96f6684fb: Pull complete\n",
      "43abb64ffa5e: Pull complete\n",
      "57185d57e74d: Pull complete\n",
      "774a06429c8b: Pull complete\n",
      "59041ebce779: Pull complete\n",
      "b16f78273812: Pull complete\n",
      "85a92ce532da: Pull complete\n",
      "65718fcc47ee: Pull complete\n",
      "ad7b87e6b52e: Pull complete\n",
      "bd673b9b9014: Pull complete\n",
      "5dfc5da02c33: Pull complete\n",
      "Digest: sha256:09bb4d9bc8f58ace504fbc8f3478d03459529ad099f626e9fde248084675d5b4\n",
      "Status: Downloaded newer image for tiangolo/uvicorn-gunicorn-fastapi:python3.7\n",
      " ---> fbed7ab11094\n",
      "Step 2/7 : COPY train /app\n",
      " ---> c201bac176c2\n",
      "Step 3/7 : COPY app /app\n",
      " ---> e00685fce672\n",
      "Step 4/7 : WORKDIR /app\n",
      " ---> Running in 9f858be1ce25\n",
      "Removing intermediate container 9f858be1ce25\n",
      " ---> 6099112e437e\n",
      "Step 5/7 : RUN pip install sklearn joblib pandas tensorflow\n",
      " ---> Running in 00f7d63b76d5\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting joblib\n",
      "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 KB 11.5 MB/s eta 0:00:00\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.3.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.3/11.3 MB 43.9 MB/s eta 0:00:00\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 588.3/588.3 MB 2.0 MB/s eta 0:00:00\n",
      "Collecting pytz>=2017.3\n",
      "  Downloading pytz-2022.7.1-py2.py3-none-any.whl (499 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 499.4/499.4 KB 42.9 MB/s eta 0:00:00\n",
      "Collecting python-dateutil>=2.7.3\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 KB 27.9 MB/s eta 0:00:00\n",
      "Collecting numpy>=1.17.3\n",
      "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 15.7/15.7 MB 39.0 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "Collecting keras<2.12,>=2.11.0\n",
      "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 69.7 MB/s eta 0:00:00\n",
      "Collecting tensorboard<2.12,>=2.11\n",
      "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.0/6.0 MB 54.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.51.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 54.9 MB/s eta 0:00:00\n",
      "Collecting packaging\n",
      "  Downloading packaging-23.0-py3-none-any.whl (42 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.7/42.7 KB 6.6 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
      "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 439.2/439.2 KB 39.6 MB/s eta 0:00:00\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 KB 10.2 MB/s eta 0:00:00\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (75 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.2/75.2 KB 13.3 MB/s eta 0:00:00\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.3/4.3 MB 60.9 MB/s eta 0:00:00\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-15.0.6.1-py2.py3-none-manylinux2010_x86_64.whl (21.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.5/21.5 MB 31.4 MB/s eta 0:00:00\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.30.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 66.0 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 KB 10.3 MB/s eta 0:00:00\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 60.4 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from tensorflow) (57.5.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 KB 19.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 KB 54.6 MB/s eta 0:00:00\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 KB 13.1 MB/s eta 0:00:00\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 KB 10.2 MB/s eta 0:00:00\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 KB 29.4 MB/s eta 0:00:00\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.8/177.8 KB 23.4 MB/s eta 0:00:00\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 53.8 MB/s eta 0:00:00\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 KB 23.8 MB/s eta 0:00:00\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2022.12.7)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 140.6/140.6 KB 21.2 MB/s eta 0:00:00\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.0.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (170 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 170.5/170.5 KB 24.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 KB 12.6 MB/s eta 0:00:00\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 KB 21.7 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py): started\n",
      "  Building wheel for sklearn (setup.py): finished with status 'done'\n",
      "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=52cf333e0fde47c1ae63336f11a827eaec1deb879f6be7a78d0215901defc760\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/56/cc/4a8bf86613aafd5b7f1b310477667c1fca5c51c3ae4124a003\n",
      "Successfully built sklearn\n",
      "Installing collected packages: tensorboard-plugin-wit, sklearn, pytz, pyasn1, libclang, flatbuffers, charset-normalizer, wrapt, werkzeug, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, python-dateutil, pyasn1-modules, protobuf, packaging, oauthlib, numpy, keras, joblib, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests, pandas, opt-einsum, markdown, h5py, google-auth, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 charset-normalizer-3.0.1 flatbuffers-23.1.21 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.8.0 joblib-1.2.0 keras-2.11.0 libclang-15.0.6.1 markdown-3.4.1 numpy-1.21.6 oauthlib-3.2.2 opt-einsum-3.3.0 packaging-23.0 pandas-1.3.5 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 python-dateutil-2.8.2 pytz-2022.7.1 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 sklearn-0.0.post1 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-io-gcs-filesystem-0.30.0 termcolor-2.2.0 urllib3-1.26.14 werkzeug-2.2.2 wrapt-1.14.1\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0m\u001b[91mWARNING: You are using pip version 22.0.4; however, version 23.0 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n",
      "\u001b[0mRemoving intermediate container 00f7d63b76d5\n",
      " ---> 909ebb18b01f\n",
      "Step 6/7 : CMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"]\n",
      " ---> Running in a3d3e681909d\n",
      "Removing intermediate container a3d3e681909d\n",
      " ---> e0e0a3a52058\n",
      "Step 7/7 : EXPOSE 8080\n",
      " ---> Running in ed0baf889bcd\n",
      "Removing intermediate container ed0baf889bcd\n",
      " ---> 849611a2391a\n",
      "Successfully built 849611a2391a\n",
      "Successfully tagged gcr.io/jchavezar-demo/custom-local-train:v1\n",
      "PUSH\n",
      "Pushing gcr.io/jchavezar-demo/custom-local-train:v1\n",
      "The push refers to repository [gcr.io/jchavezar-demo/custom-local-train]\n",
      "1856dd3a2d57: Preparing\n",
      "d35a30c80564: Preparing\n",
      "b2a172982819: Preparing\n",
      "3298ab272306: Preparing\n",
      "840df0887020: Preparing\n",
      "771ec8aea97d: Preparing\n",
      "eac3ce7d25fc: Preparing\n",
      "eb1c527cf1b8: Preparing\n",
      "c388e0d26c73: Preparing\n",
      "7a723605e383: Preparing\n",
      "da7863621d1e: Preparing\n",
      "603e0e93b469: Preparing\n",
      "575d29c2fa08: Preparing\n",
      "971add86a133: Preparing\n",
      "77a1684595a2: Preparing\n",
      "cb98838708ff: Preparing\n",
      "3138b3135f78: Preparing\n",
      "dc6462f7bb8b: Preparing\n",
      "a4db1a405763: Preparing\n",
      "9f4f964da727: Preparing\n",
      "49b333f7bad4: Preparing\n",
      "a463dbda4664: Preparing\n",
      "a9099c3159f5: Preparing\n",
      "575d29c2fa08: Waiting\n",
      "971add86a133: Waiting\n",
      "77a1684595a2: Waiting\n",
      "cb98838708ff: Waiting\n",
      "3138b3135f78: Waiting\n",
      "dc6462f7bb8b: Waiting\n",
      "a4db1a405763: Waiting\n",
      "9f4f964da727: Waiting\n",
      "49b333f7bad4: Waiting\n",
      "a463dbda4664: Waiting\n",
      "a9099c3159f5: Waiting\n",
      "eb1c527cf1b8: Waiting\n",
      "c388e0d26c73: Waiting\n",
      "7a723605e383: Waiting\n",
      "da7863621d1e: Waiting\n",
      "603e0e93b469: Waiting\n",
      "771ec8aea97d: Waiting\n",
      "eac3ce7d25fc: Waiting\n",
      "840df0887020: Layer already exists\n",
      "3298ab272306: Layer already exists\n",
      "771ec8aea97d: Layer already exists\n",
      "eac3ce7d25fc: Layer already exists\n",
      "c388e0d26c73: Layer already exists\n",
      "eb1c527cf1b8: Layer already exists\n",
      "7a723605e383: Layer already exists\n",
      "da7863621d1e: Layer already exists\n",
      "575d29c2fa08: Layer already exists\n",
      "603e0e93b469: Layer already exists\n",
      "971add86a133: Layer already exists\n",
      "cb98838708ff: Layer already exists\n",
      "77a1684595a2: Layer already exists\n",
      "3138b3135f78: Layer already exists\n",
      "dc6462f7bb8b: Layer already exists\n",
      "9f4f964da727: Layer already exists\n",
      "a4db1a405763: Layer already exists\n",
      "49b333f7bad4: Layer already exists\n",
      "a463dbda4664: Layer already exists\n",
      "a9099c3159f5: Layer already exists\n",
      "b2a172982819: Pushed\n",
      "d35a30c80564: Pushed\n",
      "1856dd3a2d57: Pushed\n",
      "v1: digest: sha256:f0fd6e305f4f1a8ec1cb8b09d0e48577bc1540b607d7458b395aeebd306e995f size: 5135\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                        IMAGES                                       STATUS\n",
      "aa47cc52-1390-4263-a5bb-27d3fdd70158  2023-02-03T18:38:53+00:00  4M15S     gs://jchavezar-demo_cloudbuild/source/1675449532.587196-1333156387d849c8aca34a55f8631671.tgz  gcr.io/jchavezar-demo/custom-local-train:v1  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit -t gcr.io/jchavezar-demo/custom-local-train:v1 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772d1f79-8f3a-44ab-bcd8-7973628446f1",
   "metadata": {},
   "source": [
    "## Upload Image to Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b84f4a9d-7359-4f28-903f-acfd1df751d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/569083142710/locations/us-central1/models/6666613877112832000/operations/3402666124901351424\n",
      "Model created. Resource name: projects/569083142710/locations/us-central1/models/6666613877112832000@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/569083142710/locations/us-central1/models/6666613877112832000@1')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform as aip\n",
    "\n",
    "my_model = aip.Model.upload(\n",
    "    display_name=\"my-model-latest\", \n",
    "    serving_container_ports=[8080],\n",
    "    serving_container_health_route=\"/health_check\",\n",
    "    serving_container_image_uri=\"gcr.io/jchavezar-demo/custom-local-train:v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbfdec9-6c46-4552-9e54-90cd9c374fdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Deploy on Vertex Endpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6236ebb-1ba5-472f-81ea-3c15eda667a4",
   "metadata": {},
   "source": [
    "![](images/ml-artifacts-3.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fdb9e7-6353-48db-b958-8bb319f96231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/569083142710/locations/us-central1/endpoints/6255134844557197312/operations/6690293852881813504\n",
      "Endpoint created. Resource name: projects/569083142710/locations/us-central1/endpoints/6255134844557197312\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/569083142710/locations/us-central1/endpoints/6255134844557197312')\n",
      "Deploying model to Endpoint : projects/569083142710/locations/us-central1/endpoints/6255134844557197312\n",
      "Deploy Endpoint model backing LRO: projects/569083142710/locations/us-central1/endpoints/6255134844557197312/operations/2249744620294504448\n"
     ]
    }
   ],
   "source": [
    "my_model.deploy(\n",
    "    deployed_model_display_name='local-model',\n",
    "    machine_type='n1-standard-4'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcefe53-50fb-4399-b849-9e24b9642f02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
