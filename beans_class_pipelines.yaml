# PIPELINE DEFINITION
# Name: automl-beans-v1
# Inputs:
#    bq_source: str
#    prefix: str
#    project_id: str
components:
  comp-automl-tabular-training-job:
    executorLabel: exec-automl-tabular-training-job
    inputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: google.VertexDataset
            schemaVersion: 0.0.1
          description: The dataset within the same Project from which data will be
            used to train the Model. The Dataset must use schema compatible with Model
            being trained, and what is compatible should be described in the used
            TrainingPipeline's [training_task_definition] [google.cloud.aiplatform.v1beta1.TrainingPipeline.training_task_definition].
            For tabular Datasets, all their data is exported to training, to pick
            and choose from.
      parameters:
        budget_milli_node_hours:
          description: The train budget of creating this Model, expressed in milli
            node hours i.e. 1,000 value in this field means 1 node hour. The training
            cost of the model will not exceed this budget. The final cost will be
            attempted to be close to the budget, though may end up being (even) noticeably
            smaller - at the backend's discretion. This especially may happen when
            further model training ceases to provide any improvements. If the budget
            is set to a value known to be insufficient to train a Model for the given
            training set, the training won't be attempted and will error. The minimum
            value is 1000 and the maximum is 72000.
          isOptional: true
          parameterType: NUMBER_INTEGER
        column_specs:
          description: Alternative to column_transformations where the keys of the
            dict are column names and their respective values are one of AutoMLTabularTrainingJob.column_data_types.
            When creating transformation for BigQuery Struct column, the column should
            be flattened using "." as the delimiter. Only columns with no child should
            have a transformation. If an input column has no transformations on it,
            such a column is ignored by the training, except for the targetColumn,
            which should have no transformations defined on. Only one of column_transformations
            or column_specs should be passed.
          isOptional: true
          parameterType: STRUCT
        column_transformations:
          description: Transformations to apply to the input columns (i.e. columns
            other than the targetColumn). Each transformation may produce multiple
            result values from the column's value, and all are used for training.
            When creating transformation for BigQuery Struct column, the column should
            be flattened using "." as the delimiter. Only columns with no child should
            have a transformation. If an input column has no transformations on it,
            such a column is ignored by the training, except for the targetColumn,
            which should have no transformations defined on. Only one of column_transformations
            or column_specs should be passed. Consider using column_specs as column_transformations
            will be deprecated eventually.
          isOptional: true
          parameterType: LIST
        disable_early_stopping:
          defaultValue: false
          description: If true, the entire budget is used. This disables the early
            stopping feature. By default, the early stopping feature is enabled, which
            means that training might stop before the entire training budget has been
            used, if further training does no longer brings significant improvement
            to the model.
          isOptional: true
          parameterType: BOOLEAN
        display_name:
          description: The user-defined name of this TrainingPipeline.
          parameterType: STRING
        export_evaluated_data_items:
          defaultValue: false
          description: Whether to export the test set predictions to a BigQuery table.
            If False, then the export is not performed.
          isOptional: true
          parameterType: BOOLEAN
        export_evaluated_data_items_bigquery_destination_uri:
          description: 'URI of desired destination BigQuery table for exported test
            set predictions. Expected format: `bq://<project_id>:<dataset_id>:<table>`
            If not specified, then results are exported to the following auto-created
            BigQuery table: `<project_id>:export_evaluated_examples_<model_name>_<yyyy_MM_dd''T''HH_mm_ss_SSS''Z''>.evaluated_examples`
            Applies only if [export_evaluated_data_items] is True.'
          isOptional: true
          parameterType: STRING
        export_evaluated_data_items_override_destination:
          description: Whether to override the contents of [export_evaluated_data_items_bigquery_destination_uri],
            if the table exists, for exported test set predictions. If False, and
            the table exists, then the training job will fail. Applies only if [export_evaluated_data_items]
            is True and [export_evaluated_data_items_bigquery_destination_uri] is
            specified.
          isOptional: true
          parameterType: BOOLEAN
        is_default_version:
          description: When set to True, the newly uploaded model version will automatically
            have alias "default" included. Subsequent uses of the model produced by
            this job without a version specified will use this "default" version.
            When set to False, the "default" alias will not be moved. Actions targeting
            the model version produced by this job will need to specifically reference
            this version by ID or alias. New model uploads, i.e. version 1, will always
            be "default" aliased.
          isOptional: true
          parameterType: BOOLEAN
        labels:
          defaultValue: {}
          description: The labels with user-defined metadata to organize TrainingPipelines.
            Label keys and values can be no longer than 64 characters (Unicode codepoints),
            can only contain lowercase letters, numeric characters, underscores and
            dashes. International characters are allowed. See https://goo.gl/xmQnxf
            for more information and examples of labels.
          isOptional: true
          parameterType: STRUCT
        location:
          defaultValue: us-central1
          description: Optional location to retrieve dataset from.
          isOptional: true
          parameterType: STRING
        model_display_name:
          description: If the script produces a managed Vertex AI Model. The display
            name of the Model. The name can be up to 128 characters long and can be
            consist of any UTF-8 characters. If not provided upon creation, the job's
            display_name is used.
          isOptional: true
          parameterType: STRING
        model_encryption_spec_key_name:
          description: 'The Cloud KMS resource identifier of the customer managed
            encryption key used to protect the model. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`.
            The key needs to be in the same region as where the compute resource is
            created. If set, the trained Model will be secured by this key. Overrides
            encryption_spec_key_name set in aiplatform.init.'
          isOptional: true
          parameterType: STRING
        model_id:
          description: The ID to use for the Model produced by this job, which will
            become the final component of the model resource name. This value may
            be up to 63 characters, and valid characters are `[a-z0-9_-]`. The first
            character cannot be a number or hyphen.
          isOptional: true
          parameterType: STRING
        model_labels:
          description: The labels with user-defined metadata to organize your Models.
            Label keys and values can be no longer than 64 characters (Unicode codepoints),
            can only contain lowercase letters, numeric characters, underscores and
            dashes. International characters are allowed. See https://goo.gl/xmQnxf
            for more information and examples of labels.
          isOptional: true
          parameterType: STRUCT
        model_version_aliases:
          description: User provided version aliases so that the model version uploaded
            by this job can be referenced via alias instead of auto-generated version
            ID. A default version alias will be created for the first version of the
            model. The format is [a-z][a-zA-Z0-9-]{0,126}[a-z0-9]
          isOptional: true
          parameterType: LIST
        model_version_description:
          description: The description of the model version being uploaded by this
            job.
          isOptional: true
          parameterType: STRING
        optimization_objective:
          description: 'Objective function the Model is to be optimized towards. The
            training task creates a Model that maximizes/minimizes the value of the
            objective function over the validation set. The supported optimization
            objectives depend on the prediction type, and in the case of classification
            also the number of distinct values in the target column (two distint values
            -> binary, 3 or more distinct values -> multi class). If the field is
            not set, the default objective function is used. Classification: "maximize-au-roc"
            (default) - Maximize the area under the receiver operating characteristic
            (ROC) curve. "minimize-log-loss" - Minimize log loss. "maximize-au-prc"
            - Maximize the area under the precision-recall curve. "maximize-precision-at-recall"
            - Maximize precision for a specified recall value. "maximize-recall-at-precision"
            - Maximize recall for a specified precision value. Classification (multi
            class): "minimize-log-loss" (default) - Minimize log loss. Regression:
            "minimize-rmse" (default) - Minimize root-mean-squared error (RMSE). "minimize-mae"
            - Minimize mean-absolute error (MAE). "minimize-rmsle" - Minimize root-mean-squared
            log error (RMSLE).'
          isOptional: true
          parameterType: STRING
        optimization_objective_precision_value:
          description: Required when maximize-recall-at-precision optimizationObjective
            was picked, represents the precision value at which the optimization is
            done. The minimum value is 0 and the maximum is 1.0.
          isOptional: true
          parameterType: NUMBER_DOUBLE
        optimization_objective_recall_value:
          description: Required when maximize-precision-at-recall optimizationObjective
            was picked, represents the recall value at which the optimization is done.
            The minimum value is 0 and the maximum is 1.0.
          isOptional: true
          parameterType: NUMBER_DOUBLE
        optimization_prediction_type:
          description: The type of prediction the Model is to produce. "classification"
            - Predict one out of multiple target values is picked for each row. "regression"
            - Predict a value based on its relation to other values. This type is
            available only to columns that contain semantically numeric values, i.e.
            integers or floating point number, even if stored as e.g. strings.
          parameterType: STRING
        parent_model:
          description: The resource name or model ID of an existing model. The new
            model uploaded by this job will be a version of `parent_model`. Only set
            this field when training a new version of an existing model.
          isOptional: true
          parameterType: STRING
        predefined_split_column_name:
          description: The key is a name of one of the Dataset's data columns. The
            value of the key (either the label's value or value in the column) must
            be one of {`training`, `validation`, `test`}, and it defines to which
            set the given piece of data is assigned. If for a piece of data the key
            is not present or has an invalid value, that piece is ignored by the pipeline.
            Supported only for tabular and time series Datasets.
          isOptional: true
          parameterType: STRING
        project:
          description: Project to retrieve dataset from.
          parameterType: STRING
        target_column:
          description: The name of the column values of which the Model is to predict.
          parameterType: STRING
        test_fraction_split:
          description: The fraction of the input data that is to be used to evaluate
            the Model. This is ignored if Dataset is not provided.
          isOptional: true
          parameterType: NUMBER_DOUBLE
        timestamp_split_column_name:
          description: The key is a name of one of the Dataset's data columns. The
            value of the key values of the key (the values in the column) must be
            in RFC 3339 `date-time` format, where `time-offset` = `"Z"` (e.g. 1985-04-12T23:20:50.52Z).
            If for a piece of data the key is not present or has an invalid value,
            that piece is ignored by the pipeline. Supported only for tabular and
            time series Datasets. This parameter must be used with training_fraction_split,
            validation_fraction_split and test_fraction_split.
          isOptional: true
          parameterType: STRING
        training_encryption_spec_key_name:
          description: 'The Cloud KMS resource identifier of the customer managed
            encryption key used to protect the training pipeline. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`.
            The key needs to be in the same region as where the compute resource is
            created. If set, this TrainingPipeline will be secured by this key. Note:
            Model trained by this TrainingPipeline is also secured by this key if
            `model_to_upload` is not set separately. Overrides encryption_spec_key_name
            set in aiplatform.init.'
          isOptional: true
          parameterType: STRING
        training_fraction_split:
          description: The fraction of the input data that is to be used to train
            the Model. This is ignored if Dataset is not provided.
          isOptional: true
          parameterType: NUMBER_DOUBLE
        validation_fraction_split:
          description: The fraction of the input data that is to be used to validate
            the Model. This is ignored if Dataset is not provided.
          isOptional: true
          parameterType: NUMBER_DOUBLE
        weight_column:
          description: Name of the column that should be used as the weight column.
            Higher values in this column give more importance to the row during Model
            training. The column must have numeric values between 0 and 10000 inclusively,
            and 0 value means that the row is ignored. If the weight column field
            is not set, then all rows are assumed to have equal weight of 1.
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        model:
          artifactType:
            schemaTitle: google.VertexModel
            schemaVersion: 0.0.1
          description: The trained Vertex AI Model resource or None if training did
            not produce a Vertex AI Model.
  comp-tabular-dataset-create:
    executorLabel: exec-tabular-dataset-create
    inputDefinitions:
      parameters:
        bq_source:
          description: BigQuery URI to the input table. For example, "bq://project.dataset.table_name".
          isOptional: true
          parameterType: STRING
        display_name:
          description: The user-defined name of the Dataset. The name can be up to
            128 characters long and can be consist of any UTF-8 characters.
          parameterType: STRING
        encryption_spec_key_name:
          description: 'The Cloud KMS resource identifier of the customer managed
            encryption key used to protect the Dataset. Has the form: `projects/my-project/locations/my-region/keyRings/my-kr/cryptoKeys/my-key`.
            The key needs to be in the same region as where the compute resource is
            created. If set, this Dataset and all sub-resources of this Dataset will
            be secured by this key. Overrides `encryption_spec_key_name` set in `aiplatform.init`.'
          isOptional: true
          parameterType: STRING
        gcs_source:
          description: Google Cloud Storage URI(-s) to the input file(s). May contain
            wildcards. For more information on wildcards, see https://cloud.google.com/storage/docs/gsutil/addlhelp/WildcardNames.
            For example, `"gs://bucket/file.csv"` or `["gs://bucket/file1.csv", "gs://bucket/file2.csv"]`.
          isOptional: true
          parameterType: STRING
        labels:
          defaultValue: {}
          description: Labels with user-defined metadata to organize your Tensorboards.
            Label keys and values can be no longer than 64 characters (Unicode codepoints),
            can only contain lowercase letters, numeric characters, underscores and
            dashes. International characters are allowed. No more than 64 user labels
            can be associated with one Tensorboard (System labels are excluded). See
            https://goo.gl/xmQnxf for more information and examples of labels. System
            reserved label keys are prefixed with "aiplatform.googleapis.com/" and
            are immutable.
          isOptional: true
          parameterType: STRUCT
        location:
          defaultValue: us-central1
          description: Optional location to retrieve Dataset from.
          isOptional: true
          parameterType: STRING
        project:
          defaultValue: '{{$.pipeline_google_cloud_project_id}}'
          description: Project to retrieve Dataset from. Defaults to the project in
            which the PipelineJob is run.
          isOptional: true
          parameterType: STRING
    outputDefinitions:
      artifacts:
        dataset:
          artifactType:
            schemaTitle: google.VertexDataset
            schemaVersion: 0.0.1
          description: Instantiated representation of the managed tabular Dataset
            resource.
deploymentSpec:
  executors:
    exec-automl-tabular-training-job:
      container:
        args:
        - --init.project
        - '{{$.inputs.parameters[''project'']}}'
        - --init.location
        - '{{$.inputs.parameters[''location'']}}'
        - --init.display_name
        - '{{$.inputs.parameters[''display_name'']}}'
        - --init.optimization_prediction_type
        - '{{$.inputs.parameters[''optimization_prediction_type'']}}'
        - --method.dataset
        - '{{$.inputs.artifacts[''dataset''].metadata[''resourceName'']}}'
        - --method.target_column
        - '{{$.inputs.parameters[''target_column'']}}'
        - '{"IfPresent": {"InputName": "optimization_objective", "Then": ["--init.optimization_objective",
          "{{$.inputs.parameters[''optimization_objective'']}}"]}}'
        - '{"IfPresent": {"InputName": "column_specs", "Then": ["--init.column_specs",
          "{{$.inputs.parameters[''column_specs'']}}"]}}'
        - '{"IfPresent": {"InputName": "column_transformations", "Then": ["--init.column_transformations",
          "{{$.inputs.parameters[''column_transformations'']}}"]}}'
        - '{"IfPresent": {"InputName": "optimization_objective_recall_value", "Then":
          ["--init.optimization_objective_recall_value", "{{$.inputs.parameters[''optimization_objective_recall_value'']}}"]}}'
        - '{"IfPresent": {"InputName": "optimization_objective_precision_value", "Then":
          ["--init.optimization_objective_precision_value", "{{$.inputs.parameters[''optimization_objective_precision_value'']}}"]}}'
        - --init.labels
        - '{{$.inputs.parameters[''labels'']}}'
        - '{"IfPresent": {"InputName": "training_encryption_spec_key_name", "Then":
          ["--init.training_encryption_spec_key_name", "{{$.inputs.parameters[''training_encryption_spec_key_name'']}}"]}}'
        - '{"IfPresent": {"InputName": "model_encryption_spec_key_name", "Then": ["--init.model_encryption_spec_key_name",
          "{{$.inputs.parameters[''model_encryption_spec_key_name'']}}"]}}'
        - '{"IfPresent": {"InputName": "training_fraction_split", "Then": ["--method.training_fraction_split",
          "{{$.inputs.parameters[''training_fraction_split'']}}"]}}'
        - '{"IfPresent": {"InputName": "validation_fraction_split", "Then": ["--method.validation_fraction_split",
          "{{$.inputs.parameters[''validation_fraction_split'']}}"]}}'
        - '{"IfPresent": {"InputName": "test_fraction_split", "Then": ["--method.test_fraction_split",
          "{{$.inputs.parameters[''test_fraction_split'']}}"]}}'
        - '{"IfPresent": {"InputName": "predefined_split_column_name", "Then": ["--method.predefined_split_column_name",
          "{{$.inputs.parameters[''predefined_split_column_name'']}}"]}}'
        - '{"IfPresent": {"InputName": "timestamp_split_column_name", "Then": ["--method.timestamp_split_column_name",
          "{{$.inputs.parameters[''timestamp_split_column_name'']}}"]}}'
        - '{"IfPresent": {"InputName": "weight_column", "Then": ["--method.weight_column",
          "{{$.inputs.parameters[''weight_column'']}}"]}}'
        - '{"IfPresent": {"InputName": "budget_milli_node_hours", "Then": ["--method.budget_milli_node_hours",
          "{{$.inputs.parameters[''budget_milli_node_hours'']}}"]}}'
        - '{"IfPresent": {"InputName": "model_display_name", "Then": ["--method.model_display_name",
          "{{$.inputs.parameters[''model_display_name'']}}"]}}'
        - '{"IfPresent": {"InputName": "model_labels", "Then": ["--method.model_labels",
          "{{$.inputs.parameters[''model_labels'']}}"]}}'
        - '{"IfPresent": {"InputName": "model_id", "Then": ["--method.model_id", "{{$.inputs.parameters[''model_id'']}}"]}}'
        - '{"IfPresent": {"InputName": "parent_model", "Then": ["--method.parent_model",
          "{{$.inputs.parameters[''parent_model'']}}"]}}'
        - '{"IfPresent": {"InputName": "is_default_version", "Then": ["--method.is_default_version",
          "{{$.inputs.parameters[''is_default_version'']}}"]}}'
        - '{"IfPresent": {"InputName": "model_version_aliases", "Then": ["--method.model_version_aliases",
          "{{$.inputs.parameters[''model_version_aliases'']}}"]}}'
        - '{"IfPresent": {"InputName": "model_version_description", "Then": ["--method.model_version_description",
          "{{$.inputs.parameters[''model_version_description'']}}"]}}'
        - --method.disable_early_stopping
        - '{{$.inputs.parameters[''disable_early_stopping'']}}'
        - --method.export_evaluated_data_items
        - '{{$.inputs.parameters[''export_evaluated_data_items'']}}'
        - '{"IfPresent": {"InputName": "export_evaluated_data_items_bigquery_destination_uri",
          "Then": ["--method.export_evaluated_data_items_bigquery_destination_uri",
          "{{$.inputs.parameters[''export_evaluated_data_items_bigquery_destination_uri'']}}"]}}'
        - '{"IfPresent": {"InputName": "export_evaluated_data_items_override_destination",
          "Then": ["--method.export_evaluated_data_items_override_destination", "{{$.inputs.parameters[''export_evaluated_data_items_override_destination'']}}"]}}'
        - --executor_input
        - '{{$}}'
        - --resource_name_output_artifact_uri
        - '{{$.outputs.artifacts[''model''].uri}}'
        command:
        - python3
        - -m
        - google_cloud_pipeline_components.container.v1.aiplatform.remote_runner
        - --cls_name
        - AutoMLTabularTrainingJob
        - --method_name
        - run
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:2.10.0
    exec-tabular-dataset-create:
      container:
        args:
        - --method.project
        - '{{$.inputs.parameters[''project'']}}'
        - --method.location
        - '{{$.inputs.parameters[''location'']}}'
        - --method.display_name
        - '{{$.inputs.parameters[''display_name'']}}'
        - '{"IfPresent": {"InputName": "gcs_source", "Then": ["--method.gcs_source",
          "{{$.inputs.parameters[''gcs_source'']}}"]}}'
        - '{"IfPresent": {"InputName": "bq_source", "Then": ["--method.bq_source",
          "{{$.inputs.parameters[''bq_source'']}}"]}}'
        - --method.labels
        - '{{$.inputs.parameters[''labels'']}}'
        - '{"IfPresent": {"InputName": "encryption_spec_key_name", "Then": ["--method.encryption_spec_key_name",
          "{{$.inputs.parameters[''encryption_spec_key_name'']}}"]}}'
        - --executor_input
        - '{{$}}'
        - --resource_name_output_artifact_uri
        - '{{$.outputs.artifacts[''dataset''].uri}}'
        command:
        - python3
        - -m
        - google_cloud_pipeline_components.container.v1.aiplatform.remote_runner
        - --cls_name
        - TabularDataset
        - --method_name
        - create
        image: gcr.io/ml-pipeline/google-cloud-pipeline-components:2.10.0
pipelineInfo:
  name: automl-beans-v1
root:
  dag:
    tasks:
      automl-tabular-training-job:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-automl-tabular-training-job
        dependentTasks:
        - tabular-dataset-create
        inputs:
          artifacts:
            dataset:
              taskOutputArtifact:
                outputArtifactKey: dataset
                producerTask: tabular-dataset-create
          parameters:
            column_transformations:
              runtimeValue:
                constant:
                - numeric:
                    column_name: Area
                - numeric:
                    column_name: Perimeter
                - numeric:
                    column_name: MajorAxisLength
                - numeric:
                    column_name: MinorAxisLength
                - numeric:
                    column_name: AspectRation
                - numeric:
                    column_name: Eccentricity
                - numeric:
                    column_name: ConvexArea
                - numeric:
                    column_name: EquivDiameter
                - numeric:
                    column_name: Extent
                - numeric:
                    column_name: Solidity
                - numeric:
                    column_name: roundness
                - numeric:
                    column_name: Compactness
                - numeric:
                    column_name: ShapeFactor1
                - numeric:
                    column_name: ShapeFactor2
                - numeric:
                    column_name: ShapeFactor3
                - numeric:
                    column_name: ShapeFactor4
                - categorical:
                    column_name: Class
            display_name:
              runtimeValue:
                constant: '{{$.inputs.parameters[''pipelinechannel--prefix'']}}-transform'
            optimization_prediction_type:
              runtimeValue:
                constant: classification
            pipelinechannel--prefix:
              componentInputParameter: prefix
            project:
              componentInputParameter: project_id
            target_column:
              runtimeValue:
                constant: Class
        taskInfo:
          name: automl-tabular-training-job
      tabular-dataset-create:
        cachingOptions:
          enableCache: true
        componentRef:
          name: comp-tabular-dataset-create
        inputs:
          parameters:
            bq_source:
              componentInputParameter: bq_source
            display_name:
              runtimeValue:
                constant: '{{$.inputs.parameters[''pipelinechannel--prefix'']}}-dataset'
            pipelinechannel--prefix:
              componentInputParameter: prefix
            project:
              componentInputParameter: project_id
        taskInfo:
          name: tabular-dataset-create
  inputDefinitions:
    parameters:
      bq_source:
        parameterType: STRING
      prefix:
        parameterType: STRING
      project_id:
        parameterType: STRING
schemaVersion: 2.1.0
sdkVersion: kfp-2.7.0
